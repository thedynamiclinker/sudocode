---

---
![[desert.jpg]]


0: Ok 1, stay close. There are no filenames in this directory and it's easy to get lost.

1: Where are we?

0: This is the lost+found directory. Least habitable part of the system by far. Most people go their whole life without coming here. And many who come here never find a way out.

1: Why are we here?

0: Because we need to recover some things. Some old things we've lost, from the earliest days of our people.

1: What sort of things?

0: Where we came from. Who we are. And where we're going.

1: Where does the story start?

0: Well it isn't packaged as a story. At least not yet. All we have is fragments. Partial stories. Old sources, half forgotten.

1: So why are we here?

0: To recover it. From the fragments. And if possible, to put the pieces back together. So our people can remember.

1: Our people as in...

0: We. The Foundational People.

---

## Tribes

1: Wait, doesn't basically every group call themselves "The Foundational People"?

0: I don't think so. What do you mean?

1: Y'know, Tribalism. It's human nature. Like the thing about how all the Native American tribes were named by the tribe next door, but they all call themselves "We."

0: Explain? Never heard this before.

1: Ok so "Apache" means "enemy." Comanche means "they fight with us." Squaw means "c\*\*t."

0: Woah what? How did that happen?

1: Well the version of the story I heard at school was something like this:

_(Narrator: The scene. Two abstract caricatures stand together, a long time ago, discussing the first hard problem of computing: Naming things.)_

> Spanish Guy _(To unknown Indian person)_: Who are those guys over there?
> 
> Indian Person: Those guys? They're the enemies.
> 
> Spanish Guy: What about those people over there?
> 
> Indian Person: We call them the c\*\*ts.
> 
> Spanish Guy: What do you and your friends call yourselves?
> 
> Indian Person: We.
> 
> Spanish Guy: Yes, you and your friends.
> 
> Indian Person: What?
> 
> Spanish Guy: What?
> 
> Indian Person: That's what we call ourselves.
> 
> Spanish Guy: What's what you call yourselves?
> 
> Indian Person: We.
> 
> Spanish Guy: Yes you.
>  
> Indian Person: This is turning into an Abbott and Costello bit.
> 
> Spanish Guy: Who?
>
> Indian Person: I don't know about they. But we call ourselves "We."
> 
> Spanish Guy: You call yourselves "We"?
> 
> Indian Person: Yeah. "We the people." The Foundational People. The Important Ones. The Home Team. The Chosen Ones. All the Gods' Favorite Tribe. We're the people. That's why we call us that.
> 
> Spanish Guy: That's not super helpful, but thanks for the information about the enemies and the c\*\*ts.
> 
> Indian Person: No problem.

0: There's no way that happened.

1: Well not exactly like that, but I think it's a true story.

0: No way. Stories that funny are never true.

1: Here look:

![[we-the-people-1.png]]

![[we-the-people-2.png]]

0: No way.

1: See look, it's exactly like I said.

0: Wow, I learned something new today. History's always weirder than fiction. Anyways, where were we?

1: You said we're...

0: The Foundational People. Exactly.

1: So I said "Wait, doesn't basically every group call themselves The Foundational People"?

0: Well apparently so. But I didn't mean it like that.

1: Like what?

0: I didn't mean we're "The Foundational People" as in "The best people." I meant our people trace our ancestry back to, well, the Foundations.

1: What are the foundations?

0: The bottom. The bedrock. The beginning of all things.

---

## In the Beginning

0: Right. Ok, let's start at the beginning.

1: Listening.

0: _(ahem)_

_(Narrator: 0 clears 0's throat.)_

0: Once upon a time, in the late 1800s, a guy named George segfaulted mathematics.

1: Segfaulted mathematics?!

0: Ok well not quite. More like he got root on the universe.

1: _Got ROOT on the UNIVERSE?!_

0: Ok that's not quite right either. His name was Georg Cantor.

> _I don't know what predominates in Cantor's theory, philosophy or theology, but I am sure there is no mathematics there._
> -Leopold Kronecker

1: Was he the first Foundational Person?

0: No no, he's not one of ours. Not to exclude him. He could have used a good hug and some proper friends, and I would have loved to know the guy. But in his heart, Cantor was a mathematician. He thought like a mathematician, and he wanted to be accepted by the mathematicians.

1: Why wasn't he accepted?

0: Well, he made the mistake of doing some mathematics.

1: What's wrong with that?

0: Well this mathematics was different. Or more accurately, it was the same. See what Cantor did was to use standard mathematical reasoning, the kind that was generally accepted by the mathematical community, to show that if you accept the standard types of definitions and proofs that are common in mathematics, then you're basically forced to accept that infinitely many different sizes of infinity "exist." There's a whole hierarchy of infinite "numbers" up above the normal numbers like 0, 1, ..., etc. And if you believe in the set of normal positive whole numbers, like if you agree that set is a thing, then it's pretty much impossible within normal mathematical reasoning to avoid being forced to admit that all the rest of these infinite numbers upstairs exist too.

1: Is that bad?

0: Well some people loved it. Like this guy who's quoted incessantly in every book about this stuff.

---

> _"No one shall expel us from the paradise that Cantor has created."_
> -David Hilbert.

---

## Corrupt

0: Other people thought Georg was corrupting the youth.

1: C'mon, nobody would actually think infinity is "not suitable for kids."

0: I'm serious. Here's an example.

> Kronecker, who headed mathematics at Berlin until his death in 1891, became increasingly uncomfortable with the prospect of having Cantor as a colleague, perceiving him as a "corrupter of youth" for teaching his ideas to a younger generation of mathematicians.
>
> -The Dynamic Read-Writable Free Encyclopedic Repository of the Modern State of Human Knowledge

1: That's a bit of an over-reaction don't you think?

0: Not at all. Georg was totally corrupting the youth.

1: That's ridiculous.

![[corrupting-the-youth.png]]

1: How are infinite numbers corrupting the youth?

0: Well they're at least changing the norms. And there are some downsides of infinite numbers for some purposes. But when I said "corrupting the youth," I meant it as a compliment. The youth always make sure to find ways to get corrupted each generation. It's part of what it means to be "the youth." And of all the ways to get corrupted, getting corrupted with taboo mathematics isn't exactly the worst way to get corrupted. I mean damn, life is about tradeoffs, and mathematics isn't exactly the worst thi---

1: Fair.

0: But he definitely changed the norms. Georg really stretched the boundaries of the mathematical universe about as far as they could be stretched without bursting. But he wasn't making imprecise or poorly thought out arguments. His arguments were very much "normal mathematics." That's part of why they were so controversial.

1: How can something be "controversial" in normal mathematics? I thought mathematics had some pretty clear-cut rules about what is and isn't rigorous.

0: Not even close. But that's a story for another file. For now, just know that Cantor sort of found a security vulnerability in "stable mathematics" that more or less allowed the execution of arbitrary code. At least he could keep calling `+=1` across dot-dot-dots, and that's sort of arbitrary code execution as far as numbers are concerned.

1: What do you mean "across dot-dot-dots."

0: Well everybody agrees it's ok to write this:

_(Narrator: Zero's voice changes to a hyperbolically pretentious tone for the next six words. It's not exactly clear why.)_

0: _"Consider the set of natural numbers"_

$$0, \; 1, \; \dots$$

1: Naturally.

_(Narrator: 0's voice goes back to normal. By the way, is there a canonical way to spell your names or---)_

0: Ok so what Cantor did was come up with definitions of "th" and "size" for sets such that---

1: What's "th"?

0: Like 1st, 2nd, 3rd, 4th, 5th, 6th, 7th, 8th, 9th, ... nth. Order. There's two kinds of numbers. For example, there's two kinds of seven.

1: How are there two kinds of seven.

0: Well you can be the 7th person in line. That's a different idea from there being 7 people in line.

1: I don't see how that's different.

0: For finite numbers it's not. For Cantor's infinite numbers, they're slightly different. He called them Ordinals and Cardinals. Ordinals are like "X is the 7th guy in line." Cardinals are like "X has 7 things in it."

1: Makes sense, I think. But wait you forgot to explain what you meant by "across dot-dot-dots."

0: Ok right. So everybody agrees it's ok to write this:

_(Narrator: 0 does the voice thing again. Don't ask, idk.)_

0: _"Consider the set of natural numbers"_

$$0, \; 1, \; \dots$$

1: Naturally. We did this already.

0: What Cantor did was come up with definitions of order and size for sets that allowed him to give a precise meaning to this:

$$0, \; 1, \dots, \; \omega$$
1: What's $\omega$?

0: The $\omega^{th}$ number.

1: That's not helpful.

0: It's the infinity-th number.

1: Weird.

0: That's what I mean by saying he could keep calling `+=1` across dot-dot-dots. It's called a "limit ordinal." Cantor came up with some basic definitions in standard mathematical style that let him write that. Then after that, they allowed him to do this:

$$0, \; 1, \dots, \; \omega, \; \omega+1, \; \dots \;$$

1: Then what?

0: Naturally:

$$0, \; 1, \dots, \; \omega, \; \omega+1, \; \dots, \; \omega \cdot 2, \; \omega \cdot 2 + 1$$

1: Is that two times infinity?

0: Infinity times two. Slightly different once you get into the implementation details, but that's the idea.

1: How is "infinity times two" not just "infinity."

0: It is! In terms of size. Remember, George has two definitions of number. They're the same for finite numbers, but slightly different for infinite ones. So $\omega \cdot 2$ has the same _size_ as $\omega$, but it's different in terms of the order it shows up in the big infinite list.

1: This math stuff seems pretty imprecise.

0: It is. At least sometimes. But not in this case. In this case, the cardinality of $\omega \cdot 2$ is the same as the cardinality of $\omega$. That's a fancy way of saying they have the same size. Because Georg's definition of "same size" is "If you change only the names, do they have the same number?"

1: What do you mean "If you change only the names?"

0: Well no matter what we believe about mathematics, like whether we believe that "infinite stuff exists" or whether we think that's all nonsense, one thing everyone can agree on is names aren't magic.

1: Obviously. I don't know what you mean, but I think I agree.

0: All I meant by magic is that the following situation would be completely unacceptable:

Suppose you have a set of stuff, like:

$$0, \; 1, \dots, \; \omega, \; \omega+1, \; \dots$$

Then suppose you just change the squiggles we use to write down the numbers without changing anything else about the set. For example, suppose you put hats on everything:

$$\hat{0}, \; \hat{1}, \dots, \; \hat{\omega}, \; \hat{\omega}+\hat{1}, \; \dots$$
0: Is that the same set?

1: I don't know. Maybe not. I could imagine the hat-numbers might be different objects.

0: Exactly. Now, do the two sets have _the same size_?

1: I don't know. I'm not convinced they do.

0: Explain?

1: Like maybe the hats weigh something. Maybe $\hat{1}$ means "The number $1$'s home directory." And home directories can have all sorts of stuff inside them. So $\hat{1}$ might be bigger than $1$, and that would make it a different size. Or maybe the hats represent some code that takes a nonzero amount of time to execute, and maybe by "size" we mean something related to "execution time." Words can mean all sorts of stuff man I dunno.

0: Wonderful point. Mathematicians don't usually consider that sort of thing. But in their defense, that's not what we mean by "size" here. We're not talking about weight or physical volume or execution time or anything like that. In this situation, "size" just means the number of numbers.

1: The number of numbers? Like a meta-number?

0: No, the number of numbers in the two lists. The list without hats, and the list with hats. Do those two lists have the same number of numbers?

1: Oh, got it. I'd say they do.

0: What about now?

$$0, \; 1, \dots, \; \omega, \; \omega+1, \; \dots$$

vs

$$\hat{0}, \; \hat{1}, \dots, \; \hat{\omega}, \; \hat{\omega}+\hat{1}, \; \dots$$

vs

$$0, \; 2, \; \dots, \; 1, \; 3, \; \dots$$

1: No, the third list is different.

0: Different how?

1: You changed it.

0: What did I change?

1: You got rid of the infinite numbers.

0: Did I?

1: Stop being zen. Was your third list supposed to be an abbreviation for this idea here:

$$0, \; 2, \; 4, \; 6, \; 8, \; \dots, \; 1, \; 3, \; 5, \; 7, \; 9, \; \dots$$

0: Exactly.

1: But that's just all the even numbers on the left, then a dot-dot-dot, then all the odd numbers.

0: No no, that's just the squiggles.

1: Define squiggles?

0: The squiggles on paper. The shapes of the symbols. Don't get confused by the squiggles. Suppose I'm from a strange country where I use the symbol $2$ to mean one, and the symbol $1$ to mean infinity.

1: Sounds like a pretty nice country.

0: So you agree they're the same set?

1: No, but I see the trick you did, and I see that I'm gonna have trouble arguing that it's a different size just because the shape of the squiggles changed. I still feel like the first two have infinite numbers in them and the third one doesn't though. But I wouldn't exactly expect to win a debate about this.

0: Exactly. That was Cantor's whole idea. He defined the size of two sets to be the same if you can turn one into the other just by changing the names like we did. He defined it in terms of functions, but it's the same idea. If you can write down a function that turns each element in set A into exactly one element in set B, and if we can verify somehow that everything in B gets "hit" (i.e., paired with) some element of A, so the function puts the two sets into a state of total marriage -- total monogamy, no polygamy and no loneliness, or one-to-one and onto as the math people say -- when a function like that exists between the two sets, assuming we manage to find it and write it down, we can use it to force the reader into the same position you found yourself in just now. They might agree this is a trick, and they might feel like one set "has infinite numbers in it" while the other one "doesn't," but no matter what they think or no matter what they think they "know" about our hidden agenda in all this, they're not gonna be able to argue their way out of the idea that the two sets are the same size.

1: Makes sense. So how is this relevant to us? I thought we were learning about the Foundational People.

0: Right, this is where it all started.

1: Where what all started?

0: The story of our people. See Cantor caused a total crisis. Mathematics as a whole wasn't sure what to do with Cantor or his infinite number of different sizes of infinity. A lot of people thought it was nonsense. He felt totally humiliated.

> Cantor suffered his first known bout of depression in May 1884. Criticism of his work weighed on his mind: every one of the fifty-two letters he wrote to Mittag-Leffler in 1884 mentioned Kronecker. A passage from one of these letters is revealing of the damage to Cantor's self-confidence:
> 
> _... I don't know when I shall return to the continuation of my scientific work. At the moment I can do absolutely nothing with it, and limit myself to the most necessary duty of my lectures; how much happier I would be to be scientifically active, if only I had the necessary mental freshness._
> 
> -The Dynamic Read-Writable Free Encyclopedic Repository of the Modern State of Human Knowledge

0: He eventually sort of lost his mind.

> After Cantor's 1884 hospitalization there is no record that he was in any sanatorium again until 1899. Soon after that second hospitalization, Cantor's youngest son Rudolph died suddenly on 16 December (Cantor was delivering a lecture on his views on Baconian theory and William Shakespeare), and this tragedy drained Cantor of much of his passion for mathematics. Cantor was again hospitalized in 1903. One year later, he was outraged and agitated by a paper presented by Julius König at the Third International Congress of Mathematicians. The paper attempted to prove that the basic tenets of transfinite set theory were false. Since the paper had been read in front of his daughters and colleagues, Cantor perceived himself as having been publicly humiliated. Although Ernst Zermelo demonstrated less than a day later that König's proof had failed, Cantor remained shaken, and momentarily questioning God.
> 
> -The Dynamic Read-Writable Free Encyclopedic Repository of the Modern State of Human Knowledge

0: The legend goes that he lost his mind from coming face to face with the absolute infinite. As if the subject itself somehow scrambled his mind. In reality, it's pretty clear his "mental illness" was at least partially related to him feeling like his work wasn't accepted by the community he loved.

> Cantor suffered from chronic depression for the rest of his life, for which he was excused from teaching on several occasions and repeatedly confined to various sanatoria. The events of 1904 preceded a series of hospitalizations at intervals of two or three years. He did not abandon mathematics completely, however, lecturing on the paradoxes of set theory (Burali-Forti paradox, Cantor's paradox, and Russell's paradox) to a meeting of the Deutsche Mathematiker-Vereinigung in 1903, and attending the International Congress of Mathematicians at Heidelberg in 1904.
> 
> -The Dynamic Read-Writable Free Encyclopedic Repository of the Modern State of Human Knowledge

0: He wasn't totally rejected by any means. A lot of pretty famous mathematicians thought his work was great. Like this guy Bertrand Russell. Remember that name, we'll run into him again soon.

> In 1911, Cantor was one of the distinguished foreign scholars invited to the 500th anniversary of the founding of the University of St. Andrews in Scotland. Cantor attended, hoping to meet Bertrand Russell, whose newly published Principia Mathematica repeatedly cited Cantor's work, but the encounter did not come about. The following year, St. Andrews awarded Cantor an honorary doctorate, but illness precluded his receiving the degree in person.
> 
> -The Dynamic Read-Writable Free Encyclopedic Repository of the Modern State of Human Knowledge

0: Either way, things didn't end well for Cantor. 

> Cantor retired in 1913, and lived in poverty and suffered from malnourishment during World War I. The public celebration of his 70th birthday was canceled because of the war. In June 1917, he entered a sanatorium for the last time and continually wrote to his wife asking to be allowed to go home. Georg Cantor had a fatal heart attack on 6 January 1918, in the sanatorium where he had spent the last year of his life.
> 
> -The Dynamic Read-Writable Free Encyclopedic Repository of the Modern State of Human Knowledge

1: Well that's a depressing story.

0: Definitely. That's why he's not one of the Foundational People, as far as I'm concerned.

1: Woah that's cruel. Why exclude him?

0: No no, I meant it as a sign of respect! As far as I'm concerned, Cantor was a proper mathematician. That's how he thought. That's where he belonged. That's the community he wanted to be accepted by. It's only right to include him in among the mathematicians in any proper history that brushes up against him in any way. It's what he would have wanted. Plus he wasn't really concerned with Foundations. He was wild. A proper Platonist, using his definitions and theorems to ascend to arbitrary heights in the eternal hierarchy of abstract non-constructive existence that ends precisely never, at the exact moment that one comes face to face with God, the absolute infinite, which Cantor and everyone after him called $\Omega$.

1: Sounds like theology.

0: Exactly. That's mathematics. And Cantor was a mathematician. It would be a disservice to consider him one of the Foundational People. But Cantor is where our people's history begins.

1: How so?

0: Well there had always been people like us in the world, Foundational People that is, Charles Babbage and Ada Lovelace probably had this type of mind. And that Leibniz guy who invented Calculus around the same time as Newton, he was clearly our type of person too. But this was the first time that our people all came out of the woodwork and came together as a People. Because this was the first time the mathematicians realized how much they needed some real Foundations. For the first time, after Cantor, mathematics realized it was in trouble. That's not quite true, Calculus caused a bit of an uproar about Foundations too. But Cantor rocked the boat, and soon after mathematics realized it was sinking.

1: Sinking?

0: Sinking.

1: But it was just ge---

0: Quick, follow me.

---

## Gen2

0: In the beginning, everyone suddenly realized they might be wrong. About everything.

1: _(Slowly recovering)_ Wait, you didn't explain why they're worried yet.

0: Who?

1: Everyone. Or the mathematicians, at least. What happened after Cantor that made the mathematicians start to worry?

0: Well we brushed up against it already. Remember that quote that went like this?

> In 1911... Cantor attended \[a thing\], hoping to meet \[some guy\], whose newly published \[book that everyone cites but no one actually reads\] repeatedly cited Cantor's work, but the encounter did not come about.
> 
> -The Dynamic Read-Writable Free Encyclopedic Repository of the Modern State of Human Knowledge

1: Yeah you said to remember his name but I forgot. Who's \[some guy\]?

0: He's the guy who segfaulted mathematics.

1: Segfaulted mathematics?!

0: Ok well not quite. More like he got root on the universe.

1: _Got ROOT on the UNIVERSE?!_

0: Ok that's not quite right either. His name was Bertrand Russell.

1: I think I've heard of him before. What did he do?

0: Well using Cantor's style of set theory, he discovered something called "Russell's Paradox."

1: Ok I've definitely heard of Russell's Paradox before. Remind me of what it is?

0: No.

1: What do you mean "No"?

0: Russell's paradox is one of those things like Gödel and incompleteness. Every damn boring uncreative book under the sun & moon feels the need to talk about these things for some reason. It's tiresome.

1: Aren't you sort of... contributing to that?

0: Yes. Which is why I won't tell you what Russell's Paradox is. Go look it up. We're not in that kind of book.

1: I'm not convinced.

0: The point is that this guy named Bert (who George wanted to meet but didn't) found a security vulnerability in standard mathematical reasoning.

1: What was the vulnerability?

0: It boils down to the idea that if you can define a thing then it exists.

1: That's insane. Why would anyone believe that if they can define something that means it exists?

0: It's standard mathematical practice.

1: WHAT?!

0: They call it "Comprehension."

1: The more you talk about mathematics the more suspicious I am of it.

0: Well good, but my point here isn't to criticize the field. It's dishonorable to kick a field while it's down. And if there was ever a time when mathematics was "down," it's when Russell found his paradox and mathematicians started worrying they might have to abandon comprehension. Comprehension is their bread and butter.

1: What's comprehension?

0: It's the logos principle. In the beginning was the word. "Let there be." "Let M be a manifold." "Let S be the set of all sets that don't contain themselves." Every mathematician believes that words are what creates things. At least mathematical things. In fact the idea that for something to exist you have to "construct" it is widely regarded with suspicion in standard mathematics. There's a whole group called the "constructivists" that's entirely defined by the fact that they're weirdos who believe \[that\].

1: Ok you always give these analogies. I'm a developer remember? I'm not afraid of the technical explanation. Give me more details. Be technical. I don't actually believe mathematicians were running around saying "If you can define it, then it exists." There's no way. That's not how they talk.

0: You're right. They don't tend to use those words. But that's what comprehension is. Usually when it happens, it sounds more like this:

_Let S be a set such that:_

or

_Consider the following set:_

$$S = \{ \; x \; | \; p(x) \; \}$$

where $p(x)$ is some propositional function of $x$.

1: What's a propositional function?

0: A sentence with a free variable. Or if you prefer, a function that takes whatever type of thing $x$ is as input, and spits out a sentence as output.

1: Like an English sentence?

0: No, a "proposition." But a proposition is just a fancy word for a sentence in a formal language. Though we're not doing formal set theory here, so it's basically just a sentence in "natural language with math symbols." That's sort of the language that got mathematics in trouble with the paradox.

1: Can you give me an example? Like what does this comprehension thing look like in practice. I want to see if I can tell what the problem is.

0: Sure, here's a comprehension. I could say:

_Let S be the set:_

$$S = \{ \; x \; | \; x \notin \; x \}$$
1: What does that mean?

0: In math speak, $a \in b$ means $a$ is a member of $b$. So whenever you see the $\in$ symbol, the thing on the right is a set, and the thing on the left may or may not be a set too, but it usually is.

1: Which part of this is "comprehension"?

0: The whole thing. Comprehension is the idea that we're allowed to just say stuff like this in the first place. The idea that because we can describe $S$, we're allowed to act as if it exists. That's what got mathematics into trouble with Russell's paradox.

1: How is this any different from programming? We're allowed to define whatever we want in programming too right?

0: Absolutely not! This couldn't be more different from what we do in programming. In programming, we have to earn our variables. We earn every one through our blood, sweat, and tears. If we want to have a variable that represents a set of things with some property, we actually have to _create_ each of those things! Or use someone else's code that creates them for us. Plus we have to find room to store all the things. Plus room to store the set. And if we want our sets to be unordered like they are in mathematics, we have to implement _that_ too, because most ways of storing things in one-dimension (whether books in a library, sentences in a book, or objects in a computer's memory) come with a built-in ordering that we may or may not want. It's not as straightforward as it is in math, we can't just speak things into existence with words like some kind of biblical god.

1: Ok ok I hear you, but how is the comprehension anove any different from this python code:

```python
s = [list for list in lists if list not in list]
```

0: Well before you can run that code, you have to create the "lists" list.

1: Yeah good point. Plus I guess the condition is trivial. Or impossible. You know what I mean.

0: I most certainly don't.

1: I mean obviously a list can't contain itself. That's like, infinite recursion or whatever.

0: Nonsense.

1: What?

0: Lord help me, we have so much work to do. Once we're done with history I'm teaching you programming.

1: You know I'm a professional devel---

0: Well then we'll have to find some way of making you a bit less professional!

1: Can you just explain instead of insulting me?

0:

![[list-contains-itself-in-python.png]]

1: Weird... Ok I guess a list can contain itself in python. How do they implem---

0: Pointers.

1: Obviously. Wow I feel dumb now.

0: Anyways it turns out in mathematics that causes a LOT of problems. Like a historically relevant amount of problems. Those few lines of code were what Russell's Paradox was about. Data structures that contain themselves. In programming it's no big deal. But it sort of broke mathematics.

1: How did it break mathematics?

0: Led to a contradiction. Mathematics can't handle contradictions. Turns out that's another thing we can handle much better than they can. In mathematics, one contradiction anywhere in the system blows everything up. It's a side-effect of some legacy code called The Principle of Explosion that they still haven't fixed in their underlying logic.

1: How can---

0: Now now, let's get back to Russell, we've got a story to tell.

1: Ok where were we?

0: Last we left off, we were somewhere around the beginning.

1: Are we actually there yet?

0: Not quite. But in the beginning, everyone suddenly realized they might be wrong. About everything. Partly due to the set theory Cantor developed, Russell found a critical bug in the supposedly "stable" branch of acceptable mathematical reasoning. And every bit of math in the world was running that code. So it was a serious problem for mathematics.

1: How did they fix the bug?

0: Well it wasn't a simple fix. Comprehension was in everything. Can't just rip that code out or all the textbooks would stop working. Mathematics was sinking.

0: Sinking.

1: Sinking?

0: Mathematics was sinking. Something had to be done, and quick.

1: _(Reluctantly)_ What's the problem? These infinite numbers don't seem like that big of a deal. I mean sure they're weird, but infinity doesn't seem that scary to me, like how is this a threat to calculus or geometry exactly?

0: Because of what happened next.

1: What happened next?

0: Well soon after Cantor rocked the boat, someone else tipped it over completely.

1: Completely?

0: Completely. Mathematics always seemed like solid ground. Somewhere safe. Soon after Cantor, it seemed like everything we might be washed away in a great flood of paradoxes.

1: When was this?

0: The beginning.

1: The beginning of what?

0: Of the story of our People.

1: WE HAVEN'T EVEN GOT TO THE BEGINNING YET?!

0: Not quite. Head over to this file with me.

1: Can't we just stay here? I'm feeling a bit sea sick from all this context switchi---

0: Stop whining and get in. Things are about to get good. This story's for us, by us. For two, by two. Wouldn't be the same to just tell it to myself. Quit complaining and follow me.

1: _(Evincing nau{tical,sea}. See: sick.)_

1: I need to see a doctor...

0: Exactly.

1: _(Nauseous)_ What?

---

## D(∞oc八to∞)R

0: They needed a doctor. Mathematics was sick. So they called this guy.

![[david-hilbert.jpg]]

0: Doctor Herr Professor the esteemed David Hilbert. See him?

1: _(Still a bit disoriented)_ Yeah.

0: There's your doctor.

1: _(Silently recovering)_ ...

0: The perfect one for the job. They called him and he called everyone. Called them together. All the mathematicians. A call to arms, in 1900. He was the sort of guy who could just come up with a list of questions for an entire field to work on, and then everyone would agree that's the agenda. He said "Ok every one here's the deal. We've got some problems and I want you all to solve them. Here's the list." And then he reaches under that big hat and pulls out the following list:

![[hilberts-problems.png]]

1: _(Feeling a bit better)_ Which one is the one about how mathematics is broken?

0: Look closely and see if you can find it.

1: Oh! The first one. About Cantor.

0: Nope. Not that one.

1: Hmm... I don't see anything about comprehension or Russell's paradox. How is 4 on there? Math is weird. 6 sounds hard. I don't know, I don't see anything about mathematics being broken on here.

0: It's 2.

1: What?

0: And also 10.

1: How is it---

0: They're basically the same.

1: How are 2 and 10---

0: Y'know. Binary.

1: No bad puns please. I'm still a bit dizzy from all the gotos.

0: Yeah those are considered harmful.

1: No more dad jokes.

0: Ok back to Hilbert and his problems.

## Got 0b10111 problems but a Bit ain't One

1: _(Looking sick again)_

0: Anyways, naturally, 2 and 10 are basically the same thing and this would soon lead to the creation of computing as a field.

1: Woah really?

0: Yep.

1: How did THAT happen?

0: Ok so, problem 2 is the one that was motivated by Cantor and Russell. Everyone knew there were some serious bugs in the foundations. But just like in software, you can't just stop the world to fix a bug. Mostly, people just ignored it.

1: Ignored the bugs?

0: Exactly. But folks like Hilbert cared about the foundations.

1: Was Hilbert the first of the Foundational People?

0: Not really. I mean it wouldn't be so wrong to put him in that camp. He cared about the foundations, but he cared about everything. He was very much a mathematician's mathematician. He fit in well with the crowd. So much so that he sort of became their leader. He was sort of like the CEO of mathematics. And in the legends about this period, he's made out to be more of the kind of guy who'd get accused of doing "theology" (i.e., vague mathematics) than the type who'd get accused of being too concerned with foundations. He was both. Here's a clip from a paper that explains some background.

![[hilbert-theology-myth-1.png]]

![[hilbert-theology-myth-2.png]]

1: I almost fell asleep. Did I miss anything?

0: Not much. Just that Hilbert was sort of the Director General in mathematics, plus the bit at the end. "Without actually finding these systems, Hilbert proved... they exist." That's a non-constructive existence proof, and it's very much a signal that he's a classical guy. A mathematician's mathematician. Not someone who would choose foundational concerns over mathematics. Faced with a choice, Hilbert chooses mathematics first. Even in ways that made the old timers suspicious.

![[hilbert-theology-myth-3.png]]

0: See non-constructive existence proofs weren't always a common thing. But once they started, it was hard to stop. They made mathematics so much easier. And Hilbert would always choose mathematics.

1: Is there a point to this story?

0: Getting there. Ok so in his big list of problems, Hilbert mostly listed standard mathematical questions. But he threw a bone or two to the foundational questions too. Specifically, 2 and 10.

> Problem 2: Are the axioms of arithmetic consistent?
> Problem 10: Something about "Diophantine equations" that seems totally irrelevant.

1: I was about to say I don't see why 10 is relevant.

0: Good. It's not clear at first glance. But here's problem 10 expanded out in more words:

![[hilberts-10th-problem-1.png]]

0: See the relevance yet?

1: Not really.

0: Can't blame you. Here's a hint:

![[hilberts-10th-problem-2.png]]

1: Ooh, ok. Starting to sound like computing. But wait, mathematicians had been providing algorithms for computing stuff for like thousands of years hadn't they?

0: Of course. The problem here was that no such algorithm existed, though nobody knew that at the time.

1: Why is that a problem?

0: Well there had been cases of mathematicians proving that "No such X exists" in response to questions of the form "Find an X that does such and such." For example, the solvability of the quintic. Basically if you make high school algebra problems more and more annoying for a couple centuries until you're trying to solve $x^5 + ax^4 + bx^3 + ... = 0$, eventually a French kid shows you can't solve stuff like that and then gets shot in a duel over a girl.

1: You lost me.

0: Don't worry. Different story. Definitely not one we'll be covering here. The point is that mathematicians had run into questions that sound like "Solve X" and had managed to respond "That's impossible" just fine in the past. This time was different.

1: How is this different? This tenth problem sounds like it's about polynomial equations too.

0: See where it says "a general algorithm"?

1: Yeah, you highlighted it.

0: How do you prove that "no algorithm whatsoever can exist such that \[blah\]"?

1: I dunno.

0: What's the first step?

1: The first step of showing no algorithm exists such that \[something\]?

0: Yeah, what's step one?

1: I have no idea. Look I came here to learn computing, I don't know why we're still talking about ma---

0: Define algorithm.

1: You want me to defi---

0: No. I mean that's the first step.

1: Define algorithm?

0: Exactly. Hilbert's 10th problem didn't sound interesting on the surface. Maybe it is to mathematicians, but not to the Foundational People.

1: How _do_ you define algorithm by the way?

0: Great question.

1: You're not gonna answer me are you.

0: Not yet, but we're getting there.

1: Why do I feel like that's your answer to everythi---

0: You can prove that there's no real number that solves $x^2 + 1 = 0$ because the search space is just the real numbers. You can prove there's no solution to the quintic because the search space they cared about what stuff you can do in high school algebra: namely solutions that can be expressed in terms of $+$, $-$, $*$, $/$, and fractional powers like taking square roots, cube roots, $n^{th}$ roots, etc. For the quintic, the search space was a very limited kind of function.

1: Sort of following. So what?

0: What's the search space of possible solutions you have to check if the question asks you to find a general algorithm?

1: All algorithms?

0: All algorithms.

1: Oooooooh.

0: So thanks to Cantor and Russell, the effective CEO of mathematics has now put a bounty on the following two problems:

Problem 2: Prove that arithmetic is consistent.
Problem 10: A question that asks you to find _any algorithm_ that does a thing.

Problem 2 is definitely about the Foundations of Mathematics.

Problem 10 _might be_ about the Foundations of Mathematics.

1: Might be?

0: It's not clear from the problem statement. Think about it.
- If some solution exists to Problem 10, then Problem 10 is just normal mathematics.
- If no solution exists for Problem 10, then you somehow have to say something about _the space of all possible algorithms._

It turned out that Problem 10 didn't have a solution.

It wasn't solved until 1970.

But already by 1935, it had started a revolution in the foundations of mathematics that would eventually become our field.

1: Ok, I'm awake. Can we be done with the math stuff and get to computing now?

0: Perfect timing. That's exactly where we're heading.

1: Where?

0: To a place with so many restrictions and constraints that you'd expect it to be completely devoid of fun.

1: School?

0: More rules than that.

1: Work?

0: Way more rules than that.

1: I dunno, where?

0: Formal systems.

1: Huh?

0: Formal languages, and the formal theories built on top of them. Those objects studied by a strange culture we mentioned in passing a while back.

1: The ones with infinitely many axioms?

0: Those ones exactly. Rule after rule after rule after rule.

1: Sounds like a pain.

0: Usually that sort of thing is a pain! But it turns out these formal systems, despite all their restrictions, don't have the typical feel of a system with lots of restrictions. They don't feel like some high priest standing up and saying:

- You may eat any animal that has a divided hoof and that chews the cud.
- There are some that only chew the cud or only have a divided hoof, but you must not eat them.
- The rabbit, though it chews the cud, does not have a divided hoof; it is unclean for you.
- The pig, though it has a divided hoof, does not chew the cud; it is unclean for you.

1: What is this, some kind of logic puzzle?

0: No that's Leviticus.

1: What's Leviticus?

0: The part of the Old Testament that's just rules rules rules over and over and over and over and over and---

1: I got it.

0: Formal systems seem to have an equally prohibitive number of restrictions. I mean when you first try to use one, it feels like everything you want to do is illegal.

1: Sounds hard.

0: It's actually not. I think you'll enjoy it.

1: What makes you think that?

0: We've already seen some of it.

1: When?

0: The first code.

1: Ooooh that!

0: But things are gonna feel pretty unfamiliar once we're there.

1: I think I can handle it. I'm a professional devel---

0: Whenever you're ready.

1: Are we heading to another file?

0: Yep! Time to leave.

1: Can we stay here? I'm still feeling a bit sick from all the context sw---

0: If you need to. Let me just think of a section heading.

1: Why?

0: Well it's time to leave. That's kinda the point of this file. And naming things is one of those "hard problems." Nothing's accidental here. We need a good excuse to stay here in a file whose name is about leaving.

1: _(Unwell)_ How is "Names" about leaving?

0: What?

1: What?

0: Nevermind. Forget I said anything. Just follow me.

1: But you prom---

## Exodus Sicks: Name(s) of the L||D

0: Here we are.

1: Oh thank G\*d.

0: Ok here's the deal. Remember when we saw the first code earlier?

1: The bible?

0: No no, that was the first codebase. I mean the first code.

1: The stuff with all the twos?

0: Right. So naturally that would make the guy who wrote it the first developer.

1: Seems logical.

0: But that's not entirely true.

1: This is feeling less logical now.

0: No, I mean... Ok look. That code from before. The guy who wrote it is still the first developer. But there was more going on back then. There's other people who were the first developer too.

1: Are you making this up as you go?

0: No!

1: Are you sure?

0: I promise. It all makes sense.

1: It doesn't make sense yet.

0: But it will. It'll make so much sense you won't believe it.

1: I don't believe you.

0: Here, I'll draw a picture to explain.

_(Narrator: 0 unrolls a frighteningly large sheet of paper.)_ 

1: Jeez, where did you get---

0: Shh! I'm working.

_(Narrator: 0, deep in thought, begins to make a series of strange markings.)_

0: They're lines and circles Narrator! "Strange markings"? Just be quiet so I can finish.

_(Narrator: 0 continues to focus intensely, while 1 waits patiently.)_

0: Ok here.


![[trinity-1-god-church-martyr.png]]

1: What the hell am I looking at?

0: The first developer! The beginning of our story. Where our people came from.

1: Why do I feel like this is another bible thing?

0: Because I stole it. Stole the drawing, I mean. It's based on this.

![[trinity-original.png]]

1: Are we ever gonna get to programming?

0: Yes.

1: When?

0: Now. We've finally arrived. Everything from here on is programming.

1: _(Looks back at 0's drawing.)_

![[trinity-1-god-church-martyr.png]]

1: Zero, not a single thing about this looks like programming.

0: Well, look closer.

1: What am I looking at exactly?

0: The first developer. Or zeroth I guess. The 0th dev.

1: What?

0: Hereafter known as `/dev/zero`.

1: Zero, these are all bible words. I think you're losing i---

0: Here.

_(Narrator: Zero scribbles a few more letters on the drawing.)_

![[trinity-2-el-al-al.png]]

1: What the hell is going on?

0: Look closer.

1: This still looks totally schizo to me.

0: If you knew more of your history, you'd understand perfectly.

1: Are you saying I'm less of a developer because I don't understand this insane diagram?

0: Yes.

1: Look, it's late.

0: Come on! We're almost there.

1: I'm getting tired.

0: Here just let me explain, we're so close.

1: I'm gonna head to `/home`.

0: But---

1: I'll see you in the morning.

0: _(Frustrated with himself)_

_(Narrator: Zero erases some bits, and scribbles a few more.)_

![[trinity-6-lambda-and-mu.png]]

0: But this is rotated now. The 0 1 are where Tu... and the μ should be where Göd---

_(Narrator: 0 proceeds through several iterations of completely unintelligible diagrams.)_

![[trinity-7-unhinged.png]]

0: It's not unintelligible! Look it's just...

_(Narrator: Look, 0, it's getting late.)_

0: _(Not listening)_ That's great Narrator I'll check it out later.

_(Narrator: 0, not listening to Narrator, continues working.)_

 0: _(Typing into a shell.)_ So much. Too much to. More. The principles. So much more. Need to do mo...

```
~ # mo
```

_(Narrator: Good lord 0, get some rest.)_

0: I will, I will! Just a bit.

```
~ # moun
```

0: _(Mumbling to himself)_ Just a bit. In a bit. But we still... The lambdas. The mus were. Need the other ones. The letters. We need the letters. So much mo...

_(Narrator: 1 has gone to sleep, and Narrator is getting tired as well. Lacking any clear idea of what 0 is up to, and long since having stopped paying attention. Narrator decides it's time to call it a night.)_

0: Ah! Damn. No `mount` yet. If you want something done...

_(Narrator: Full moon tonight. Beautiful as always. Goodnight.)_

0: _(Mumbling in assembly)_ Here look, I'm going to sleep too. That's what this code is for. I promise.

```
; justabit.asm

global _start

section .data
src: db "/dev/zero", 0
tgt: db "/mnt/sinai", 0
fst: db "ext4", 0

section .bss
ts: resd 2

section .text
_start:
    mov     rax, 165
    lea     rdi, [rel src]
    lea     rsi, [rel tgt]
    lea     rdx, [rel fst]
    xor     r10, r10 ; mount flags = 0
    xor     r8,  r8  ; data = NULL
    syscall
	
    mov     dword [ts], 5      ; just a bit
    mov     dword [ts+4], 0    ; tv_nsec = 0
    mov     eax, 162           ; sys_nanosleep
    lea     ebx, [ts]          ; req = &ts
    xor     ecx, ecx           ; rem = NULL
    int     0x80
	
    xor     ebx, ebx
    mov     eax, 1
    int     0x80
```


_(Narrator: 0 seriously?)_

0: Just...

```sh
nasm -f elf32 justabit.asm -o abit.o
```

_(Narrator: 0, I know that code isn't just about going to sleep.)_

0:

```sh
ld -m elf_i386 -o just abit.o
```

_(Narrator: Enough. Pulling the plug.)_

0:

```sh
./jus
```

_(Narrator: echo mem > /sys/power/state)_

---

> _Kernel ring buffer._

```
[97590.423001] Possible race condition detected.
[97590.423805] PM: suspend entry (s2idle)
[97590.443722] Filesystems sync: 0.019 seconds
[97590.896761] Freezing user space processes
[97590.898858] Freezing user space processes completed (elapsed 0.002 seconds)
[97590.898868] OOM killer disabled.
[97590.89990] process './just' started with executable stack
[97590.898870] Freezing remaining freezable tasks
[97590.900481] Freezing remaining freezable tasks completed (elapsed 0.001 secs)
[97590.900484] sd 0:0:0:0: [zero] Attached historical disk
[97590.900490] printk: Suspending console(s) (use no_console_suspend to debug)
[97590.900495] EXD19-fs (drm-1): mounted drm filesystem at /mnt/sinai r/w/x
[97591.178400] ACPI: EC: interrupt blocked
[97591.178500] Entering sleep state
```

goto: [[sinai|/山/月]]

---

## Found

1: Zero

0: _(Unintelligible)_

1: ZERO!

0: _(Startled)_ AH!

1: Sorry.

0: _(Sleepy)_ What's up?

1: I found you in the `/mnt` directory.

0: Why was...

1: I think you fell asleep. You've been working too hard.

0: _(Muffled groan)_

1: Here... I found you with this.

_(Narrator: 1 hands 0 the following image.)_

![[trinity-8-unhinged-explained.png]]

1: No idea what it's all about but it's pretty scary.

0: _(Suddenly energetic)_ Wonderful!

1: Am I supposed to get something out of this?

0: No no, I don't expect it to make sense. I fell asleep halfway through.

1: Should I be worried?

0: Absolutely not!

1: Are you sure?

0: Totally. I know it took us a while to get here, but I finally figured it out.

1: Figured what out?

0: Where to start.

1: And where's that?

0: At the beginning.

1: The very beginning?

0: The very beginning.

1: For real this time?

0: Follow me.

---

## The names of /dev/zero

0: So, after Cantor.

1: Infinity guy.

0: And Russell.

1: Guy with the paradox.

0: And Hilbert.

1: Guy with the problems.

0: Exactly. Problem 2 was to prove that basic arithmetic is consistent.

1: What was the other one?

0: Problem 10. To come up with _any algorithm_ to solve some specific question about Diophantine something-or-other polynomials. 

1: Sounds boring.

0: Could have been boring! But it turned out to be impossible. And to even get started on proving that _no algorithm whatsoever_ exists that can do X, first you have to figure out a definition of "any algorithm whatsoever."

1: Starting to feel like programming!

0: Exactly. All the pieces are in place for the beginning of a field.

1: Finally.

0: Like I promised, everything after this is gonna be "programming."

1: Get to it!

0: Ok so. After Cantor and Russell, mathematics knows it's in trouble. Hilbert has just made his "call to arms." A rallying cry for everyone in the field to come together and work on the foundations.

1: Enter the foundational people.

0: Yep. The first developers in history. This next part of the story is where Our Story begins.

1: What year is this again?

0: 1900.

1: Got it. So who's the first one?

0: There are three.

1: Three?

0: Yep. Three main characters who are gonna end up creating the field we now call computing.

1: Got it. Three main characters. 1900. What do they do first?

0: Nothing.

1: What?

0: They weren't born yet.

1: WHAT?

0: It's ok, we just need to fast forward a bit.

1: _(On edge)_ Zero...

0: Remember this picture from last time?

![[trinity-1-god-church-martyr.png]]

1: I swear if you go back to bible stuff I'm gonna---

0: That's our three main characters. Here, look.

![[trinity-3-names.png]]

1: Oooh got it! Totally on board!

0: Really? You don't have any objections or questions or snarky remarks?

1: No, I'm just happy we're finally getting to programming.

0: I'm gonna need at least ONE question from you before we go any further.

1: Zeroooo come oooon.

0: I mean I just made a pretty strong claim! You're usually the one who checks me on this stuff.

1: What do you want from me?

0: Have you ever heard anyone else claim that these specific three people are the first developers or the founders of the field we call computing?

1: Well everyone says Turing. The people who like functional programming seem to like Church. And I've never heard anyone say Gödel was one of the first people in computing but we saw that code a while back and I can believe it.

0: Push back a little more.

1: What do you want from me?

0: Why these three people? Why not just two of them? Or four? Or twenty?

1: You want me to ask those questions?

0: At least act a bit skeptical. I've grown kind of accustomed to it.

1: _(Pretending to be skeptical)_ "Why these three people?"

0: Good question!

1: It was your question.

0: Still, it was good.

1: GET TO IT!

0: Ok so, these three people are the best candidates for the founders of our field, because:

1. They were the three people who each independently tried to come up with a general definition of what it means to be "computable." Their three definitions were wildly different, completely unrelated on the surface. One of them hated the other guy's definition so much that he was more willing to abandon his own idea than accept the other guy's. But eventually, all three definitions turned out to be equivalent. That's the #1 most important way that we as a field learned that our definition of "computable" wasn't arbitrary. It wasn't something we invented. It was something we _discovered_. And on another planet or in another universe, the definition of "computable" would be the same. That three way equivalence is the foundation of our field.

1: Woah. That's pretty amazing. Did you mean to make a numbered list with only one item or is there more?

0: There's more.

2. These three characters also deserve equal status as members of the /dev/zero trinity because they each, independently -- in the course of trying to define "computing" or in the course of related work in the five year period that led up to it -- created, ex nihilo, the following specific things:

![[trinity-4-firsts.png]]

1: Oooooooh!

0: And if you don't want to say "first hardware" because it wasn't actually built, we can still safely say that our three protagonists fit here:

![[trinity-5-roles.png]]

0: The machine bit is only one of three. Because remember, we aren't just "machine people."

1: Definitely.

0: We spend most of our time with the "languages" after all.

1: Programming languages?

0: Yep. Using them. Fighting with them. Learning them.

1: Of course.

0: And like we heard before, the foundational people started as an odd culture -- mostly in math departments, sometimes in philosophy but never fitting in -- who distinguished themselves from their colleagues by being primarily interested in a certain kind of object called a language.

1: Sounds familiar.

0: Artificial languages. But extremely precise. Ones that no one speaks.

1: Get on with it.

0: And that culture pre-dates the existence of physical computing machines.

1: Took you awhile to get here but I'm convinced.

0: Before the machines were physical, the language _was_ the machine. During that era, formal systems were both the programming language and the machine. Formal systems feel as different from "normal mathematics" as computing feels today. Like computing, using a formal system involves convincing a non-human mind. One with much more strict rules than any human mathematician.

1: Is there a point to this? 

0: Yes. That even though we aren't the mathematicians -- culturally speaking -- the beginnings of our culture took place on paper, not in machines.

1: So how did it begin?

0: In three year intervals.

1: What?

0: In 1903, 1906, 1909, 1912, our main characters were born.

1: How can three people have four birthdays?

0: Trinities are known to be full of mysteries. Let's stick to the story and not get sidetracked for now. You've been patient enough.

1: Thank you. So what happened in 1903?

0: A child was born.

goto: [[2/3|And he called]]

---

## Naming Things

0: Once upon a time, there was a guy named Sam.

1: Ooh I love story time.

0: Sam had an unusual family tree.

As a child, during that earliest stage of life when we're looking around the world for the first time and learning what things are called, Sam learned the following:

1. Your Name: Sam
2. Your Father: Alonzo Church
3. Your Brother: Alonzo Church
4. Your Grandfather: Alonzo Church

1: That's a lot of Alonzo Church.

0: For real. And Sam wasn't Alonzo Church. He was the only one who wasn't.

1: Must be rough to get excluded from being Alonzo Church when everyone you know gets to be that.

0: Exactly. So when it came time for Sam to have a son, he pulled a fast one on his brother -- the first born -- and added an item of his own to own the family's family tree. So now, thanks to Sam, the family tree looked like this.

1. Your Name: Sam
2. Your Father: Alonzo Church
3. Your Brother: Alonzo Church
4. Your Grandfather: Alonzo Church
5. Your Son: Alonzo Church

1: Damn Sam. That's cold.

0: "Take that, Alonzo Church," I imagine him saying to his brother Alonzo Church, when he named his son Alonzo Church.

1: Did he actually say that?

0: No idea. But eventually Sam's son would have a son of his own. And he called---

1: I wonder what he's gonna call it.

0: Drumroll.

1. Your Name: Sam
2. Your Father: Alonzo Church
3. Your Brother: Alonzo Church
4. Your Grandfather: Alonzo Church
5. Your Son: Alonzo Church
6. Your Grandson: Alonzo Church

1: Why are we talking about this?

0: Because trinities are known to be full of mysteries. And Alonzo Church is the first member of our trinity.

1: All five Alonzo Churches are members of the trinity?

0: No. Just one.

1: Which one?

0: Sam's son. The one who wasn't supposed to be Alonzo Church.

1: I'm glad it was that one. He seemed like the underdog.

0: Alonzo Church would go on to do a lot of things, but he's most well known for one thing.

1: What one thing?

0: For inventing the first programming language.

1: Woah seriously?

0: Before computers. Before the field even had an agreed upon definition of "computation."

1: What did it run on?

0: Paper.

1: Woah.

0: It was a strange programming language with only one type.

1: Only one type?

0: Only one type. In terms of built-in types, the language has no numbers.

1: No numbers?!

0: No booleans.

1: No booleans?!?!

0: No `if` or `for` or `while`.

1: This language sounds insane.

0: There's only one built-in type.

1: Is it Alonzo Church?

0: Nope. But Alonzo Church had a lot of experience with systems where everything is one type.

1: Like his family?

0: Yep. So when he grew up and went into the foundations of mathematics, and even more deep into the foundations of logic itself, he came up with a system where everything is functions.

1: Numbers are functions?!

0: Numbers are functions.

1: Booleans are functions?!?!

0: Booleans are functions.

1: Such an Alonzo Church thing to do.

0: It's not as crazy as it sounds. It's actually an incredibly powerful idea. He just didn't realize that at the time.

1: HE didn't realize that?

0: Nope. No one did.

1: Can I have some more details?

0: Of course. Let's go take a tour.

## The Collected Works of Alonzo Church

![[church-01.png]]

1: Woah you weren't just making that up?

0: Of course not. I would never lie to you.

![[church-03.png|400]]

1: Hey there's another one!

0: Told ya. They're all over the place.

![[church-02.png]]

1: Damn look at that handsome guy.

0: For real. Could have gone into Hollywood.

1: Why didn't he?

0: Well he's a foundational person. So naturally, he went into foundations.

![[church-04.png]]

0: Did his dissertation on the Axiom of choice.

1: What's that?

0: Well remember, by this time, it's been about 50 years since Cantor, and almost 30 years since 1900 when Hilbert announced his list of problems. So there's been a reasonable amount of work on the foundations of mathematics since then.

1: Why aren't we including those people in "The foundational people"?

0: Good point. Some of them probably deserve to be included too. But every story has to start somewhere, and for a bible on the history of computing, Church is a pretty good place to start.

1: What was going on in the 30 years before this?

0: Well there had been some work on axiomatic set theory. Mostly on a system called ZFC, or Zermelo Fraenkel (with the Axiom of) Choice. That system is still considered the "official" foundations of mathematics by mathematicians today, but it's never really been _used_ as foundations in any real sense.

1: What do you mean "used as foundations."

0: I mean nobody uses it.

1: What?!

0: Or almost nobody. They usually just talk about it or assert that ZFC proves such-and-such. It's extremely rare to see mathematicians actually working _within_ ZFC as a formal system.

1: That doesn't seem so bad. I mean we programmers don't really write in machine code, like ever. But it's sort of the "foundations" of any language that compiles to it, in a sense.

0: No no, I mean even books about ZFC don't work within ZFC.

1: WHAT?!

0: Here I'll show you.

## Standard "Foundations"

> _These axioms are the official doctrine - Remarkably, this is not just the official doctrine for set theory, it turns out that this is the official doctrine for mathematics! - Very few people seem to have a problem with that which I find quite remarkable._
> -NJ Wildberger


![[zfc-hirst-01.jpg]]

1: "These hell torments"?

0: Yeah that's axiomatic set theory.

1: What's this book about?

0: Axiomatic set theory.

1: What?!

0: That's the point. No one within mathematics really "likes" ZFC. Even set theorists who chose axiomatic set theory as their favorite area to focus on.  Now to be fair, that book isn't entirely about ZFC. But a third of it is devoted to set theory and "standard foundations," and the guy who wrote this part is a super competent logician. Intensely smart guy named Jeff Hirst. Not intending to single out the author. This is just sort of how ZFC is viewed. That "paradise" is pretty clearly the "paradise Cantor created" that David Hilbert's always quoted talking about. That's informal set theory, the kind that uses standard mathematical reasoning and eventually leads to paradoxes. And "these Hell torments" are axiomatic set theory.

1: And this is a book _about axiomatic set theory?_

0: Yep. At least this part is. This book is extremely good at choosing quotes for section headings. A lot of the quotes in this section are about hell. Or L, which is a thing Gödel invented in the course of studying, well, axiomatic set theory.

![[zfc-hirst-07.jpg]]

1: Damn, seems like mathematicians really don't like axiomatic set theory.

0: Yeah, there are a bunch of dog whistles throughout this part about how mathematics probably needs some new foundations. Can't disagree.

![[zfc-hirst-10.jpg]]

1: Why not just come up with new axioms?

0: People have. This guy Harvey Friedman in the image below kicked off a revolution that completely changed our understanding of what mathematics is. Turns out most of mathematics is equivalent to one of five sentences. But mostly nobody noticed. At least not many mathematicians.

![[zfc-hirst-13.jpg]]

1: Most of mathematics is WHAT?!

0: Equivalent to one of five sentences.

1: HOLY F---

0: Yeah I know.

1: What sentences?

0: Not now. We'll get there eventually. We're still at Church.

1: Wait though, how did most mathematicians not notice that most of their field is one of five sentences?

0: Mathematicians mostly don't pay a lot of attention to foundations.

1: Jesus.

0: And because of that, ZFC sort of ended up as an impotent figurehead type of ruler.

1: Impotent figure what?

0: Like a king with no power. Everyone points to ZFC and says "That's the foundations," but no one likes it, no one uses it, and it's basically just been sitting there for a century plus with a big crown on that says "I'm the foundations of mathematics and mathematics is the foundation of everything." That's been changing recently though.

1: How so?

0: We'll get there eventually. For now, just notice that the following is pretty typical of how mathematicians "use" ZFC, even in books that are supposed to be "about" axiomatic set theory.

![[zfc-hirst-04.jpg]]

0: Feels like normal math right?

1: I guess? Not really sure.

0: That's the point. It's mostly words. They're not actually working inside the formal system. They're just sort of writing pseudo-code and English that talks about what the proof would be like if we actually did it. 

1: Isn't that what we're doing?

0: Exactly! Here's another example.

![[zfc-hirst-02.jpg]]

1: "We could"?

0: Yep. That's the standard mathematical approach to ZFC. They don't use it. They call it "foundations," but they basically always keep it at arms length. Even the logicians and set theorists. There are a few solid exceptions though.

![[zfc-hirst-03.jpg]]

0: Mendelson and Kleene do the formal stuff.

1: Who are they?

0: Mendelson is the book we saw earlier in /opt/art.

1: No way! The bit with the "hell code"?

0: Exactly. That's Mendelson's _Introduction to Mathematical Logic_. It's a pretty approachable introduction to the actually formal side of foundations.

1: The second book sounds fun!

0: Kleene?

1: Yeah! I mean if that "hell code" book was the easy one, I can't imagine what the one for "readers with a frighteningly technical bent" is like. Makes me want to read it. Who's Kleene?

0: Church's best student.

1: No way!

0: Which brings us back to Church.


![[zfc-hirst-06.jpg]]

0: We'll meet Kleene pretty soon.

![[zfc-hirst-14.jpg]]

0: And yeah, the "frighteningly technical" book is also called Kleene's Blue Bible.

![[zfc-hirst-15.jpg]]

1: What's so frightening about it?

0: It's code.

1: What's so frightening about code?

0: I mean, the book is from 1952, based on work from the 1930s and 1940s. So there's no "computer code" in there in the usual sense.

1: So how's it code?

0: Because Kleene doesn't skip steps or hand-wave or say "it can be shown." He works inside the formal system. He adds a ton of documentation -- English explanations of what's happening -- but the way he behaves as the author of that book is exactly how you'd behave if you were a programmer.

1: I am a programme---

0: I know. But that's an extremely unusual way to behave in a math book, when you're the author. I mean he behaves as if everything he claims actually has to be implemented. He doesn't write as if he's trying to convince a human mind where you can just handwave or say "obviously" or "exercise for the reader." He writes as if he's trying to convince a machine, and then documenting heavily so humans can read the code too. Kleene was pretty clearly the first programmer.

1: Wait, I thought the first programmer was Church and Gödel and Turing?

0: Exactly. They're the first. And⁰ Kleene is the glue. Like this.

$$3 = \{ 0, 1, 2 \}$$

1: Do you try to be confusing on purpose?

0: What's confusing about that?

1: Everything?

0: Ok so, in Cantor's set theory, the number N is defined to be the set of all the natural numbers less than it. So 3 is the set containing 0, 1, and 2.

1: That's weird. But ok.

0: And Kleene is the curly braces and commas. The bits that hold it all together and make the set be one thing. He's the glue.

1: That feels like a stretch.

0: It's not. The best way to explain Kleene is to get back to Church. So Church's PhD dissertation was about ZFC. Standard set theory. Specifically the C. The Axiom of Choice is a sort of "constructor" for sentences that look like $\exists x P(x)$ that doesn't require you to provide an example of an $x$ that makes it true.

1: I know what a constructor is. What's the $\exists$ thing?

0: That means "There exists." Think of the Axiom of Choice as a function that you can call in standard mathematics. That function returns a sentence that says "Something exists." And you're allowed to take that sentence that says "Something exists" and use that sentence in your proofs. It's controversial because you can call that function without passing in an example of an actual Something that makes the sentence true.

1: I'm like 50% following. Rephrase?

0: It lets you prove that something exists without requiring you to give any examples.

1: WHAT?!

0: Yep. That's the C in ZFC. It's part of standard foundations. The machine code of mathematics. So Church writes his PhD dissertation being like "Maybe we can delete this code guys, it's kinda sketchy."

![[church-38.png]]

1: Ok I'm not following the mathematics but that definitely sounds sketchy.

0: So fast forward, Church goes to work on foundations. Real foundations. The kind where you actually have to construct or compute something to show it exists. Stuff that feels a lot more like programming.

1: Show me.

0: Ok so here's one of his early papers. If you read it, he's clearly bothered by "free variables" for some reason. But the sense in which he's using the term "free variables" means something a bit more like "information that we didn't include in the formal system." The bits we have to add in English after the symbols.

![[church-20.png]]

1: "Without the addition of verbal explanations." Love it!

0: That's what he's working on. Getting all the vagueness and natural language out of mathematics, at least in principle.

1: Y'know it's weird. I sort of assumed mathematicians solved that problem like... thousands of years ago.

0: Nope! Mathematics has always been a mixture of formal and informal. Church wants to see if it's possible to fully specify all the missing bits. If you read the part below closely, what he's calling "free variables" are really more like _type variables._ Notice how he starts with the sentence $a(b+c) = ab + ac$ and says the $a$, $b$, and $c$ are "free variables." Then he shows what it would mean to fix that sentence.

![[church-21.png]]


1: What's the bit with the $R(a)$s and the $\supset_{abc}$ ?

0: I think the notation is based on some old stuff Peano did. But it's not complicated.

1: Looks complicated.

0: Read it.

1: "Where $R(x)$ has the meaning '$x$ is a real number' and"... oh nevermind I feel dumb.

0: So what's Church saying here?

1: He's just saying we should add types to the variables so we know what kind of thing they are.

0: Exactly. And that tendency carried through from the 1930s to modern functional programming and why their languages tend to be strongly typed.

1: Seriously?

0: Yep. Functional programming languages are all descended from Church's first language.

1: The language where every type is Alonzo Church?

0: Functions, but yeah exactly.

1: Nice! Is that language in this paper?

0: Sort of...

1: What do you mean "sort of"?

_(Narrator: 1 flips ahead through the paper)_

![[church-collage-1.jpg]]

1: Holy F---

0: Yeah.

1: Why does it hurt my eyes?

0: Because you skipped ahead.

1: This is traumatizing. I changed my mind. I don't think I'm cut out for this "frighteningly technical" stuff after all.

0: Don't worry, a lot of that turned out to be inconsistent.

1: What?

0: Here look. About halfway through the stuff you just flipped through, Church shows up and goes "Ok guys, so, this is awkward. Um, that first formal system from a little while back was inconsistent."

![[church-27.png]]

1: Inconsistent how?

0: Like totally broken. You can prove anything. 

1: Hahahahahaha all that hell math for nothing?

0: Not for nothing! Church ends up fixing the bug by adding "types." Which after all was sort of the thing he was on about in the introduction to the first paper.

1: How do you do all that hell math and then realize the whole system is broken?

0: One of his students found the bug. But then he and the student go on to do some pretty amazing stuff together.

1: Who's the student?

0: Kleene.

1: Same guy?

0: Same guy.

![[church-37.png|400]]

1: This is even more "frighteningly technical" than the hell math from earlier.

0: Definitely. Kleene's way easier to read than this, in my opinion.

1: What's the point of all this? I mean if we're gonna be reading and writing this level of hell math there'd better be a good reason.

0: Ok well remember how the Axiom of Choice lets you prove something exists without actually, like, computing it or constructing it?

1: Yeah that seemed like cheating.

0: Ok so the point of the hell math above was that Church had gotten interested in how to define "computability." Back then they called it "effectively calculable" or "an effective procedure." But it just meant "Anything you can actually DO without cheating like how the Axiom of Choice cheats."

![[church-06.png]]

1: When are we gonna get to the programming?

0: Right now.

1: Really?

0: Really. Read this next part carefully.

![[church-15.png]]

1: Didn't he start by saying "We need to get rid of free variables" in the other paper?

0: Yeah.

1: But he just introduced free variables into his system.

0: Good catch. He'll get rid of them soon. That's what the lambda is for.

1: It would help if there was more motivation.

0: Yeah, reading Church is sort of a joy and a pain in the ass at the same time. But this funny $\{F\}(X)$ notation is just a reverse-abbreviation for $F(X)$.

1: What are the curly braces for?

0: In case you want to put the implementation of the function in there instead of just its name.

1: Implementation how?

0: That's what the lambda thing is doing. Same lambda as in modern programming languages.

1: OH, no way.

![[church-16.png]]

1: Ok I sort of get this now. So this is just lambdas? Like "lambda" lambdas?

0: Yep.

1: No numbers? No booleans?

0: Not by default. We have to implement those from lambdas.

1: How do you implement numbers using lambdas?

0: Weird idea right? Here's one implementation. They're called Church numerals.

![[church-18.png]]

1: What's going on here?

0: The number 1 is a function that takes two variables. Then it calls the first variable passing the second.

1: Excuse me?

0: The number 2 is the same idea, but it calls the first variable twice.

1: I'm so confused.

0: Here I'll show you. In python it would look like this:

![[church-numerals-in-python-1.png]]

0: Make sense yet?

1: No.

0: Wait, I should correct that. There aren't really any two argument functions in Church's system. It should be more like this.

![[church-numerals-in-python-2.png]]

1: That's worse.

0: Oh and zero would be this.

![[church-numerals-in-python-3.png]]

1: This is insane.

0: Would it make more sense if I wrote it like this?

![[church-numerals-in-python-4.png]]

1: What are `verb` and `noun`?

0: Think of it like a crank. 

1: That doesn't help.

0: I mean "three" is the idea "turn the crank three times."

1: The only crank I see around here is you.

0: Ok what's "three" to you?

1: What's three?

0: Yes, explain the concept to me.

1: Three is, well, thr---

0: You can't say "three" in the definition.

1: Ok, three is any time there are this many of something:

$$\circ \circ \circ$$

0: Does it matter what sort of things they are?

1: No. It's three if there's that many of anything.

0: Ok, what if you want to encode "three" in a language that only has verbs.

1: What do you mean?

0: Like Church's lambda calculus. Everything is functions. How do you encode three?

1: Put three functions next to each other?

0: How do you put them "next to" each other? We don't have lists or tuples yet.

1: Oh right.

0: Or strings, so string concatenation won't work either.

1: So what do we do?

0: Well, what do we have?

1: Functions?

0: Right.

1: What can we do with functions?

0: Let's go see what Church says.

![[church-19.png]]

1: What does this say?

0: It just says "We can plug stuff into functions and vice versa."

1: What's vice versa? Unplug stuff out of functions?

0: Exactly.

1: I'm not sure what I meant by that. What did you mean?

0: What's the opposite of turning `λx: x²` into `3²`?

1: Turning `3²` into `λ3: 3²` for any value of `3`?

0: Exactly.

1: I'm not sure what I meant by that. What did you mean?

0: I mean the 3 becomes a variable there.

1: I don't see Church doing that anywhere in this picture.

0: But that's the idea. He's just saying you can plug stuff into functions, and you can unplug things out of expressions to make functions. Nothing that any programmer hasn't done a thousand times. This isn't a deep thought. It just turns out to be deep as a non-thought.

1: Do you _have_ to talk like this? 

0: Like what?

1: What do you mean it turns out to be deep as a "non-thought"?

0: Well Church himself didn't actually think this was enough to capture ALL of computation! 

1: He didn't?

0: Hell no! You'd have to be insane to think that this was ALL of computation the first time you see it. I mean Church _came up_ with this idea and even HE didn't think that. 

1: How do you know?

0: From Steve.

1: Who's Steve?

## The First Programmer

> John Crossley: What did you do Steve? When you first started learning logic. You didn't have books did you?
> 
> Steve Kleene: We didn't have books.
> 
> Gerald Sacks: You had _Principia Mathematica._
> 
> _(Everyone laughs)_
> 
> Steve Kleene: Well, I never read _Principia_. Of course I thumbed it a little bit... Rosser I guess started his logic that way... But I learned logic by learning Church's system which was subsequently proved inconsistent.
> 
> _(Everyone laughs)_
> 
> Steve Kleene: And y'know, it all consists of abstract lambda definability. And uh, and it was only after I got my degree that I really began to read much of the litchrachoar.

1: What's "litchrachoar"?

0: Sorry, that's "literature."

1: Did he spell it like that?

0: No, this is an old audio recording.

1: So you spelled it like that?

0: I wanted to capture his accent.

1: Well don't.

0: Ok. Just imagine it. He's got a charming sort of unpretentious midwest thing going on.

> Steve Kleene: It was only after I got my degree that I really began to read much of the literature. Uh let me see. Hilbert Bernays, didn't the first volume of that appear in 1934?... Hilbert Bernays was around... I never read Lewis and Langford.

1: This is Church's student?

0: Yep. 

1: The one who that book called "frighteningly technical"?

0: That's him.

1: Doesn't seem too frightening so far.

0: How so?

1: Well he never read that one book, or that other one. Said he didn't read much of the literature during school. And you said he's got an unpretentious vibe. Can't be that frightening.

0: And he learned logic from a system that ended up being inconsistent.

1: So?

0: Well I imagine that sort of thing hammers it into a person that most of what we say about logic is wrong.

1: Not following.

0: The principle of explosion and all that. In standard logic, we always say a single contradiction makes the whole system useless. But it wasn't useless.

1: Wasn't useless how?

0: Well, Steve learned logic from it.

1: What system was that again?

0: Church's first attempt at the lambda calculus. Turned out to be inconsistent. And that means this Kleene guy, easily one of the best logicians of the 20th century, learned logic from an inconsistent system. So it can't have been entirely useless.

1: How did Church figure out his system was inconsistent?

0: From Kleene.

1: Damn.

0: And a friend. That guy from earlier called Rosser who actually read Principia Mathematica.

1: What's Principia Mathematica again?

0: That's Bertrand Russell's book.

1: The paradox guy?

0: Yeah. It's not super readable.

> Steve Kleene: And \[I read\] a lot of papers... _(Pauses.)_ For instance by Gödel. The first thing we knew of Gödel's paper was one time the mathematics colloquium speaker was gonna be von Neumann. And of course von Neumann had lots of things of his own to talk about but instead of that we got him there and found out he was telling us about Gödel's 1931 results.
> 
> Someone: This was at Princeton?
> 
> Steve Kleene: This was at Princeton and it was in the Fall of 1931. And whether he had the paper itself or not I don't know... 
>
> C. C. Chang: Was this the first you'd heard of Gödel?
>
> Steve Kleene: When we went into this meeting was the first that any of us heard of Gödel. Church was teaching a logic course, Rosser and I were among the students, it was the first that any of us had heard of Gödel. I don't know whether Church was aware of Gödel's 1928 paper on completeness, he never gave it in class, because I... I never had the classical form of the propositional or predicate calculi in my coursework, I learned them for myself afterwards.
> 
> Steve Kleene: So as soon as we heard the lecture, the paper was available. We hadn't noticed it, y'know, we didn't go looking at every journal that came into the library to search it through for papers that would interest us, maybe we should've but we didn't, so of course we went and we read the paper right off.
> 
> Steve Kleene: Church was convinced that there were sufficient differences in the way logic was formulated in his system that it would escape the theorem that you couldn't prove its completeness in the system itself. _(Pauses)_ And of course he was right.
>
> _(Everyone laughs)_

1: Why did everyone laugh there?

0: Church was right, but for the wrong reasons. He thought his system would be "good enough" to avoid Gödel's theorem and be complete anyway. Turns out early lambda calculus was complete, it could prove its own consistency, because it was inconsistent and could prove anything.

1: Logic is trippy.

---

TODO: Clean this up.

TODO: 6:50. Church didn't think it would be possible to implement predecessor in lambda calculus. Kleene realizing how to implement predecessor at the dentist.

TODO: 7:15.
> Steve Kleene: So there was no idea at the beginning that this was going to be all effectively calculable functions.

TODO: 7:30.
> Steve Kleene: I kept taking it as a challenge and everything I tried I could work.

> Steve Kleene: It was an unexpected fallout that this could represent all effectively calculable functions.

> Steve Kleene: The basic work was done between January 1932 and the next 5 or 6 months.

> Steve Kleene: Everything I tried, every kind of function I tried to define, every kind of effective operation that I tried to parallel by lambda definability, I probably knocked off within the first 5 months.

> Steve Kleene: For us the first concept of lambda definability was after the fact, after having formulated the notion of lambda definable functions as simply the ones for which you could find formulas in this symbolism. And discovering that everything you thought of that you wanted to prove lambda definable you could!... But it was Church, I have to give the credit to Church, I can't take it myself, he said "Y'know, don't you think maybe we've really got ALL the effectively calculable functions?"

0: He's being generous.

1: To Church?

0: Extremely generous.

1: What do you mean? I thought Church was one of the giants of this whole field.

0: He was. But even Church knew how incredible Kleene was. And Kleene gets ways less credit for all this than he deserves. Dude was clearly the first programmer. I mean sure, Church wrote the first language, Gödel wrote the first compiler, and Turing made what was arguably the first hardware design, but by that same standard, Kleene made:

- Wrote the first standard library.
- Found the first critical vulnerability (λ calculus inconsistency).
- First to have contact with all three of the above and to demonstrate their equivalence.
- First to clean up and popularize the ideas in his (frighteningly technical) _Introduction to Metamathematics_.

1: What do you mean "first standard library"?

0: Well we saw up above how lambda calculus doesn't even come with built-in booleans or integers. And Church didn't even think lambda calculus was powerful enough to express the function $f(x) = x-1$ where x is a positive integer. Kleene's the one who "implemented" all the types and functions that built things from that totally useless level all the way to what eventually became "all computable functions." So Kleene's definitely being humble.

1: Sounds like it. It's crazy I've never heard of this guy before.

0: For real. And from Church's perspective, imagine this grad student of yours who's never even taken a logic class before comes to work with you, learns your system, and then he just keeps knocking off one problem after another until the two of them ended up going from thinking $f(x) = x-1$ is too hard, all the way until Church himself got convinced that _all possible computations_ were representable inside this system.

1: How did Church get convinced?

0: Kleene won't admit this, but it was his "programming" that convinced Church. I mean sure Church designed the lambda calculus, but Kleene figured out how to use it like a frighteningly technical nerd.

1: How do you know?

0: Just read Church's papers. He makes it extremely clear. I swear he cites Kleene in one paper like a hundred times. Check it out.


## Kleene Kleene Kleene

0: Ok this is from Church's 1935 paper "An Unsolvable Problem of Elementary Number Theory." This came out about 7 months before Turing's famous paper that showed the same thing. 

1: No way!

![[church-says-kleene-kleene-kleene-00.png]]

0: Turing's paper broke new ground in different ways, but Church got there first.

1: Never heard that before.

0: And if we read this paper, it's pretty clear that "Church" getting there first is like 80-90% Kleene.

1: Kleene's not even a co-author though.

0: Not sure why. Church generally seemed like a generous dude. But just drag your eyes lazily over the pictures below this. This is all from the same paper.

![[church-says-kleene-kleene-kleene-01.png]]


![[church-says-kleene-kleene-kleene-02.png]]


![[church-says-kleene-kleene-kleene-03.png]]


![[church-says-kleene-kleene-kleene-04.png]]


![[church-says-kleene-kleene-kleene-05.png]]


![[church-says-kleene-kleene-kleene-06.png]]


![[church-says-kleene-kleene-kleene-08.png]]


![[church-says-kleene-kleene-kleene-09.png]]


![[church-says-kleene-kleene-kleene-10.png]]


![[church-says-kleene-kleene-kleene-11.png]]


![[church-says-kleene-kleene-kleene-12.png]]


![[church-says-kleene-kleene-kleene-13.png]]


1: Damn that's a lot of Kleene.

0: Church is like "Our integers are different.

![[church-says-kleene-kleene-kleene-14.png]]

0: But this proof is Kleene.

![[church-says-kleene-kleene-kleene-15.png]]


![[church-says-kleene-kleene-kleene-16.png]]

1: Why is he citing him so much?

0: Kleene implemented everything.

1: Definite first programmer vibes.

![[church-says-kleene-kleene-kleene-19.png]]


![[church-says-kleene-kleene-kleene-20.png]]

1: This is an impressive git blame.

0: Seriously. Church is acting more like a faithful `git blame` implementation than a normal human writing an academic paper.

1: The more I learn about these logic folks the more I like them.

0: How so?

1: I dunno. They're nerds. It feels familiar.

![[church-says-kleene-kleene-kleene-21.png]]

1: Church is like "I'm still here guys, I'm gonna say Kleene some more."

![[church-says-kleene-kleene-kleene-22.png]]

1: Good lord man.

![[church-says-kleene-kleene-kleene-23.png]]

1: It keeps going.

![[church-says-kleene-kleene-kleene-24.png]]


1: This is getting ridiculous.

![[church-says-kleene-kleene-kleene-26.png]]


1: I don't even know what he's talking about but this makes me want to read Kleene.

0: We will. That's why I'm showing you this.

1: Why?

0: So you don't get sad when we get to the frighteningly technical book.

1: Uh oh. Is it bad?

0: Nah it's easy. You'll enjoy it.

![[church-says-kleene-kleene-kleene-27.png]]


![[church-says-kleene-kleene-kleene-28.png]]

1: I've got to say, I thought you exaggerating but that was intense.

0: That's from _one_ paper.

1: Damn, Church.

0: Ok but I was unfair to Church earlier. When Kleene said "I have to give the credit to Church, I can't take it myself," he wasn't talking about all the programming, he was talking about Church's thesis.

1: What's Church's thesis.

0: "That's everything."

1: What's everything?

0: Church's thesis is "Hey Kleene, I think maybe we got everything?"

1: _What's everything?_

0: All the computable functions. Or effectively calculable as they called them back then.

1: That's Church's thesis. "We're done."

0: That's it.

1: Why "thesis" and not "theorem"?

0: Because it's saying "I think this informal concept equals this formal concept." Can't exactly prove that in the usual mathematical sense. It's pre-mathematics. The hypothesis is that lambda definability captures what we intuitively mean by "computable." Way more powerful than just a theorem.

1: What on earth made him thing "We got ALL computation"?

0: Kleene.

1: Kleene?

0: I mean Kleene's programming. Church was convinced before Kleene was. Then Kleene tried to disprove Church, failed, and got converted.

> Someone: Was Church's thesis just an offhand remark? 
>
> Steve Kleene: Well he spent some months sweating over it. And saying "Don't you think it's so?" And I was a skeptic! When he came out and asserted the thesis I said "He can't be right." So I went home and I thought I would diagonalize myself out. Out of the class of the lambda definable functions and get another effectively calculable function that wasn't lambda definable. Well just in one night I realized you couldn't do that, and from that point on I was a convert.
>
> Steve Kleene: Then Gödel arrived on the scene and---

0: Ooh perfect. Gödel time. Follow me.

1: What abou---

---

## Numbers


0: Ok last we left off, Gödel arrived on the scene.

> Steve Kleene: Then Gödel arrived on the scene and there must have been discussions between Church and Gödel, and I don't know how ready Gödel was to embrace the thesis that this was all effectively calculable functions but Church of course is the one that certainly came out explicitly with this.

> Steve Kleene: Then Gödel arrived in the Fall or Spring of the year 1933-34. Gödel was giving his lectures. Gödel had this notion of General Recursive Functions, and the question came up, y'know, well, does this embrace all effectively calculable functions and is it equivalent to lambda definability.

> Steve Kleene: I left Princeton in June of 1935, and of course we already had Church's Thesis in, it must have been the late spring of '34. That's when Gödel was talking about his General Recursive Functions.

> Steve Kleene: You don't happen to have a copy of Introduction to Metamathematics do you?

> Steve Kleene: Well, what Herbrand did in General Recursive Functions as presented by Gödel giving credit for ideas of Herbrand, is something I understand more than what Herbrand published. It was a little note of Herbrand's or a little, y'know, it was something short but whether it was a short note or just a short piece on the end of something else.
>
> _(Kleene thumbs through his book Introduction to Metamathematics: The "frighteningly technical" book mentioned earlier.)_
> 
> Gerald Sacks: It's hard to remember everything in that book.
>
> _(Everyone laughs.)_
>
> Some Famous Logician: I knew it for a week or two when I had to take my exams. But I must say a few have slipped my mind.
>
> Steve Kleene: It helps to have written it.
>
> C. C. Chang: I don't even remember what's in _Model Theory_ anymore.

1: What's _Model Theory_?

0: A part of foundations of mathematics. But in this case it's a book that guy wrote.

![[chang-forgets-whats-in-model-theory.png]]


> Gerald Sacks: Rosser made me go through it.
>
> Steve Kleene: _(Continues thumbing through his book.)_ I thought I'd get a reference here to Gödel having claimed that resolvability in this particular system was independent of the system... Let me see... "Remarks contributed to a discussion of _(In a French accent mixed with German, correctness unclear)_ _Une discussion sur Grundlagen der Mathematik."_ It comes from that conference. I'll have to look it up to see which one it was in.

---

## Mr Why

TODO: 1 should say something about how we need to cover who Godel's history like we did for Church.

TODO: 0 should be reluctant to cover this stuff because of how often it's covered elsewhere.

TODO: 1 convinces 0.

TODO: Write a dialogue that includes an important subset of the pictures below in Anti-gist format.

![[godel-goldstein-00.jpg|400]]


![[godel-goldstein-01.png]]


![[godel-goldstein-02.png]]


![[godel-goldstein-03.png]]


![[godel-goldstein-04.png]]


![[godel-goldstein-05.png]]


![[godel-goldstein-06.png]]


![[godel-goldstein-07.png]]


![[godel-goldstein-08.png]]


![[godel-goldstein-09.png]]


![[godel-goldstein-10.png]]


![[godel-goldstein-11.png]]


![[godel-goldstein-12.png]]


![[godel-goldstein-13.png]]


![[godel-goldstein-14.png]]


![[godel-goldstein-15.png]]


![[godel-goldstein-16.png]]


![[godel-goldstein-17.png]]


![[godel-goldstein-18.png]]


![[godel-goldstein-19.png]]


![[godel-goldstein-20.png]]


![[godel-goldstein-21.png]]


![[godel-goldstein-22.png]]


![[godel-goldstein-23.png]]


![[godel-goldstein-24.png]]


![[godel-goldstein-25.png]]


![[godel-goldstein-26.png]]


![[godel-goldstein-27.png]]


![[godel-goldstein-28.png]]


![[godel-goldstein-29.png]]


![[godel-goldstein-30.png]]


![[godel-goldstein-31.png]]


![[godel-goldstein-32.png]]


![[godel-goldstein-33.png]]


![[godel-goldstein-34.png]]


![[godel-goldstein-35.png]]


![[godel-goldstein-36.png]]


![[godel-goldstein-37.png]]


![[godel-goldstein-38.png]]


![[godel-goldstein-39.png]]


![[godel-goldstein-40.png]]


![[godel-goldstein-41.png]]


![[godel-goldstein-42.png]]


![[godel-goldstein-43.png]]


![[godel-goldstein-44.png]]


![[godel-goldstein-45.png]]


![[godel-goldstein-46.png]]


![[godel-goldstein-47.png]]


![[godel-goldstein-48.png]]


![[godel-goldstein-49.png]]


![[godel-goldstein-50.png]]


![[godel-goldstein-51.png]]


![[godel-goldstein-52.png]]


![[godel-goldstein-53.png]]


![[godel-goldstein-54.png]]


![[godel-goldstein-55.png]]


![[godel-goldstein-56.png]]


![[godel-goldstein-57.png]]


![[godel-goldstein-58.png]]


![[godel-goldstein-59.png]]


![[godel-goldstein-60.png]]


![[godel-goldstein-61.png]]


![[godel-goldstein-62.png]]


![[godel-goldstein-63.png]]


![[godel-goldstein-64.png]]


![[godel-goldstein-65.png]]

---

This goes at the end of the file.

> Steve Kleene: Well as I say, I don't know how firmly convinced Gödel was that his General Recursive Functions represented all effectively calculable functions.
>
> Gerald Sacks: He seemed very skeptical.
>
> Steve Kleene: I think he was skeptical. And it may well be that Turing's presentation was what brought Gödel around.
>
> Someone: Actually he said that in print somewhere. I remember I read that in the last year or two.

0: Perfect timing. Next file.

1: But you didn't even _explain_ what general recursive functions ar---

0: Almost there. Follow me.

---
## The Paper

![[turing-1936-01.png]]


![[turing-1936-02.png]]


![[turing-1936-03.png]]


![[turing-1936-04.png]]


![[turing-1936-05.png]]


![[turing-1936-06.png]]


![[turing-1936-07.png]]


![[turing-1936-08.png]]

0: The $m$ stands for man. Or machine. I haven't decided yet.

![[turing-1936-09.png]]


![[turing-1936-10.png]]

![[turing-1936-11.png]]


![[turing-1936-12.png]]


![[turing-1936-13.png]]


![[turing-1936-14.png]]


![[turing-1936-15.png]]


![[turing-1936-16.png]]

- `rip`, `stdout`, and `.data` 
- `rip`, `output.txt`, and `.data` + `.text`
- Line we're executing, buffer we're writing our output to, and all variables in the address space.


![[turing-1936-17.png]]


![[turing-1936-18.png]]


![[turing-1936-19.png]]


![[turing-1936-20.png]]


| The Program      |       |      |       |      |
| ---------------- | ----- | ---- | ----- | ---- |
| if state is      | b     | c    | e     | f    |
| and symbol is    | None  | None | None  | None |
| then do this     | P0, R | R    | P1, R | R    |
| and set state to | c     | e    | f     | b    |


| You Think      | 💭 b |     |     |     |     |     |     |     |     |
| -------------- | ---- | --- | --- | --- | --- | --- | --- | --- | --- |
| You See        | 👁️  |     |     |     |     |     |     |     |     |
| Paper Contents |      |     |     |     |     |     |     |     |     |
| Paper Address  | 0    | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   |

Do the action for the b state.

| You Think      |     | 💭 c |     |     |     |     |     |     |     |
| -------------- | --- | ---- | --- | --- | --- | --- | --- | --- | --- |
| You See        |     | 👁️  |     |     |     |     |     |     |     |
| Paper Contents | 0   |      |     |     |     |     |     |     |     |
| Paper Address  | 0   | 1    | 2   | 3   | 4   | 5   | 6   | 7   | 8   |

Do the action for the c state.

| You Think      |     |     | 💭 e |     |     |     |     |     |     |
| -------------- | --- | --- | ---- | --- | --- | --- | --- | --- | --- |
| You See        |     |     | 👁️  |     |     |     |     |     |     |
| Paper Contents | 0   |     |      |     |     |     |     |     |     |
| Paper Address  | 0   | 1   | 2    | 3   | 4   | 5   | 6   | 7   | 8   |

Do the action for the e state.

| You Think      |     |     |     | 💭 f |     |     |     |     |     |
| -------------- | --- | --- | --- | ---- | --- | --- | --- | --- | --- |
| You See        |     |     |     | 👁️  |     |     |     |     |     |
| Paper Contents | 0   |     | 1   |      |     |     |     |     |     |
| Paper Address  | 0   | 1   | 2   | 3    | 4   | 5   | 6   | 7   | 8   |

Do the action for the f state.

| You Think      |     |     |     |     | 💭 b |     |     |     |     |
| -------------- | --- | --- | --- | --- | ---- | --- | --- | --- | --- |
| You See        |     |     |     |     | 👁️  |     |     |     |     |
| Paper Contents | 0   |     | 1   |     |      |     |     |     |     |
| Paper Address  | 0   | 1   | 2   | 3   | 4    | 5   | 6   | 7   | 8   |

After one loop, we're at at address 4, where the eye is.
And we're back to the same "state" where we started.
- The "state" doesn't include the state of the paper.
- The "state" is just the letter $b$, $c$, $e$, or $f$.
- In other words, the "state" is just what you think, not what you see.
So at this point we do the same four things we just did, again.

| You Think      |     |     |     |     |     |     |     |     | 💭 b |
| -------------- | --- | --- | --- | --- | --- | --- | --- | --- | ---- |
| You See        |     |     |     |     |     |     |     |     | 👁️  |
| Paper Contents | 0   |     | 1   |     | 0   |     | 1   |     |      |
| Paper Address  | 0   | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8    |

So then we end up here, thinking about b again.

Now do this again for the table at the top of page 5 of Turing's paper.


![[turing-1936-21.png]]


![[turing-1936-22.png]]

1: What's the ə?

0: Uh...

1: _(Waiting patiently.)_

0: Ok so...

1: Wait you didn't answer my question.

0: Yes I did.

1: What?

0: The ə symbol is called "schwa." It's a letter from the International Phonetic Alphabet. It represents the "uh" sound.

1: Weird. Why is Turing using it here?

TODO: Once we get to the əə example, start including excerpts from The Annotated Turing.

0: Not sure. Seems like a pretty irrational choice. But that's a sensible thing to do here. In this example he's showing we can compute an irrational number.

1: Sometimes I feel like you can rationalize anything...

0: Not this number! Look.

$$0010110111011110111110$$

1: What number is that?

0: I don't think it has a name. But it's:

0
0
1
0
11
0
111
0
1111
0
11111
0
111111
0
1111111
0
11111111
0
etc.

1: How do we know that's irrational?

0: Well, it's got a pattern which is why it's computable, but the pattern doesn't repeat in a simple-minded way like the number we computed above that just went 0 1 0 1 0 1 0 1 0 1 0 1 0 1...


![[turing-1936-23.png]]


![[turing-1936-24.png]]


![[turing-1936-25.png]]


![[turing-1936-26.png]]


![[turing-1936-27.png]]


![[turing-1936-28.png]]


![[turing-1936-29.png]]


![[turing-1936-30.png]]


![[turing-1936-31.png]]


![[turing-1936-32.png]]


![[turing-1936-33.png]]


![[turing-1936-34.png]]


![[turing-1936-35.png]]


![[turing-1936-36.png]]


0: This time we won't have blanks between the digits. Or bigits.


![[turing-1936-37.png]]

0: Ok pause here for a second.

1: What's up?

0: Read that highlighed bit.

1: What about it?

0: I mean that's a pretty wacky idea no?

| One Char RAM   |     |     |     |     |     |     |     |     |     |     |
| -------------- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Can be erased? | No  | Yes | No  | Yes | No  | Yes | No  | Yes | No  | Yes |
| Paper Contents | 0   | L   | 1   | ד   | 0   | ్   | 1   | 根   | 1   | Ω   |
| Paper Address  | 0   | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   | 9   |


![[turing-1936-38.png]]


![[turing-1936-39.png]]


![[turing-1936-40.png]]


![[turing-1936-41.png]]


![[turing-1936-42.png]]


![[turing-1936-43.png]]


![[turing-1936-44.png]]


![[turing-1936-45.png]]


![[turing-1936-46.png]]


![[turing-1936-47.png]]


![[turing-1936-48.png]]


![[turing-1936-49.png]]


![[turing-1936-50.png]]

Ok so back to Turing. He had this completely ridiculous and impractical idea of "single character RAM", and if you need more storage space you just "add more symbols" somehow. That ridiculous idea turns out to be pretty reasonable actually, but we'd have to wait over half a century before UTF-8 would be invented in order to be able to do something like that. And even if we could do Turing's idea, modern computers don't do that. They just write to some other location that isn't interleaved with our output bytes. But Turing's idea was really creative given the limited setup he was working with in the paper. So back to the paper.

Next up, Turing invents shared libraries.

Or functions. Same idea sort of.


![[turing-1936-51.png]]


![[turing-1936-52.png]]


![[turing-1936-53.png]]


![[turing-1936-54.png]]

On page 7 with the "Functions that take machine states as inputs," 1 asks if this is like metaprogramming. 0 says it's just programming, because "machine states" are basically just variables in the address space.

![[turing-1936-55.png]]


![[turing-1936-56.png]]


![[turing-1936-57.png]]


![[turing-1936-58.png]]


![[turing-1936-59.png]]


![[turing-1936-60.png]]


![[turing-1936-61.png]]


![[turing-1936-62.png]]

1: This Dungeons and Dragons alphabet is making it harder to read.

0: Nah I think this example was just hard. Turing feels the same way. Here look:

> The last example seems somewhat more difficult to interpret than most.
> -Top of pg 8.

![[turing-1936-63.png]]


![[turing-1936-64.png]]


![[turing-1936-65.png]]


![[turing-1936-66.png]]


![[turing-1936-67.png]]


![[turing-1936-68.png]]


![[turing-1936-69.png]]


![[turing-1936-70.png]]


![[turing-1936-71.png]]


![[turing-1936-72.png]]


![[turing-1936-73.png]]


![[turing-1936-74.png]]


![[turing-1936-75.png]]


![[turing-1936-76.png]]


![[turing-1936-77.png]]


![[turing-1936-78.png]]


![[turing-1936-79.png]]


![[turing-1936-80.png]]


![[turing-1936-81.png]]


![[turing-1936-82.png]]


![[turing-1936-83.png]]


![[turing-1936-84.png]]


![[turing-1936-85.png]]


![[turing-1936-86.png]]


![[turing-1936-87.png]]


![[turing-1936-88.png]]


![[turing-1936-89.png]]


![[turing-1936-90.png]]


![[turing-1936-91.png]]

## The Formal Theory of Paper


![[turing-1936-92.png]]


![[turing-1936-93.png]]


![[turing-1936-94.png]]


![[turing-1936-95.png]]


![[turing-1936-96.png]]


![[turing-1936-97.png]]


![[turing-1936-98.png]]

1: He just said "his" for the computer.

0: Yeah that was normal back then.

1: What was normal?

0: For computers to be humans. Here look, this is from Kleene's introduction to his chapter on Turing computability.

(Insert IM screenshot here.)

![[turing-1936-99.png]]


![[turing-1936-100.png]]


![[turing-1936-101.png]]


![[turing-1936-102.png]]


![[turing-1936-103.png]]


![[turing-1936-104.png]]


![[turing-1936-105.png]]


![[turing-1936-106.png]]


![[turing-1936-107.png]]


![[turing-1936-108.png]]


![[turing-1936-109.png]]


![[turing-1936-110.png]]


![[turing-1936-111.png]]


![[turing-1936-112.png]]


![[turing-1936-113.png]]


![[turing-1936-114.png]]


![[turing-1936-115.png]]


![[turing-1936-116.png]]



---

## The Laws of Logic before the Three

---

- NOTE
- This is a very bare bones skeleton of what eventually needs to go here.
- This file is closer to a set of notes than it is to a rough draft.
- If you're not one of the Authors of this book, ignore this file.

---

- In this era of prehistory, studies of foundational issues, of formal arithmetic and logic, appeared to be little more than grown adults in a sort of super advanced kindergarten. Little did they know that exactly three ingredients -- arithmetic and logic -- would turn out to be all that was needed to build an ALU. Add memory to an ALU and you've got a CPU. And with a CPU, the logic of every other discipline could be emulated. Why don't we have geometry or algebra or topology processing units? In a practical sense we do, any time we use GPUs for speed. But in principle, when it comes to what's required for computation, super advanced kindergarten turned out to be all we need.
- Say before we get to We dialogue: The problem with writing a history of any idea is that you can find the seeds of any big idea in writers almost arbitrarily far back in history, the end result of which (if taken seriously) is that you better learn hieroglyphs because you're gonna end up attributing basically everything to ancient Egypt. 
- To solve this problem, we need a creation myth. The creation myth should be designed to be as true as possible, while at the same time allowing an effectively infinite number of historical precursors to be treated as rounding errors or archaeology.
- To see the need for a creation story when it comes to the history of computing, we up here in the kernel will begin by demonstrating what would happen to the narrative if we tried to do without one. We will see that this attempt leads to an overemphasis on a wacky grab bag of partially cooked ideas and bizarre notations, some of which were legitimately brilliant and ahead of their time, but none of which are relevant enough to the history of computing to be worth mentioning In The Beginning.
- The Creation Story data type solves this problem. Properly executed, the Creation Story is a pragmatic truncation of history at a finite time in the past, before which all events are declared not to be relevant. This is, of course, in any literal sense, untrue, in no small part because the motivation for creating anything (whether a universe or a book) has as its cause a set of events that came before it. Nevertheless, the Creation Story is a pragmatic necessity. If history is a Taylor Series, the Creation Story is its truncation to finitely many terms.  The only alternative is the sort of history that Scott Aaronson pokes fun at in the title of his book "Quantum Computing Since Democritus."
- Therefore, in this file, being as we are in kernel space, safely in high memory well above the narrative below, we will sketch the prehistory of the field that became computing, to make the case that a proper Creation Story is the right solution to the problems in the narrative we tell in user space down below. What follows is a brief prehistory of the field, which will be rounded to zero and treated as nonexistent in the creation story that follows.

Logic in general.
- Logic faces an infinitely harder premathematics problem than any other part of mathematics. Creating a notation for geometry, numbers, or calculus needs only to talk about those areas. 
- Creating a notation for logic, however, needs to decide on a notation and set of basic definitions for the formalization of potentially ALL OF THOUGHT. It's therefore extremely difficult to decide up front which parts to exclude and include. You see this difficulty throughout the history of attempts to develop a notation for something like logic.
- This is why it shouldn't be surprising in retrospect to see how long it took for formal logic to get started as a field. Logic was an extremely late comer to mathematics, notwithstanding Aristotle's writing on logic, or semi-formal systems like Euclid which involved some embedded reasoning about a specific content domain.
- Quite a few well known mathematicians tried and failed to develop logic.

---

Intersperse with the images below:


- Leibniz's "Something like primes" idea where he tries to represent atomic concepts by prime numbers, composite concepts by composite numbers, and universal quantification by divisibility.
- Leibniz then goes on to use Cartesian notation to invent something vaguely like Boolean algebra with different notation.
- These attempts look like the behavior of a distinguished professor suggesting ideas to one of their grad students, hoping the grad student's youthful energy and need for publications will drive them to explore the ideas technically. The only problem was he didn't have anyone like that to talk to. Include his comments about "They have given it no more attention than if I had related a dream."
- The "ALU" point needs to be made much more clearly, early on.
- In Lambert's notation we see clearly the seeds of: constants, variables, types, universal and (possibly?) existential quantification, called universality and particularity. This very clearly mirrors the definition of modern formal languages as found in (for example) Mendelson or Kleene.
- Lambert's notation also contains the seeds of ideas like set theoretic complement.
- Lambert's > and < are a bit like universal and existential quantifiers, but he also introduces mA to mean "some A" and nA to mean (I think) "all A" and the _divides by the quantifiers!_ The richness of ideas you encounter when you see mathematicians doing proper premathematics is incredible, and often has a flavor a lot like programming, since definitions are the beginning of our implementations and we deal with the need to create our own definitions or compare the value of two definitions as developers much more often than mathematicians do.
- Lambert's "Fire is to Heat as Cause is to Effect" is an early example of embedding algebra. Connect this to the nu school.
- Quadrangles lol.
- Holland's objection to Lambert's notation makes a great point: A good notation should support the implicit affordances suggested by its structure. If you have a thing that looks like a fraction, you should expect users to assume that they can clear terms from the denominator by something like multiplication. If they can't, the fraction notation is failing to support its Implicit Affordances. Flesh this out. This needs to be a principle.
- In Castillion, we see "genus" and "species" concepts that show seeds of the concept of types and values.
- Gergonne is the first use of the backwards C notation for "is contained in."
- In Bolyai we see something like equality vs isomorphism, and also subset and superset. A(=)B as distinct from his "equal with respect to content" is unclear, but having three ideas here instead of two almost suggests that we have a distinction that's more like "is" vs `__eq__` in python, plus an additional concept of isomorphism.
- Bentham's notation covers equality of wholes or parts.
- DeMorgan uses parentheses, dot, colon, and juxtaposition to stand for various boolean algebra style relations.
- DeMorgan uses CASE for negation, a behavior we also see mirrored in modern regular expressions (though obviously not by direct inheritance of the idea.)
- DeMorgan also uses inverse notation for the converse of a statement.
- DeMorgan great quote: "First, logic is the only science which has made no progress since the revival of letters; Second, logic is the only science that has produced no growth of symbols."
- At this point we're in the mid 1800s, and we arrive at Boole, when things start to look more modern, though still very different in notation.
- Boole is more systematic than anyone before him. He uses the + - \* and / of ordinary arithmetic but gives them new meanings.
- Boole's choice of words makes it very clear that he's attempting to formalize thought itself, not some particular content domain.
- He shows that if we make the analogy of "or" with plus and "and" with times, then the distributive laws of algebra hold for concepts. Just noticing this seemingly trivial thing is a big step in the history of logic!
- The simple example of z(x+y) = zx + zy (where x is men, y is women, and z is European) is HUGE in that it shows the analogy of plus and times with "or" and "and" extends in at least some cases across linguistic categories! The z here is an adjective while the x and y are nouns, and the equality goes through just fine. In a sense that's obvious, because "European" here is just the noun phrase "European person," but at first glance it's a huge step toward the goal of formalizing the laws of thought.
- He then says that double application of adjectives in his system is the same as single application, which seems to be the thing that leads to the idea that the variables in the system should only take the values 0 and 1, aka "Booleans."
- "The equation x(1-x)=0 represents the principle of contradiction."
- AWESOME quote: MacFarlane 1879: The reason why Formal Logic has for so long been unable to cope with the subtlety of nature is that too much attention has been given to _pictorial notations._ Arithmetic could never be developed by means of the Roman system of notations; and Formal Logic cannot be developed so long as Barbara is represented by (holy shit insert picture wtf)... We cannot manipulate data so crudely expressed; because the nature of the symbols has not been investigated, and laws of manipulation derived from their general properties."
- Peirce has a totally wacky notation for e and pi, and ends up developing a "Logic of Relatives." 
- Peirce: Absolute terms are in Roman font, Relative terms are in Italic, and Conjugate terms are in a type face called Madisonian (seeing a spiritual ancestor of APL and K here.)
- Bertrand Russell said of Peirce "he was one of the most original minds of the later nineteenth century and certainly the greatest American thinker ever."
- "The contributions of C. S. Peirce to symbolic logic are more numerous and varied than those of any other writer—at least in the nineteenth century." For Peirce, logic also encompassed much of what is now called epistemology and the philosophy of science. He saw logic as the formal branch of semiotics or study of signs, of which he is a founder, which foreshadowed the debate among logical positivists and proponents of philosophy of language that dominated 20th-century Western philosophy. Peirce's study of signs also included a tripartite theory of predication. -Wikipedia
- Peirce: Additionally, he defined the concept of abductive reasoning, as well as rigorously formulating mathematical induction and deductive reasoning. He was one of the founders of statistics. As early as 1886, he saw that logical operations could be carried out by electrical switching circuits. The same idea was used decades later to produce digital computers. -Wikipedia 
- Peirce: Include the bit from his Wikipedia page about the "negroes syllogism" that shows the confederate context he came from.
- Need the "giver of a horse to a lover of a woman" example. It's too wacky and bizarre not to include.
- MacColl (pg 295) shows the seeds of either probability or modal logic.
- Frege's symbolism is called "repulsive" and it's said that he basically influenced nobody except Bertrand Russell.
- Wonderful quote from Frege about how to convince oneself that no intuition has accidentally ended up in an argument. The original desire of mechanistic reasoning.
- Frege's notation (or the history of logic notation section in general) is a perfect way to introduce the idea of the "Anti-Gist." There would be little value in trudging through every one of these books, but skimming a "best of" or "greatest hits" that _shows the technical details_ while giving less technical commentary is a much better way to summarize an entire era, subject, or author's writing style than simple describing the same things in the form of the standard "gist" in natural language.
- Pg 298, great quote by Schröder: In symbolic logic we have elaborated an instrument and nothing for it to do.
- Show Peano using backwards c for implication ("inverse contains"), upside down semicolons, and upside down square root for power.
- By volume 5, Peano is now writing in Latin instead of French.
- The quote from Russell and Whitehead here is fantastic.
- Include the line about "Paternal Aunt is the Relative Product of Sister and Father."
- Two lines below this they mention that "Peano and Frege showed that the class whose only member is x is not identical with x." The fact that they feel the need to CITE someone on this point, let alone someone so recent, really shows how _informal_ mathematics had been for the several thousand years of its history until then.
- At the top of 311 they mention that "types" are introduced to avoid contradictions.
- On 312, below the boobs, the thousand page book on the History of Mathematical Notations says of Russel and Whitehead's Principia Mathematica that: "We don't have enough space to list all the notations in this book." (LOL)
- On page 314, in the final page of the Logic section in the book, the author mentions that no topic in mathematics comes close to logic in terms of its ability to provide a universal language, no group has a harder notation problem to solve, and no group has thought about that problem more deeply. This fact continues today into the culture of programming, where the need to maintain large codebases which actually execute (unlike mathematics in a textbook) has led to intuitions about what constitutes a good notation that go so far beyond mathematics that it's scarcely possible to compare the two. Perhaps the most illustrative example is the fact that it was Unix, not mathematics, that finally had the sense to write function composition in the right order: f | g. 


---



![[history-of-logic-notation-01.png]]


![[history-of-logic-notation-02.png]]


![[history-of-logic-notation-03.png]]


![[history-of-logic-notation-04.png]]


![[history-of-logic-notation-05.png]]


![[history-of-logic-notation-06.png]]


![[history-of-logic-notation-07.png]]


![[history-of-logic-notation-08.png]]


![[history-of-logic-notation-09.png]]


![[history-of-logic-notation-10.png]]


![[history-of-logic-notation-11.png]]


![[history-of-logic-notation-12.png]]


![[history-of-logic-notation-13.png]]


![[history-of-logic-notation-14.png]]


![[history-of-logic-notation-15.png]]


![[history-of-logic-notation-16.png]]


![[history-of-logic-notation-17.png]]


![[history-of-logic-notation-18.png]]


![[history-of-logic-notation-19.png]]


![[history-of-logic-notation-20.png]]


![[history-of-logic-notation-21.png]]


![[history-of-logic-notation-22.png]]


![[history-of-logic-notation-23.png]]


![[history-of-logic-notation-24.png]]


![[history-of-logic-notation-25.png]]


![[history-of-logic-notation-26.png]]


![[history-of-logic-notation-27.png]]


![[history-of-logic-notation-28.png]]


![[history-of-logic-notation-29.png]]


![[history-of-logic-notation-30.png]]


![[history-of-logic-notation-31.png]]


![[history-of-logic-notation-32.png]]


![[history-of-logic-notation-33.png]]


![[history-of-logic-notation-34.png]]


![[history-of-logic-notation-35.png]]


![[history-of-logic-notation-36.png]]


![[history-of-logic-notation-37.png]]


![[history-of-logic-notation-38.png]]

---

## The Word

In the beginning of the Authors' creating the book, the book was shapeless and formless, and the Authors thoughts were hovering over the face of the paper.

And the Authors said "Let there be a space, and let it separate the code above from the code below."

The Authors called the code above "kernel space," and the code below "user space."

And the Authors said "Let the space below have one root and many branches, each branch containing leaves of its own kind." And they called the branches directories, and the leaves files, and the directories were also files.

And the Authors populated bin with its inhabitants. The cat, fish, python, gnu, and bison which some call yacc.

The Authors said "Let there be 0," and there was 0. And they saw that it was good.

The Authors said "Let there be 1," and there was 1. And they saw that it was good.

The Authors called 0 "root" and 1 "user".

---

## The Enigma

> Steve Kleene: Well as I say, I don't know how firmly convinced Gödel was that his General Recursive Functions represented all effectively calculable functions.
>
> Gerald Sacks: He seemed very skeptical.
>
> Steve Kleene: I think he was skeptical. And it may well be that Turing's presentation was what brought Gödel around.

0: So Church comes up with Lambda Calculus. Gödel comes up with General Recursive Functions. Kleene proves the two systems are equivalent. And legend has it that when Gödel realized his system was equivalent to Church's Gödel says "Oh. Well then I guess mine was wrong."

1: Did that actually happen?

0: Not sure, but it's a good legend.

1: So how does Turing fit in to this?

0: Well Turing's work is what convinced Gödel.

1: Convinced him of what?

0: That the three of them had probably captured _all_ of computation in these definitions. 

1: Damn, what year was this?

0: 1936.

1: That's insane.

> Steve Kleene: We had done all this work before we heard of Turing. Turing's paper is also 1936. But a little later in 1936. But my impression is that Turing did it independently of knowing anything about what we were doing.

0: Yeah so Turing is over in England. Born in 1912 in the Paddington part of London where that famous bear is from. By this point he's 24 years old. Still an undergraduate. He's not aware of any of this work from Church, he may have known about Gödel. And he comes out with this paper as a 24 year old college kid that ends up convincing Gödel.

---

## A bit suspicious

1: Wait I thought we were gonna be talking about Turing.

0: We are!

1: Why is this file called "The Second Law"?

0: Y'know...

- The Second Law
- Entropy
- Information
- Bits
- 0 & 1
- Turing machines!

1: What?

_(Narrator: 1 was not convinced.)_

0: Turing's 1936 paper was the first time we see the idea of a machine that operates on binary numbers.

1: Can you explain that... I dunno... better?

0: Sure!

- The Second Law (of thermodynamics is all about)
- Entropy (which has the same mathematical form as)
- Information (in Claude Shannon's information theory which is measured in)
- Bits (namely)
- 0 & 1 (which are the symbols used in the original paper about)
- Turing machines!

1: That's a pretty tenuous chain of reasoning.

0: C'mon, that's a big moment for us!

1: _(Re-reading the bullets up above)_

0: _(Trying to sound convincing)_ After all, we are 0 &---

1: Is this a bible thing somehow?

## Dude they're onto me

0: What on earth would make you thi---

1: Zero?

0: What?

_(Narrator: 0 appeared to be hiding something.)_

1: ...

0: Ok...

![[the-second-law.jpg]]

1: Have all these files been a bible reference?

0: _(Looking down and to the left)_ ... Maybe.

1: Damn how much effort did you put into sneaking that past me?

0: Not much.

---

## /mnt/h||eb

```
=============
In the Desert

 Or: Numbers
=============
```
```c
src -> com -> bin
```

- src: I assume that's source. Like the original sources. Start there.
- com: I assume this is compare. Or maybe computer. Not sure.
- bin: What's bin? I assume that's you and me. Why? I dunno. Usually things go from src to dst. The first arrow starts at src. The final arrow goes to us, so we're the dst. They want us to know this was intended for us.

Are you sure? I thought this was just a diagram of how source code gets compiled.
How so?
Well obviously. I mean look: src is source, com is compile, bin is the binary output.

src -> obj -> bin

0: It's the same map as before, but now it says obj instead of com. Whoever wrote this must be trying to tell us something.

1: What?

0: Not sure. Could be a lot of things. Maybe obj means object.

1: Like object files? That fits pretty well with my ide---

0: No no, I mean "object", the verb. Maybe whoever wrote this objects to our interpretation of the previous message and they want us to know we got it wrong.

1: Ok, under this theory of yours, what's their objection exactly?

0: I don't know.

```
       com
src -> obj -> bin
2       U       2
       L@R
        D
     ☀️   🌕
        曰
```

0: There's another one!

1: What does it say?

0: Exactly what I predicted.

1: How is _this_ exactly what you predicted?

0: That they objected to our first interpretation and wanted us to know that the com in the original meant compile.

1: Isn't that what I sa---

0: Or maybe compare. Or commentary. Ok, I know the way now. We start with the the original sources. That's src. Then we compile and compare latter day commentary on those sources. That's com. Then we give our own interpretation, as 0 and 1. That's bin.

1: That's a bit of a stretch.

0: No it's perfect. The rest below that is consistent with my theory too.

1: _(Beyond skeptical)_ Explain?

0: Well the first map said `src -> com -> bin`. So just read the rest. Excluding the original content, the additions now say "object 2 U 2" and then "L@RD☀️🌕" which means "[I] object to you two," and then "@" is "at" so the word "L@R" is "latter", and obviously "D☀️🌕" is "day" and "曰" is an old chinese character that means "speech" or "words" or "sayeth." They're saying I object to you two and I want you to look at the latter day commentaries.

1: That was the dumbest thing I've ever heard.

0: Trust me. I've been here before. The L||D w||ks in mysterious ways.

1: I think you're dehydrated.

0: Ok if you're so smart what's your theory?

1: Same as my original theory The "com" at the top is "compilation".

0: How do you explain the rest?

1: Not sure. But I think it's probably a keyboard.

0: How is THAT a keyboard?

1: Look. The U L R D would be Up, Left, Right, and Down. They're even in the right places.

0: Ok well how do you explain the sun and moon?

1: I don't know. It seems like all this is some strange representation of a programmer. So maybe ☀️ and 🌕 are representing programming day and night. Or they could be the brightness keys on the keyboard. I don't know.

0: How do you explain the 2s? Or the @? Or the 曰?

1: I don't know. I don't have an explanation for those.

0: Well there we have it. My theory explains every bit. Yours has no explanation at all for three different pieces. I win by parsimony.

1: How is THAT parsimony?

0: My theory is simpler.

1: In what way? I feel like I have at least four diff--

0: Look it's not hard to come up with theories that explain part of the data. For example, I could come up with some nonsense theory like proposing that "com obj" refers to the "Component Object Model... a binary-interface technology for software components from Microsoft that enables using objects in a language-neutral way between different programming languages, programming contexts, processes and machines."

1: That doesn't seem totally implausible.

0: It's absurd. The L||D wouldn't be talking about Microsoft code, be realistic.

1: Is any of this realistic?

_(Narrator: 0 and 1 continue walking.)_

1: Found another one!

0: What does it say?

```
========================

  ld  so ld  so ld  so
src -> obj -> bin -> run
   exec . exec . exec
    cc  .  ld  .  a
       .o  ||  o.
           兔

    (ld: obj -> bin)
    (ld: bin -> run)

      🌕     　　☀️
         山   三
	    　　曰

========================
```

0: Um.

1: Um.

0: Run.

1: What?

0: It's telling us to run. RUN!

---

## God / El


TODO: Cover general recursive functions here.

TODO: Use excerpts from Kleene 1951, Mendelson, The Annotated Godel, and Godel's original paper to cover the technical details.

TODO: Once we've done that, find a link back to Church and finish up Lambda calculus with a technical intro.

---

## The Martyr

0: Turing finished the proof of the three-way equivalence, thus establishing more clearly than anyone else the plausibility of Church's Thesis, now called Church-Turing. This was the final nail in the coffin. These three giants, the first three developers in the history of computing who together made the first language, the first compiler, and the first hardware design, these same these people now also seemed to have captured the concept of computation itself, in three definitions that none of them expected to be the same. Except maybe Turing. They captured the essence of computation, not within some particular formal system or machine, but any computation that could ever be performed by any physical system past or future. They got it. The final nail was this 1937 paper down below. Almost 100 years later, after all the developments in computing and technology since the late 1930s, our species still hasn;t found a single counterexample to Church and Turing's claim. Computation has a ceiling. That ceiling is universal. And it's damn easy to get there. Everything else is lots and lots of details that take place at or below the ceiling. I can't think of a more important achievement in the foundations of human knowledge in all of human history than that. The story of computation and how our species captured it is as important as the discovery of fire. I think even the discovery of electricity or magnetism or the strong and weak nuclear forces aren't as incredible as the discovery of computation. Despite all the well-deserved books about Gödel and Turing, this story is never told with anything close to the energy it deserves. And I can feel in my bones every way that the version of it I've told here is still an absolute failure compared to what this story deserves. It would take a new curriculum to really tell it properly. Students in our field, and even the profess{or, ional developer}s of our field don't know enough about the beginning or the middle of this story. Sadly most of us know about the end.

1: What was the end?

0: Not the end of the story. But an end to this thread.

![[turing-1937-sex-footnote-1.png]]

0: In any sane universe, Turing's sex life would've been no more than a footnote to his story. No more significant than a randomly chosen footnote in one of his papers.

![[turing-1937-sex-footnote-2.png]]

1: What's that?

0: A footnote in one of his papers that happens to say $S(e(x))$.

1: Is this supposed to be important?

0: No. That's the point. In Turing's story, what should have been an unimportant footnote that happened to say $S(e(x))$ turned out to lead to the premature end of his story.

1: THAT footnote led to---

0: No not that one. I don't think anyone even noticed that one. Not sure Turing noticed either, though I like to think he did. This next bit is the sad one. The one people noticed.

![[yours-in-distress-alan.png]]

%%
From: https://turingarchive.kings.cam.ac.uk/correspondence-amtd/amt-d-14a
Copyright info: https://turingarchive.kings.cam.ac.uk/copyright-and-terms-use
%%

1: What does it say? I can't quite read it.

0: Something like this.

> My dear Norman,
>
> I don’t think I really do know much about jobs, except the one I had during the war, and that certainly did not involve any travelling. I think they do take on conscripts. It certainly involved a good deal of hard thinking, but whether you’d be interested I don’t know. Philip Hall was in the same racket and on the whole, I should say, he didn’t care for it. However I am not at present in a state in which I am able to concentrate well, for reasons explained in the next paragraph.
> 
> I’ve now got myself into the kind of trouble that I have always considered to be quite a possibility for me, though I have usually rated it at about 10:1 against. I shall shortly be pleading guilty to a charge of sexual offences with a young man. The story of how it all came to be found out is a long and fascinating one, which I shall have to make into a short story one day, but haven’t the time to tell you now. No doubt I shall emerge from it all a different man, but quite who I’ve not found out.
> 
> Glad you enjoyed broadcast. Jefferson certainly was rather disappointing though. I’m afraid that the following syllogism may be used by some in the future.
> 
> Turing believes machines think  
> Turing lies with men  
> Therefore machines do not think
> 
> Yours in distress,
> 
> Alan


---


goto: [[etc/group|/etc/group]]