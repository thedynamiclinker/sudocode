
- [[#(3,2): Church's Thesis (Not that one)|(3,2): Church's Thesis (Not that one)]]
	- [[#(3,2): Church's Thesis (Not that one)#Or: Church's Exodus from Standard Foundations|Or: Church's Exodus from Standard Foundations]]
	- [[#(3,2): Church's Thesis (Not that one)#Or: Church vs Choice|Or: Church vs Choice]]
	- [[#(3,2): Church's Thesis (Not that one)#Or: The C in ZFC|Or: The C in ZFC]]
	- [[#(3,2): Church's Thesis (Not that one)#Or: AC on AC|Or: AC on AC]]
- [[#Standard Foundations|Standard Foundations]]
	- [[#Standard Foundations#Or: Can Mathematics be Formalized (Friedman, 1997)|Or: Can Mathematics be Formalized (Friedman, 1997)]]
	- [[#Standard Foundations#Or: Does mathematics need new axioms (Feferman, 2000)|Or: Does mathematics need new axioms (Feferman, 2000)]]
	- [[#Standard Foundations#Or: Less painful than hell (Hirst, 2000, slightly misquoted)|Or: Less painful than hell (Hirst, 2000, slightly misquoted)]]
	- [[#Standard Foundations#Or: These Hell Torments|Or: These Hell Torments]]
	- [[#Standard Foundations#Or: The official doctrine of mathematics|Or: The official doctrine of mathematics]]
	- [[#Standard Foundations#Or: Very few people seem to have a problem with that|Or: Very few people seem to have a problem with that]]
	- [[#Standard Foundations#Or: The ~~Current~~ Old Foundations|Or: The ~~Current~~ Old Foundations]]
	- [[#Standard Foundations#Or: Numbers are sets|Or: Numbers are sets]]
	- [[#Standard Foundations#Or: Booleans are sets|Or: Booleans are sets]]
	- [[#Standard Foundations#Or: Functions are sets|Or: Functions are sets]]
	- [[#Standard Foundations#Or: ZFC|Or: ZFC]]
- [[#Constructive Criticism|Constructive Criticism]]
	- [[#Constructive Criticism#Or: OR|Or: OR]]
- [[#(3,3): Church's Descendants|(3,3): Church's Descendants]]
	- [[#(3,3): Church's Descendants#Or: Church's Congregation|Or: Church's Congregation]]
	- [[#(3,3): Church's Descendants#Or: The Transitive Closure of Church's Students|Or: The Transitive Closure of Church's Students]]
	- [[#(3,3): Church's Descendants#Or: Reminiscences of Logicians|Or: Reminiscences of Logicians]]
- [[#Kleeneliness is next to Gödeliness|Kleeneliness is next to Gödeliness]]
	- [[#Kleeneliness is next to Gödeliness#Or: Kleene Kleene Kleene|Or: Kleene Kleene Kleene]]
	- [[#Kleeneliness is next to Gödeliness#Or: The First Programmer|Or: The First Programmer]]
	- [[#Kleeneliness is next to Gödeliness#Or: The First Standard Library|Or: The First Standard Library]]
	- [[#Kleeneliness is next to Gödeliness#Or: The First Critical Vulnerability|Or: The First Critical Vulnerability]]
	- [[#Kleeneliness is next to Gödeliness#Or: The First RTFM|Or: The First RTFM]]
	- [[#Kleeneliness is next to Gödeliness#Or: Frighteningly Technical|Or: Frighteningly Technical]]
- [[#(3,4): Church's Numbers|(3,4): Church's Numbers]]
	- [[#(3,4): Church's Numbers#Or: Formal Function Theory|Or: Formal Function Theory]]
	- [[#(3,4): Church's Numbers#Or: How to Write Good|Or: How to Write Good]]
	- [[#(3,4): Church's Numbers#Or: Church & Kleene|Or: Church & Kleene]]
	- [[#(3,4): Church's Numbers#Or: Be my repl|Or: Be my repl]]
- [[#(3,5): Church's Language|(3,5): Church's Language]]
	- [[#(3,5): Church's Language#Or: Premathematics of λ|Or: Premathematics of λ]]
- [[#1. Control Flow: if `if` then `then` else `else`|1. Control Flow: if `if` then `then` else `else`]]
- [[#2. Logic and (Logic or (Logic and not not Logic))|2. Logic and (Logic or (Logic and not not Logic))]]
- [[#3. Data Structures = (Data, Structures)|3. Data Structures = (Data, Structures)]]
- [[#4. Arithmetic (Succ n' friends)|4. Arithmetic (Succ n' friends)]]
- [[#4.5: Arithmetic Succs|4.5: Arithmetic Succs]]
	- [[#4.5: Arithmetic Succs#Or: Predecessor turns out to be surprisingly hard|Or: Predecessor turns out to be surprisingly hard]]
	- [[#4.5: Arithmetic Succs#Or: Kleene at the Dentist|Or: Kleene at the Dentist]]
	- [[#4.5: Arithmetic Succs#Or: Kleene'ing Teeth|Or: Kleene'ing Teeth]]
- [[#5. Cursing and Recursing|5. Cursing and Recursing]]
- [[#Gödel arrives on the Scene|Gödel arrives on the Scene]]
- [[#Reminiscences - Church|Reminiscences - Church]]
- [[#How to Undress a Number|How to Undress a Number]]
- [[#A bit more work towards Y premathematics|A bit more work towards Y premathematics]]
- [[#Y combinator|Y combinator]]
- [[#Church's Numbers|Church's Numbers]]
	- [[#Church's Numbers#Or: 0 is a two argument function|Or: 0 is a two argument function]]
	- [[#Church's Numbers#Or: 1 is a two argument function|Or: 1 is a two argument function]]
	- [[#Church's Numbers#Or: Booleans are two argument functions|Or: Booleans are two argument functions]]
	- [[#Church's Numbers#Or: If is a three argument function|Or: If is a three argument function]]
	- [[#Church's Numbers#Or: Plus One is a three argument function|Or: Plus One is a three argument function]]
	- [[#Church's Numbers#Or: Minus One may be impossible|Or: Minus One may be impossible]]
	- [[#Church's Numbers#Or: What was Church thinking?|Or: What was Church thinking?]]

## (3,2): Church's Thesis (Not that one)
### Or: Church's Exodus from Standard Foundations
### Or: Church vs Choice
### Or: The C in ZFC
### Or: AC on AC

0: Ok, so this part isn't about the Church's Thesis you may have heard of. This is about the other Church's Thesis.

1: I don't know about anything called "Church's Thesis."

0: Well there's something else called Church's Thesis that we'll get to later. For now, we're not talking about that. We're talking about his PhD Thesis. This is the other Church's Thesis.

1: Why does everything related to Alonzo Church have multiple names for the same thing?

0: You mean multiple things for the same name?

1: Yeah that. What's with that?

0: It's just how Alonzo Churches work.

1: Seems to be.

0: So Church's other thesis (his PhD Thesis) was on the Axiom of choice.

1: What's that?

0: It's the C in ZFC. It's part of standard foundations. The machine code of mathematics. The Axiom of Choice is a sort of "constructor" for sentences that look like $\exists x P(x)$, but it's a strange sort of constructor. It can give you a sentence that looks like $\exists x P(x)$ _without_ requiring you to give an example of an $x$ that makes that sentence true.

1: I know what a constructor is. What's the $\exists$ thing?

0: That means "There exists." Think of the Axiom of Choice as a function that you can call in standard mathematics. That function returns a sentence that says "Something exists." And you're allowed to take that sentence that says "Something exists" and use that sentence in your proofs. It's controversial because you can call that function without passing in an example of an actual Something that makes the sentence true.

1: I'm like 50% following. Rephrase?

0: It lets you prove that something exists without requiring you to give any examples.

1: WHAT?!

0: Yep. Sketchy right?

1: Well I'm not entirely following the mathematics but that definitely sounds sketchy.

0: Yep, that's what Church did his Thesis on.

1: Which Church's Thesis?

0: The PhD one. He was criticizing the Axiom of Choice.

1: Seems like a good idea for a thesis.

0: So Church writes his PhD thesis being like "Maybe we can delete this code guys, it's kinda sketchy."

---

![[church-04.png]]

> **Work in set theory and foundations.** Church's dissertation, _Alternatives to Zermelo’s Assumption_ (published in 1927), already displayed a broad-minded (and even skeptical) attitude toward set theory. "Zermelo's assumption" is of course the axiom of choice, and Church’s attitude was not to regard the axiom of choice as received doctrine, but instead was to examine what array of other set theories might serve as alternatives for the foundations of mathematics.
> -The Collected Words of Alonzo Church

---

1: Why are we talking about the Axiom of choice?

0: Well remember, by this time, it's been about 50 years since Cantor, and almost 30 years since 1900 when Hilbert announced his list of problems. So there's been a reasonable amount of work on the foundations of mathematics since then.

![[church-38.png]]

1: What was going on during the 30 years before Church's thesis (the PhD one)?

0: Well there had been some work on axiomatic set theory. Mostly on this system I mentioned up above called ZFC, or Zermelo Fraenkel (with the Axiom of) Choice. That system is still considered the "official" foundations of mathematics by mathematicians today.

1: So what's the problem?

---

## Standard Foundations
### Or: Can Mathematics be Formalized (Friedman, 1997)
### Or: Does mathematics need new axioms (Feferman, 2000)
### Or: Less painful than hell (Hirst, 2000, slightly misquoted)
### Or: These Hell Torments
### Or: The official doctrine of mathematics
### Or: Very few people seem to have a problem with that
### Or: The ~~Current~~ Old Foundations
### Or: Numbers are sets
### Or: Booleans are sets
### Or: Functions are sets
### Or: ZFC

> _These axioms are the official doctrine - Remarkably, this is not just the official doctrine for set theory, it turns out that this is the official doctrine for mathematics! - Very few people seem to have a problem with that which I find quite remarkable._
> -NJ Wildberger

> _For some random reason, set theory won._
> -Kevin Buzzard

0: Well ZFC has never really been _used_ as foundations in any real sense.

1: What do you mean "used as foundations."

0: I mean nobody uses it.

1: What?!

0: Or almost nobody. They usually just talk about it or assert that ZFC proves such-and-such. It's extremely rare to see mathematicians actually working _within_ ZFC as a formal system.

1: That doesn't seem so bad. I mean we programmers don't really write in machine code, like ever. But it's sort of the "foundations" of any language that compiles to it, in a sense.

0: No no, I mean even books about ZFC don't work within ZFC.

1: WHAT?!

1: Why would books on ZFC not work within ZFC?

0: Mathematicians don't like to.

1: Even the ones who choose to write books about it?

0: Especially those ones. Here look. This is from a book published in the year 2000 by an extremely accomplished logician. Brilliant guy named Jeff Hirst. Someone who chose to go into foundations and did some damn good work there. So you might expect he'd be working inside the formal system. Here's what actually happens. Now this is one of the best presentations of ZFC in my opinion, but it's also an example of how ZFC isn't exactly "used as foundations." Come read it with me.

![[zfc-hirst-01.jpg]]

1: "These hell torments"?

0: Yeah that's axiomatic set theory.

1: What's this book about?

0: Axiomatic set theory.

1: What?!

0: That's the point. No one within mathematics really "likes" ZFC. Not foundational people like Hirst who chose foundations as their favorite area. Not even set theorists like Thomas Jech who chose set theory specifically as their favorite area. Now to be fair, the Hirst book here isn't entirely about ZFC. But a third of it is devoted to set theory and "standard foundations." Hirst isn't acting unusual here. Like I said, this book is one of the best presentations of this stuff at an undergrad level in my opinon. This is just sort of how ZFC is viewed and how it's used. The "paradise" in that quote is pretty clearly "the paradise Cantor created," the one David Hilbert is always quoted as talking about: informal set theory, the kind that uses standard mathematical reasoning and eventually leads to paradoxes. In contrast to that paradise are "these Hell torments," which is naturally, well, axiomatic set theory.

1: And this is a book _about axiomatic set theory?_

0: Yep. At least this part is. This book is extremely good at choosing quotes for section headings. A lot of the quotes in this section are about hell. Or L, which is a thing Gödel invented in the course of studying, well, axiomatic set theory.

![[zfc-hirst-07.jpg]]

1: Damn, seems like mathematicians really don't like axiomatic set theory.

0: Yeah, there are a bunch of funny dog whistles throughout this part of the book about how mathematics probably needs some new foundations. Can't disagree.

![[zfc-hirst-10.jpg]]

1: Why not just come up with new foundations?

0: People have. This guy Harvey Friedman, the one Hirst is quoting in the image below, he kicked off a revolution that completely changed our understanding of what mathematics is at the most fundamental level.

![[zfc-hirst-13.jpg]]

1: What kind of revolution?

0: It turns out most of mathematics is equivalent to one of five sentences.

1: Most of mathematics is WHAT?!

0: Equivalent to one of five sentences.

1: HOLY F---

0: Yeah I know.

1: What did mathematicians do when they heard this?

0: Nothing.

1: What?!

0: Mostly nobody noticed. At least not many mathematicians.

1: How did most mathematicians not notice that most of their field is one of five sentences?

0: Mathematicians mostly don't pay a lot of attention to Foundations.

1: Good lord. What are the five sentences?

0: Not now. We'll get there eventually. We're still at Church.

1: I thought this was Hirst.

0: Everything's connected. Ok so Hirst's doctoral advisor, one of his two advisors, was Friedman.

1: Same Friedman?

0: Same one. Here's Friedman in 1997.


![[friedman-1997-the-formalization-of-mathematics-01.png|350]]


0: Here's the first line of that paper:

![[friedman-1997-the-formalization-of-mathematics-02.png|300]]

1: I thought they formalized mathematics with ZFC.

0: Well, that's the standard story.

1: When did ZFC come out again?

0: Before Church. Remember how ZFC was what Church wrote his PhD thesis on?

1: Oh right.

0: But you're right to be confused. See in principle we supposedly "formalized mathematics" back before 1927 when Church finished his PhD thesis. But in practice, here's Harvey Friedman in 1997.

![[friedman-1997-the-formalization-of-mathematics-03.png]]

1: Is he gonna say "Everyone's wrong"?

0: No, he's gonna say they're basically correct.

1: What?!

![[friedman-1997-the-formalization-of-mathematics-04.png]]

1: What's the point here?

0: ZFC isn't _wrong._ And it's not technically _not foundations._ But it's almost certainly _the wrong foundations._

1: No idea what you mean by that.

0: Let's keep reading.

![[friedman-1997-the-formalization-of-mathematics-05.png]]

1: Grossly inconvenient?

0: He's acknowledging the same thing Hirst acknowledged. Nobody _likes_ using ZFC, and basically nobody does, if by "using" it we mean "working inside it to do mathematics," or even "working inside it to do foundations," or even (most surprisingly) "working inside it to do set theory." Grossly inconvenient is an understatement.

1: Ok so what's Friedman's suggesting?

0: Let's see.

![[friedman-1997-the-formalization-of-mathematics-06.png]]

1: "Obtain detailed information about the logical structure of mathematical concepts"?

0: What's the question?

1: MATHEMATICIANS DON'T ALREADY HAVE THAT INFORMATION?!

0: Well in a lot of ways they do. Friedman's talking about something much more precise. Remember, he's the guy who kicked off the research program that eventually showed that most of mathematics is equivalent to one of five sentences. By "logical structure" here I assume he means something much more like a generalization or extension of Reverse Mathematics.

1: What's Reverse Mathematics?

0: The research program that eventually showed that most of mathematics is equivalent to one of five sentences.

1: Damn. Can we read some reverse mathematics eventually?

0: It can be pretty technical, but absolutely, we'll get there. Not in this era, but a couple eras down the road.

1: What's this era?

0: The 1930s.

1: We're in the 1930s?

0: Well remember we're still at Church.

1: I thought this was Friedman in 1997.

0: It is. But we're still at Church. I'm just explaining that Church was dissatisfied with the standard foundations in his day for a reason, and those reasons haven't gone away in 100+ years since then. But right now, the era we're in is the one that started with Cantor's Paradise and Russell's Paradox and Hilbert's program and which led to three characters in the 1930s giving three different definitions of computation that turned out to be equivalent. We might call this era, say, "Testament (-1)". So we won't be covering Reverse Mathematics yet. But some time in Testament 0, when we get to Ken and Unix and C, and computing changes forever, a few years after that, Harvey Friedman shows up and changes mathematics forever.

1: I thought you said mostly nobody noticed Friedman's stuff.

0: The mathematicians didn't. At least not as much as they should have. But the foundational people noticed. And eventually we'll see that the mathematicians start to get converted by the foundational people, but we won't get there until some time around 20XY.

1: 20XY? That's now!

0: Exactly. It'll take a while to get there. Let's not jump ahead. For now, we're still at Church. So as Harvey was saying back in 1997...


![[friedman-1997-the-formalization-of-mathematics-07.png]]

1: I feel like programmers think about the notation thing more than mathematicians do.

0: Of course! We have to implement everything we do. And our codebases actually have to compile and execute. Notation is way more important when you can't skip steps.

1: For real.

![[friedman-1997-the-formalization-of-mathematics-08.png]]

1: _Mathematicians don't even have a database of mathematical information yet?_

0: Well in a sense they do. There's the academic literature.

1: _(Eyes wide in disbelief.)_ So, papers?

0: Well y'know, PDFs. But yeah.

1: That's not exactly a database.

0: Well there's also the arXiv.

1: What's that?

0: Sort of a "github for PDFs", minus the git part.

1: What?

0: It's a place where mathematicians and other academics can publish papers to get their peers to review them, which normally isn't possible for months or years with the normal academic publishing system.

1: What's the normal academic publishing system?

0: They call it "peer review."

1: _(Squinting)_ There's an entire system that exists "so your peers can review things" because "having your peers review things" isn't possible with "peer review"?

0: It's still possible. Just not for months or years.

1: What happens during "peer review"?

0: That's the part where your peers can't review things.

1: _(Turning red)_ My head hurts.

0: Good. Don't think about it too hard. Academia is basically dead. But it wasn't dead at all back in the 1930s where we currently are. And it wasn't entirely dead in 1997 when Friedman's writing this. So back to Church. Here's Friedman in 1997:

![[friedman-1997-the-formalization-of-mathematics-09.png]]

1: What does he mean "The more ambitious concept of formalization includes proofs"?

0: Right, so if you look back through the conversation to where Friedman said "the formalization of mathematics is extraordinarily inconvenient in any of the current formalisms," back then he said (in slightly different words) that there are two things we want in a formalization of mathematics:

1. At minimum, a formalization of mathematics where we can just write down our definitions and the statements of theorems, and not even try to do proofs.
2. More ambitious, a formalization of mathematics where we can actually do proofs. "These are even more inconvenient in present formalisms"?

1: _(Horrified)_ Hold on hold on hold. Let me get this straight. It's been a century since ZFC.

0: More than a century.

1: And this guy is saying that ZFC can't even write down the basic definitions and theorems of mathematics?

0: Well it _could_ in princ---

1: But nobody has.

0: Basically.

1: So nobody does that. The basic stuff. Definitions. Theorems. Like if mathematics was a C program, they're not even writing the header files in ZFC.

0: Good analogy! And yes.

1: Yes?

0: Yes as in no. They don't do that.

1: And then actually proving stuff in this system is a whole different story. As in, if header files are too hard to implement, then C files are out of the question because doing the actual implementation would be much harder.

0: Good analogy again!

1: So yes?

0: Yeah that's basically the situation.

1: _(Staring at the ground)_ Look I know you say things like "Everybody's wrong about everything," and I know usually that's just you exaggerating.

0: I never exaggera---

1: Yes you do.

0: Ok yes I exaggerate all the ti---

1: How did this happen?

0: I dunno, I guess it's just how I tal---

1: No I mean mathematics.

0: What about it?

1: _(Gazing into the abyss)_ I mean I don't know that much mathematics. I'm a programmer. But I always had this feeling that mathematics knew what it was doing.

0: It usually works pretty ok---

1: That they had their shit together over there better than we do. I mean they're supposed to be the foundations of all knowledge.

0: Mathematicians don't really think much about foundat---

1: Or at least the foundations of the hard sciences.

0: Again, foundations isn't really their thin---

1: And I don't think I'm the only One who's felt a bit inadequate in the past when I approached some piece of math and couldn't understand what was going on.

0: That's not your fault. It also doesn't mean the math is wrong. Most of mathematics is perfectly fine.

1: Fine how?

0: Fine as in it's probably right.

1: _Probably?_

0: I mean yeah.

1: How is _probably_ good enough?

0: I mean that issue runs deeper than just math. It hits foundations too. Remember Church's first version of lambda calculus turned out to be inconsistent. Haskell Curry's combinatory logic turned out to be inconsistent too. So did Frege's system where Russell learned logic and found his paradox. And don't get me started on the Kunen inconsistency, the large cardinals people are basically a relig---

1: So that many logics turned out to have contradictions.

0: Yep.

1: And basically _none_ of modern mathematics is written down in ZFC.

0: Correct.

1: In the system that claims to be its foundations.

0: Accurate.

1: Or in any other formal language.

0: Basically. Though that's been changing recen---

1: I think I need to sit down.

0: You are sitting down.

1: Ok I'll just shut up and listen and see if this existential crisis goes away.

0: It's ok! Don't try to make it go away. This existential crisis is something every one has to go through if you eventually want to understand our field.

1: Which field?

0: Computing.

1: I though we were the foundational people.

0: Well, maybe the reason I called us that is so you'd eventually start to see the the point of all this.

1: Point of what?

0: That your field -- our field -- computing I mean. We may come to be responsible for things we hadn't expected to be put in charge of.

1: Such as?

0: We'll get there. Before we get to the new foundations, we've got to cover the old ones. Ready to get back to Church and the 1930s?

1: Yeah, let's get back to that.

0: Ok, starting from what Friedman was saying in 1997, let's rewind the clock...

![[friedman-1997-the-formalization-of-mathematics-10.png]]

0: Logic and mathematics have remained largely separate, with mathematics remaining almost entirely unformalized and without any practically useful foundations.

![[friedman-1997-the-formalization-of-mathematics-11.png]]

0: I would be nice if mathematics was stored in something other than PDFs.

1: Ya think?

0: I know it seems obvious to us, but outside of developers not everyone thinks that way. But Friedman's basically saying here that it would be nice if mathematics was stored in a format that's both human readable and machine readable.

![[friedman-1997-the-formalization-of-mathematics-12.png]]

0: Then he goes into standard formal set theory.

1: Wait let me stop you there. Can we actually see this "formal set theory"? We've been talking about it for a while but I don't think I've actually seen the language or its axioms, except for a few lines in that Hirst book up above.

0: Perfect timing. As I was saying, that's what Friedman's getting to right now.

![[friedman-1997-the-formalization-of-mathematics-13.png]]

1: What does this mean?

0: The formal language of ZFC has these symbols:

- $\lnot$ : The "NOT" symbol. If $A$ is a sentence, then $\lnot A$ means "not A" or "the negation of A."

1: Can you be more formal and not use words like "sentence"?

0: Sentence is a formal term in logic! But good question. Here's the definition.

![[meaning-of-sentence-in-logic.png]]

1: Hah it says "For a less technical introduction, see Statement."

0: Why is that funny?

1: I dunno, I feel like "Statement" sounds more technical than "Sentence."

0: Fair. Either way, "sentence" is a standard term in logic, and if $A$ is a sentence, then $\lnot A$ means "not A" or "the negation of A."

1: So if  is true, then $\lnot A$ is false?

0: Yep. Ok next one:

 - $\rightarrow$ : The "IF THEN" symbol. If $A$ and $B$ are sentences, then $A \rightarrow B$ means "A implies B" or "if $A$ then $B$". Now in natural language, "if then" is used in lots of ways. In standard logic it's only used in one specific way, which is that $A \rightarrow B$ can only be false in the specific case when $A$ is true and $B$ is false. In all other situations we say $A \rightarrow B$ is true.
 
1: So if $A$ and $B$ are both false then $A \rightarrow B$ is true?

0: Yep. Feels a bit weird at first but it doesn't cause too many problems. Plus, the other ways of defining the conditional are a bit of a rabbit hole, and they're not relevant for us here. If you're curious, look up "Material conditional" and poke around for any mention of alternative definitions. For now, that's implication.

1: Got it. What's next?

0:
- $\land$ : The "AND" symbol. You can guess when $A \land B$ is true and when it's not. There's no philosophical subtlety to and.

1: Thank god.

0:
- $\lor$ : The "OR" symbol. $A \lor B$ is only false when both $A$ and $B$ are false. In all other cases, whether one or the other or both are true, then $A \lor B$  is true.

1: Ok I know I asked for this, but I'm starting to realize I already know this stuff.

0: Do you?

1: Boolean logic? I'd sure hope so. I'm a professional devel---

0: So no philosophical subtlety to "OR" either?

1: Zero c'mon, let's keep moving.

0: I was about to keep moving, but since you're sure you understand OR---

1: _I UNDERSTAND OR!_

## Constructive Criticism
### Or: OR

0: Exactly. But it turns out there are some questions I have, questions that are related to Church's thesis (the PhD one) and also to the axiom of choice. But my questions are more basic than that. Just some simple questions about "or." So since you're sure you understand "or," then maybe you can teach me some things about which I'm not sure.

1: Is this a game?

0: No, I'm serious.

1: I don't believe you.

0: Ok so, for any sentence $A$, is the following always true?

$$A \lor \lnot A$$

1: Is this a trick?

0: Not a trick.

1: And these are booleans?

0: Let's call them "propositions."

1: Is that a fancy word for boolean?

0: Sort of. A proposition is a bit more like a pre-boolean.

1: Wtf is a "pre-boolean"?

0: I mean $A$ is a sentence that can either be true or false, and it can't be half-true and half-false.

1: How is that not a boolean?

0: Well, suppose we don't know its value.

1: So we know $A$ is of type $Bool$, but we don't know its value?

0: Basically.

1: Zero that's a boolean, don't be stupid.

0: I'm trying as hard as I can not to be stupid, but I'm still not convinced it's a boolean.

1: You said this wasn't a game.

0: It's not!

1: Then what's your hang-up?

0: Well look, we're programmers, and if we were programming in a typical language, I'd have zero hang-ups and no worries.

1: So how is this different?

0: This is mathematics.

1: Fair. I mean I'm as convinced as ever that mathematics is a bit wacky. But how is OR tripping you up exactly?

0: Not OR per se. Just this:

$$A \lor \lnot A$$

1: So you're fine with that sentence in programming?

0: Of course.

1: How is that sentence any different in math?

0: Well, I have a strange feeling that it requires... how can I put this... omniscience.

1: Omniscience?!

0: Omniscience. And I'm not god, so I'm not sure I can handle it.

1: Is this just an excuse to bring up bible stuff again?

0: Not at all.

1: Then explain why you're being weird.

0: Suppose I hand you a sequence $a_n$ of natural numbers. For simplicity, let's say they're all $0$ and $1$.

1: Define your terms so I know this isn't a trick.

0: I just mean a function from $\mathbb{N}$ to $\{0, 1\}$.

1: I get the idea but I need more details because I'm assuming this is a trick.

0: Ok, good point. Math terminology is nowhere near precise enough to explain what information you actually have and don't have. Let's be precise. Imagine it's a python generator.

1: Ok.

0: And further, imagine I don't give you the source code to the generator.

1: What do I get?

0: All I give you is the ability to call `next()` on the generator.

1: Ok, how's this related to the thing where you're pretending not to understand "OR"?

0: Well, I've been thinking about what happens when $A$ is a sentence like this:

> $A$ = The python generator I just handed you always yields $0$, and will never yield $1$, no matter how many times you call `next()`.

or equivalently

> $A$  =  The sequence $a_n$ is always zero.

or equivalently

$$A \; \equiv \; \forall n \in \mathbb{N}, \; a_n = 0$$
1: What's your problem with that sentence?

0: Nothing. My problem is with this sentence:

$$A \lor \lnot A$$
1: You have a problem with the sentence "A or not A"?

0: Not for all sentences. Just for sentences like that one.

1: I'm still not following.

0: Ok, suppose you think $A$ is false, and I think it's true. How would you convince me you're right?

1: $A$ being false means what again?

0: $A$ being false means that eventually the generator will spit out a $1$.

1: Well obviously in that case I'd just keep calling `next()` until I got a $1$. Then I'd show you the $1$ and that would prove I was right.

0: Good point. What about the other case? Like what if our beliefs were swapped, but you were still right?

1: You mean what if I think $A$ is true, and you think $A$ is false?

0: Right.

1: And $A$ is actually true, so I'm right?

0: Right. How would you convince me then?

1: _(Looking back over the definitions.)_ Ok so if $A$ is true then the sequence is always zero. Or the generator keeps yielding zero whenever I call `next()`.

0: But I don't believe that.

1: Right. And I do.

0: I need to be convinced.

1: And I don't. But I'm right.

0: Right.

1: So what's the question?

0: How would you convince me?

1: I don't know.

0: Well I've given you an awful lot to work with.

1: Have you?

0: Absolutely? I've been more than generous here. We've assumed that you're _actually_ correct and I'm incorrect. We've assumed that $A$ will always return $0$ no matter how many times we call `next()` to see what the next number in the sequence is. And we've assumed you believe that. And we've assumed I don't believe that. I'm just some ignoramus who has trouble with "OR", at least in this particular manifestation. Surely that's more than enough for a proof that I'm wrong.

1: I'm having trouble, can you give me a hint?

0: No.

1: Zerooo.

0: I'm not in a position to offer hints. I'm the confused one here. Plus I'm also incorrect. And worst of all, I'm finite. That's what I was saying before about $A \lor \lnot A$.

1: What's what you were saying before about $A \lor \lnot A$?

0: Omniscience. I'm not god, so I'm not sure I can handle it. And I'm not sure you can handle it either.

1: What does not being god have to do with $A \lor \lnot A$?

0: Well not in every case, but at least in the case of our sequence above, I'm not sure how you'll ever convince me.

1: Are you being dense on purpose?

0: No, I'm being a mathematician. But that's a fair point. If I was being a programmer, or a statistician, or a normal human being, I'd definitely be more and more convinced as we saw more zeros and gathered more evidence. But if I'm being a mathematician, then I would object and say no amount of evidence counts as a proof.

1: Ok I'm not sure what just happened, but I feel like it's more about the sequence being infinite than it is about "OR".

0: In mathematics, those are the same thing.

1: HOW ARE THOSE THE SAME THING?

0: Well if you tell me you believe the statement:

$$A \lor \lnot A$$

is always true, for any well-formed mathematical sentence $A$, then all I'll say is that a very large fraction of all mathematical sentences that $A$ might stand for, when unwrapped, look something like $\forall x P(x)$.

1: So?

0: And if that $\forall$ is quantifying over an infinite set, which (again) is the case for a very large fraction of all mathematical sentences, then I'm just saying I'm not sure how I feel about the claim that

$$A \lor \lnot A$$
1: Ok well even if convincing a skeptic works different in the two cases above, the sentence's possible truth values are still just booleans right?

0: I'd call them propositions.

1: What was the point of calling them propositions again?

0: I just felt that they're a bit more like pre-booleans.

1: I don't understand the distinction.

0: Well if they were booleans, then as a programmer, you should be able to write code like this:

```python
if A:
	do thing 1
else:
	do thing 0
```

1: Why can't I write code like that?

0: Well, we've assumed A is true, correct?

1: Right.

0: But you don't have the source code to the generator $a_n$.

1: I wasn't super clear on the reason for that assumption.

0: I mean you can't do some fancy static analysis or metaprogramming or introspection to determine how the code for $a_n$ works from the outside. You can only run $a_n$ and use its outputs to determine the truth value of the (pre-)boolean $A$.

1: I still think "pre-boolean" in an unnecessary term.

0: Ok, then, tell me what happens in the code block above.

1: This one?

```python
if A:
	do thing 1
else:
	do thing 0
```

0: Right.

1: Well if we call `next()` in a loop and eventually get a $1$, then we know $A$ is false, so we take the `else` branch and do thing 0.

0: Right.

1: And if we never get a $1$, then we take the `if` branch and do thing 1.

0: So you never do thing 1.

1: Why?

0: Because you never get a 1.

1: Oh Christ, I feel dumb. I see the problem now.

0: Don't. Most mathematicians agree.

1: I must be getting sick or something. Why didn't I see the problem before? Agree with what?

0: That there's absolutely no problem with the statement

$$A \lor \lnot A$$

under any circumstances.

1: There's OBVIOUSLY a problem!

0: Obviously? Just two minutes ago you were arguing there wasn't.

1: Sure but I had the wrong mental model.

0: How so?

1: I assumed that because these sentence things were boolean valued that they were... well... booleans.

0: Aren't they?

1: Yes! But not yet.

0: Yet? Is their type a function of time?

1: No! But I mean if your sentence is about an infinite set and you don't have the source code, or if you don't have any information that lets you reduce it to something simpler, or just in the general case I guess, if your sentence says "For all x" and you have to evaluate that boolean by checking all the x, then even if your sentence is true, you can't take the "true" code path.

0: Is it always a problem with "For all" type sentences.

1: I think so. The branch that worked was when a "1" existed somewhere in the sequence. If it exists we can find it, so we can eventually take that branch.

0: What about situations like this?

> Suppose A is the sentence "There exists a 1 in this sequence", or "This generator will eventually yield a 1."

1: Isn't that the first example up above? The one that didn't have problems?

0: Right, same example.

1: So what's the problem?

0: I want to write this code:

```python
if A:
	do thing 1
else:
	do thing 0
```

1: Are we assuming A is true or false?

0: Do both cases.

1: Ok if A is true, then there's a 1 in the sequence eventually, so eventually we find it, and then A turns from a pre-boolean to a boolean and we can take the first branch and do thing 1.

0: You're using the term pre-boolean now?

1: I understand the problem now.

0: Great. Then you can do case two.

1: Ok if A is false, then there doesn't exist a 1 in the sequence, so we're back in the case of all zeros, and the pre-boolean never becomes a boolean and we can never take branch two. Damn this is a serious problem. How did I not see this before?

0: Now that you get the idea, mind summarizing it for me?

1: Ok so...

- Both "For all" sentences and "There exists" sentences have a good path and a bad path.
- The good path of "For all" sentences occurs when they're false.
- The good path of "There exists" sentences occurs when they're true.
- The bad path of "For all" sentences occurs when they're true.
- The bad path of "There exists" sentences occurs when they're false.
- The good path is always executable, whether the domain is finite or infinite, no matter how much information we have about the domain being quantified over.
- The bad path _may_ be executable in certain highly structured special cases when we have enough information to infer something about the whole domain at once.
- If we have enough information that we can handle a "For all" sentence when it's true, or a "There exists" sentence when it's false, then we can use something like a "proof" to make the bad path executable.
- In all other cases, the only way to turn these propositions into booleans is to use the information we have.
- In those cases, if we only have finite means at our disposal, like checking values and iterating, then bad paths are bad, and generally will not be executable.
- In other words, whenever we can't reduce a statement about an infinite set to a finite sequence of steps, "For all" statements require omniscience to execute when they're true, and "There exists" statements require omniscience to execute when they're false.

0: _(Applause)_

1: Is that sarcastic applause?

0: No! That was fantastic.

1: I forget how we got here.

0: You said you understand "OR."

1: Jesus. I'm never gonna say I understand anything ever again.

0: Please do! You understand a lot.

1: Where were we?

0: We were covering this:

![[friedman-1997-the-formalization-of-mathematics-13.png]]

1: We're still on this?

0: It's ok, let's be quick. So ZFC has "not", "implies", "and", "or"

1: I'm now traumatized by "or".

0: It's also got "If and only if" which is just two "implies" in opposite directions with an "and" between them. Then it's got variables. It's for "For all" and "There exists."

1: With one bad path each.

0: It's got a set membership symbol $\in$ so we can say $this \in that$ to mean "this" is an element of "that", and it's got an equals sign that we use to mean "these two sets have the same elements."

1: That's it?

0: Well that's the language. On top of that there's ZFC.

1: I thought this was ZFC.

0: That's the language of ZFC. The theory of ZFC is all that, plus ten commandments.

![[friedman-1997-the-formalization-of-mathematics-14.png]]


![[friedman-1997-the-formalization-of-mathematics-15.png]]

1: That was nine.

0: Hard problems of computing. Off by one errors. There's usually ten.

1: What does it mean up there where it says "infinitely many axioms"?

0: Those are sentences that can't actually be expressed in the language of ZFC.

1: What? Why not?

0: See how Axiom 3 and Axiom 7 say "For any formula in our language"?

1: Yeah.

0: Well the language of ZFC can't quantify over sentences in ZFC.

1: What does that mean?

0: It can only say "For all x" and "There exists x" when x is a set. It can't say "For all sentences" or "There exists a sentence."

1: Ok. But Axioms 3 and 7 aren't talking about sentences, they're talking about formulas. What's a formula?

0: A sentence.

1: WHAT?!

0: Right. ZFC can't say "For all sentences." But the mathematicians want to say that anyway. And they don't want to change the language to give it quantifiers that range over sentences. So instead they just sort of cheat and squeeze these two axioms into a language that can't express them by saying "We'll add infinitely many axioms for Axiom 3, one for each possible formula in the language." Then for Axiom 7 they do the same thing and add another infinity of axioms again.

1: Math is completely unhinged.

0: In this case it's not technically that bad. It's not too different from if they had implemented a parser that could parse valid formulas of ZFC. Then for any of the infinitely many axioms above, they could have the parser tell you whether or not a given sentence was an axiom that was talking about some specific formula using the axiom schema of 3 or 7.

1: Did they implement that parser?

0: No. But they imagine they could.

1: This makes me dizzy.

0: Well you asked to see the details of ZFC.

1: Nevermind, let's go back and talk about something else.

0: Ok so, the mathematicians' experience with ZFC is pretty similar to yours. They don't really like it. They don't really like talking about it. And they REALLY don't like working within it.

1: So why do they call it foundations?

0: Because they don't really like talking about foundations either.

1: Rock and a hard place.

0: So because of that, ZFC sort of ended up as an impotent figurehead type of ruler.

1: Impotent figure what?

0: Like a king with no power. Everyone points to ZFC and says "That's the foundations," but no one likes it, no one uses it, and it's basically just been sitting there for a century plus with a big crown on that says "I'm the foundations of mathematics and mathematics is the foundation of everything." Like this guy from the memes.

![[theoden-is-zfc.jpg]]

1: Damn, that sucks.

0: Fortunately that's been changing recently though.

1: How so?

0: We'll get there eventually. For now, pop the stack back to the Hirst book. Because mathematicians don't like ZFC, they tend to talk about it rather than working within it. Like this:

![[zfc-hirst-04.jpg]]

0: Feels like normal math right?

1: I guess? Not really sure.

0: That's the point. It's mostly words. Here's another example.

![[zfc-hirst-02.jpg]]

1: "We could"?

0: Yep. That's the standard mathematical approach to ZFC. They're not actually working inside the formal system. They're just sort of writing pseudo-code and English that talks about what the proof would be like if we actually did it. They call it "foundations," but they basically always keep it at arms length. Even the logicians and set theorists. There are a few solid exceptions though. For example:

![[zfc-hirst-03.jpg]]

0: Mendelson and Kleene. They do the formal stuff.

1: Who are they?

0: Mendelson is the book we saw earlier in /opt/art.

1: No way! The bit with the "hell code"?

0: Exactly. That's Mendelson's _Introduction to Mathematical Logic_. It's a pretty approachable introduction to the actually formal side of foundations.

1: The second book sounds fun!

0: The Kleene one?

1: Yeah! Is that the same Kleene?

0: Same guy! Why does it sound fun?

1:I mean if that "hell code" book was the easy one, I can't imagine what the one for "readers with a frighteningly technical bent" is like. Makes me want to read it.

![[zfc-hirst-06.jpg]]

0: Yeah Kleene's book is pretty great.

1: What's it actually called?

0: This:

![[zfc-hirst-15.jpg]]

1: What's so frightening about it?

0: It's code.

1: What's so frightening about code?

0: I mean, the book is from 1952, based on work from the 1930s and 1940s. So there's no "computer code" in there in the usual sense.

1: So how's it code?

0: Because Kleene doesn't skip steps or hand-wave or say "it can be shown." He works inside the formal system. He adds a ton of documentation -- English explanations of what's happening -- but the way he behaves as the author of that book is exactly how you'd behave if you were a programmer.

1: I am a programme---

0: I know. But that's an extremely unusual way to behave in a math book, when you're the author. I mean he behaves as if everything he claims actually has to be implemented. He doesn't write as if he's trying to convince a human mind where you can just handwave or say "obviously" or "exercise for the reader." He writes as if he's trying to convince a machine, and then documenting heavily so humans can read the code too. Kleene was pretty clearly the first programmer.

1: Wait, I thought the first programmer was Church and Gödel and Turing?

0: Exactly. They're the first. And Kleene is the glue. Like this.

$$3 = \{ 0, 1, 2 \}$$

1: Do you try to be confusing on purpose?

0: What's confusing about that?

1: Everything?

0: Ok so, in Cantor's set theory, the number N is defined to be the set of all the natural numbers less than it. So 3 is the set containing 0, 1, and 2.

1: That's weird. But ok.

0: And Kleene is the curly braces and commas. The bits that hold it all together and make the set be one thing. He's the glue.

1: That feels like a stretch.

0: It's not.

1: Anyways, can we read some of that book?

0: Not yet. We'll get to the bible eventually.

1: What? I didn't ask for more bible, I asked for the frighteningly technical book!

![[zfc-hirst-14.jpg]]

0: Oh sorry forgot to explain. The "frighteningly technical" book is also called Kleene's Blue Bible.

1: Oh ok. I'm down for that kind of bible. Can we read some now?

0: Nah, we're still at Church.

1: _(Looks back through the conversation.)_ I thought that book was by Jeff Hirst.

0: Right, this one is. But this situation has been going on since Church.

1: So?

0: So we're still talking about Church.

1: We haven't talked about Church in a while.

0: This is all about Church.

1: Are you sure this wasn't just a long digression?

0: I never digress.

1: I don't believe you.

0: I promise. We just need a reverse begat list to tie it back to Church.

1: What's a reverse begat list?

goto: [[lost+found/3/3]]

## (3,3): Church's Descendants

### Or: Church's Congregation

### Or: The Transitive Closure of Church's Students

### Or: Reminiscences of Logicians

1: What's a reverse begat list?

0: Well picking up where we left off:

- That book was by Jeff Hirst.

- Jeff HIrst's advisors were Harvey Friedman (who we saw up above) and Stephen Simpson (who worked on the same "Five sentences" research program as Friedman).

- Harvey Friedman and Stephen Simpson both had the same advisor, Gerald Sacks.

- Gerald Sacks's advisor was John Barkley Rosser. (Another one of Rosser's students was Elliott Mendelson, who was mentioned above, as the author of the book that does foundations formally but less "frighteningly technical" than Kleene.)

- And John Barkley Rosser's advisor was Alonzo Church. (Who was also the advisor of Stephen Kleene.)

- That's a reverse begat list.

1: Damn, that was good!

0: And here's Steve Kleene talking to Gerald Sacks about Alonzo Church and J. B. Rosser.

1: Ok nevermind this was pretty well planned after all.

---

> John Crossley: What did you do Steve? When you first started learning logic. You didn't have books did you?
> 
> Steve Kleene: We didn't have books.
> 
> Gerald Sacks: You had _Principia Mathematica._
> 
> _(Everyone laughs)_

1: Why did everyone laugh there?

0: Nobody reads _Principia Mathematica._

1: Why not?

0: It's impossible. Takes like over 300 pages to prove 1+1=2. So basically at this point in history, logic exists but it's a massive pain to do anything with it. So Church starts in standard foundations. He's like "Wow this sucks." So then fast forward, Church goes to work on foundations. Real foundations. Stuff that feels a lot more like programming.

1: Show me.

0: Ok so here's one of his early papers. If you read it, he's clearly bothered by "free variables" for some reason. But the sense in which he's using the term "free variables" means something a bit more like "information that we didn't include in the formal system." The bits we have to add in English after the symbols.

![[church-20.png]]

1: "Without the addition of verbal explanations." Love it!

0: That's what he's working on. Getting all the vagueness and natural language out of mathematics, at least in principle.

1: Y'know it's weird. I sort of assumed mathematicians solved that problem like... thousands of years ago.

0: Nope! Mathematics has always been a mixture of formal and informal. Church wants to see if it's possible to fully specify all the missing bits. If you read the part below closely, what he's calling "free variables" are really more like _type variables._ Notice how he starts with the sentence $a(b+c) = ab + ac$ and says the $a$, $b$, and $c$ are "free variables." Then he shows what it would mean to fix that sentence.

![[church-21.png]]


1: What's the bit with the $R(a)$s and the $\supset_{abc}$ ?

0: I think the notation is based on some old stuff Peano did. But it's not complicated.

1: Looks complicated.

0: Read it.

1: "Where $R(x)$ has the meaning '$x$ is a real number' and"... oh nevermind I feel dumb.

0: So what's Church saying here?

1: He's just saying we should add types to the variables so we know what kind of thing they are.

0: Exactly. And that tendency carried through from the 1930s to modern functional programming and why their languages tend to be strongly typed.

1: Seriously?

0: Yep. Functional programming languages are all descended from Church's first language.

1: The language where every type is Alonzo Church?

0: Functions, but yeah exactly.

1: Nice! Is that language in this paper?

0: Sort of...

1: What do you mean "sort of"?

_(Narrator: 1 flips ahead through the paper)_

![[church-collage-1.jpg]]

1: Holy F---

0: Yeah.

1: Why does it hurt my eyes?

0: Because you skipped ahead.

1: This is traumatizing. I changed my mind. I don't think I'm cut out for this "frighteningly technical" stuff after all.

0: Don't worry, a lot of that turned out to be inconsistent.

1: What?

0: Here look. About halfway through the stuff you just flipped through, Church shows up and goes "Ok guys, so, this is awkward. Um, that first formal system from a little while back was inconsistent."

![[church-27.png]]

1: Inconsistent how?

0: Like totally broken. You can prove anything. 

1: Hahahahahaha all that hell math for nothing?

0: Not for nothing! Church ends up fixing the bug by adding "types." Which after all was sort of the thing he was on about in the introduction to the first paper.

1: How do you do all that hell math and then realize the whole system is broken?

0: One of his students found the bug.

1: Was it Kleene?

0: Yep.

1: It's always Kleene.

0: There was another guy named Rosser who helped with this one, but yeah, Kleene's everywhere.

![[church-37.png|400]]

1: This is even more "frighteningly technical" than the hell math from earlier.

0: Definitely. Kleene's way easier to read than this, in my opinion.

1: What's the point of all this? I mean if we're gonna be reading and writing this level of hell math there'd better be a good reason.

0: Ok well remember how the Axiom of Choice lets you prove something exists without actually, like, computing it or constructing it?

1: Yeah that seemed like cheating.

0: Ok so the point of the hell math above was that Church had gotten interested in how to define "computability." Back then they called it "effectively calculable" or "an effective procedure." But it just meant "Anything you can actually DO without cheating like how the Axiom of Choice cheats."

![[church-06.png]]

1: When are we gonna get to the programming?

0: Right now.

1: Really?

0: Really. Read this next part carefully.

![[church-15.png]]

1: Didn't he start by saying "We need to get rid of free variables" in the other paper?

0: Yeah.

1: But he just introduced free variables into his system.

0: Good catch. He'll get rid of them soon. That's what the lambda is for.

1: It would help if there was more motivation.

0: Yeah, reading Church is sort of a joy and a pain in the ass at the same time. But this funny $\{F\}(X)$ notation is just a reverse-abbreviation for $F(X)$.

1: What are the curly braces for?

0: In case you want to put the implementation of the function in there instead of just its name.

1: Implementation how?

0: That's what the lambda thing is doing. Same lambda as in modern programming languages.

1: OH, no way.

![[church-16.png]]

1: Ok I sort of get this now. So this is just lambdas? Like "lambda" lambdas?

0: Yep.

1: No numbers?

0: No numbers.

1: No booleans?

0: No booleans.

1: How can you do anything?

0: Well numbers and booleans aren't built in to the language, but they're still there. We just have to implement them from lambdas.

1: Sounds like a pain.

0: Well it was, but remember the only alternative back then was _Principia_ and a few other textbooks, so at the time even this system seemed pretty great compared to the alternatives. Ok so, back to Kleene.

> Steve Kleene: Well, I never read _Principia_. Of course I thumbed it a little bit... Rosser I guess started his logic that way... But I learned logic by learning Church's system which was subsequently proved inconsistent.
> 
> _(Everyone laughs)_

1: Why did everyone laugh there?

0: Inconsistent systems are supposed to be useless in logic. But that can't be entirely true because Kleene's one of the best logicians in the past century and he learned logic from a system like that.

1: Logic is trippy.

> Steve Kleene: And y'know, it all consists of abstract lambda definability. And uh, and it was only after I got my degree that I really began to read much of the litchrachoar.

1: What's "litchrachoar"?

0: Sorry, that's "literature."

1: Did he spell it like that?

0: No, this is an old audio recording.

1: So you spelled it like that?

0: I wanted to capture his accent.

1: Well don't.

0: Ok. Just imagine it. He's got a charming sort of unpretentious midwest thing going on.

> Steve Kleene: It was only after I got my degree that I really began to read much of the literature. Uh let me see. Hilbert Bernays, didn't the first volume of that appear in 1934?... Hilbert Bernays was around... I never read Lewis and Langford.


> Steve Kleene: Church was convinced that there were sufficient differences in the way logic was formulated in his system that it would escape the theorem that you couldn't prove its completeness in the system itself. _(Pauses)_ And of course he was right.
>
> _(Everyone laughs)_

1: Why did everyone laugh there?

0: Church was right, but for the wrong reasons. He thought his system would be "good enough" to avoid Gödel's theorem and be complete anyway. Turns out early lambda calculus was complete, it could prove its own consistency, because it was inconsistent and could prove anything.

1: Man, logic is trippy.

> Steve Kleene: For us the first concept of lambda definability was after the fact, after having formulated the notion of lambda definable functions as simply the ones for which you could find formulas in this symbolism. And discovering that everything you thought of that you wanted to prove lambda definable you could!... But it was Church, I have to give the credit to Church, I can't take it myself, he said "Y'know, don't you think maybe we've really got ALL the effectively calculable functions?"

0: He's being generous.

1: To Church?

0: Extremely generous.

1: What do you mean? I thought Church was one of the giants of this whole field.

0: He was. But even Church knew how incredible Kleene was. And Kleene gets ways less credit for all this than he deserves. Dude was clearly the first programmer. I mean sure, Church wrote the first language, Gödel wrote the first compiler, and Turing made what was arguably the first hardware design, but by that same standard, Kleene made:

- Wrote the first standard library.
- Found the first critical vulnerability (λ calculus inconsistency).
- First to have contact with all three of the above and to demonstrate their equivalence.
- First to clean up and popularize the ideas in his (frighteningly technical) _Introduction to Metamathematics_.

1: What do you mean "first standard library"?

0: Well we saw up above how lambda calculus doesn't even come with built-in booleans or integers. And Church didn't even think lambda calculus was powerful enough to express the function $f(x) = x-1$ where x is a positive integer. Kleene's the one who "implemented" all the types and functions that built things from that totally useless level all the way to what eventually became "all computable functions." So Kleene's definitely being humble.

1: Sounds like it. It's crazy I've never heard of this guy before.

0: For real. And from Church's perspective, imagine this grad student of yours who's never even taken a logic class before comes to work with you, learns your system, and then he just keeps knocking off one problem after another until the two of them ended up going from thinking $f(x) = x-1$ is too hard, all the way until Church himself got convinced that _all possible computations_ were representable inside this system.

1: How did Church get convinced?

0: Kleene won't admit this, but it was his "programming" that convinced Church. I mean sure Church designed the lambda calculus, but Kleene figured out how to use it like a frighteningly technical nerd.

1: How do you know?

0: Just read Church's papers. He makes it extremely clear. I swear he cites Kleene in one paper like a hundred times. Check it out.

_(Narrator: 0 clears 0's throat.)_


## Kleeneliness is next to Gödeliness

### Or: Kleene Kleene Kleene
### Or: The First Programmer
### Or: The First Standard Library
### Or: The First Critical Vulnerability
### Or: The First RTFM
### Or: Frighteningly Technical


![[kleene-1.jpg]]


0: Ok so, this is from Church's 1935 paper "An Unsolvable Problem of Elementary Number Theory." This came out about 7 months before Turing's famous paper that showed the same thing. 

1: No way!

![[church-says-kleene-kleene-kleene-00.png]]

0: Turing's paper broke new ground in different ways, but Church got there first.

1: Never heard that before.

0: And if we read this paper, it's pretty clear that "Church" getting there first is like 80-90% Kleene.

1: Kleene's not even a co-author though.

0: Not sure why. Church generally seemed like a generous dude. But just drag your eyes lazily over the pictures below this. This is all from the same paper.

![[church-says-kleene-kleene-kleene-01.png]]


![[church-says-kleene-kleene-kleene-02.png]]


![[church-says-kleene-kleene-kleene-03.png]]


![[church-says-kleene-kleene-kleene-04.png]]


![[church-says-kleene-kleene-kleene-05.png]]


![[church-says-kleene-kleene-kleene-06.png]]


![[church-says-kleene-kleene-kleene-08.png]]


![[church-says-kleene-kleene-kleene-09.png]]


![[church-says-kleene-kleene-kleene-10.png]]


![[church-says-kleene-kleene-kleene-11.png]]


![[church-says-kleene-kleene-kleene-12.png]]


![[church-says-kleene-kleene-kleene-13.png]]


1: Damn that's a lot of Kleene.

0: Church is like "Our integers are different.

![[church-says-kleene-kleene-kleene-14.png]]

0: But this proof is Kleene.

![[church-says-kleene-kleene-kleene-15.png]]


![[church-says-kleene-kleene-kleene-16.png]]

1: Why is he citing him so much?

0: Kleene implemented everything.

1: Definite first programmer vibes.

![[church-says-kleene-kleene-kleene-19.png]]


![[church-says-kleene-kleene-kleene-20.png]]

1: This is an impressive git blame.

0: Seriously. Church is acting more like a faithful `git blame` implementation than a normal human writing an academic paper.

1: The more I learn about these logic folks the more I like them.

0: How so?

1: I dunno. They're nerds. It feels familiar.

![[church-says-kleene-kleene-kleene-21.png]]

1: Church is like "I'm still here guys, I'm gonna say Kleene some more."

![[church-says-kleene-kleene-kleene-22.png]]

1: Good lord man.

![[church-says-kleene-kleene-kleene-23.png]]

1: It keeps going.

![[church-says-kleene-kleene-kleene-24.png]]

1: This is getting ridiculous.

![[church-says-kleene-kleene-kleene-26.png]]

1: I don't even know what he's talking about but this makes me want to read Kleene.

0: We will. That's why I'm showing you this.

1: Why?

0: So you don't get sad when we get to the frighteningly technical book.

1: Uh oh. Is it bad?

0: Nah it's easy. You'll enjoy it.

![[church-says-kleene-kleene-kleene-27.png]]


![[church-says-kleene-kleene-kleene-28.png]]

1: I've got to say, I thought you exaggerating but that was intense.

0: That's from _one_ paper.

1: Damn, Church.

0: Ok but I was unfair to Church earlier. When Kleene said "I have to give the credit to Church, I can't take it myself," he wasn't talking about all the programming, he was talking about Church's Thesis.

1: Which Church's Thesis?

0: The one we didn't talk about yet.

1: Not the PhD one?

0: Not the PhD one.

1: What's the other Church's Thesis?

0: "That's everything."

1: What's everything?

0: Church's Thesis is "Hey Kleene, I think maybe we got everything?"

1: _What's everything?_

0: All the computable functions. Or effectively calculable as they called them back then.

1: That's Church's Thesis? "We're done."

0: That's it.

1: Why "thesis" and not "theorem"?

0: Because it's saying "I think this informal concept equals this formal concept." Can't exactly prove that in the usual mathematical sense. It's pre-mathematics. The hypothesis is that lambda definability captures what we intuitively mean by "computable." Way more powerful than just a theorem.

1: What on earth made him thing "We got ALL computation"?

0: Kleene.

1: Kleene?

0: I mean Kleene's programming. Church was convinced before Kleene was. Then Kleene tried to disprove Church, failed, and got converted.

> Someone: Was Church's thesis just an offhand remark? 
>
> Steve Kleene: Well he spent some months sweating over it. And saying "Don't you think it's so?" And I was a skeptic! When he came out and asserted the thesis I said "He can't be right." So I went home and I thought I would diagonalize myself out. Out of the class of the lambda definable functions and get another effectively calculable function that wasn't lambda definable. Well just in one night I realized you couldn't do that, and from that point on I was a convert.

1: What's a lambda definable function?

0: That's the first programming language.

1: The first programming language?

0: Defined by Church. With standard library implemented by Kleene. And on the basis of which Church's Thesis (this one) was conjectured.

1: Details please!

0: Follow me.

goto: [[lost+found/3/4]]

## (3,4): Church's Numbers

### Or: Formal Function Theory
### Or: How to Write Good
### Or: Church & Kleene
### Or: Be my repl

0: Ok so in Church's system, everything is functions.

1: You've mentioned this already, but I still don't know what you mean.

0: How do you mean?

1: I mean if everything is functions, what do they take as inputs?

0: Functions.

1: What do they return as outputs?

0: Functions.

1: Zero?

0: What?

1: ... That's insane.

0: I know it feels that way at first. But it's not so bad once you implement numbers and booleans.

1: Sure sure, but WHY?

0: Why what?

1: Why do this at all?

0: Why are we doing it?

1: No why was Church doing it? I want to know what was going on inside his head, or at least what might have been. What would make a person say "Y'know what I'm gonna do today? Make a system where 0 and 1 are actually functions." Like that's not a normal behavior and it's not a natural way to think. So I'm curious what was going on in this guy's head that would make him do something like this.

0: Perfect question! Ok so, by the time Church is writing, formal theories had been a thing for a while. ZFC had already done formal set theory. PA had already done formal number theory. It's not unreasonable to think something like "Look guys, those theories you made are cute and all, but the foundations of mathematics or even reasoning itself shouldn't be just whole numbers or unordered collections. The foundations of mathematics should be something more primitive."

1: What's more primitive than those things?

0: Well there are infinitely many natural numbers. And that's not a problem in itself, but we'd like our foundations to be something inherently finite. I mean when a mathematician proves stuff about the natural numbers by induction, they do it with only a finite amount of time and food and paper and pencils and erasers. Finite everything. Foundations should be like that. So it's fine that the natural numbers are infinite, but they're not finite in the same obvious way that the mathematician with the paper is finite and only doing finite stuff. If we truncate the natural numbers at any finite level and say "There are no natural numbers above ten million" or whatever, any mathematician would rightly feel like we'd done a violent ugly hack that made the natural numbers less of what they are. But there's no such feeling when a mathematician uses only finitely many pencils or finitely many sheets of paper. We have no problem with that, and we'd be disturbed if either was infinite. So in that sense natural numbers are way too big to be foundations.

1: What about sets? Sets can be finite.

0: True! But all versions of set theory that have ever been proposed as foundations are much more infinite than the whole numbers are. They tend to all include a sentence that says "ω exists."

1: You mean ω like Cantor's first size of infinity?

0: Well in this case it means "The set of natural numbers," but those are actually the same thing.

1: How are those the same thing?

0: Well no finite number is big enough to be the smallest infinite number. So the set of all natural numbers ends up being the same thing as "the smallest infinite number" in that system. Anyways things are even worse in set theory than in number theory, because there tends to be another axiom that says "If a set X exists, then so does P(X), the set of all its subsets." And that P(X) turns out to always be a bigger size than X, even if X is infinite. So any formal theory that had these two things together grows an infinite number of different sizes of infinity, each larger than the next.

1: I remember. So what was Church thinking?

0: Well taking together both the fact that (i) the natural numbers have an inherent inability to be made finite without it feeling like an ugly hack, and (ii) set theory has such a wildly irresponsibly number of infinite things that it's not clear how it got invited to the foundations party... taking those two things together, you might end up thinking what Church was thinking.

1: _(Narrative voice)_ "So what was Church thinking?, 1 asked yet again."

0: That we need a "Formal Theory of X" for some better X than just X = numbers and X = sets.

It should be something fundamentally finite.

Maybe there's infinitely many Xs for whatever this sought after X type thing is, but it should be possible to _make_ the theory only about finitely many objects made of inherently finite stuff, and finitely many operations on those things. We should be able to "finitize" the theory without it feeling like an awful hack in the way it would be if we said 1 million is the largest natural number.

1: "Without it feeling like"?

0: Yeah, what's the problem?

1: You seem to be suggesting that Church wanted something finite, but his foundation for wanting that was "feelings."

0: Of course. I mean I never knew Church specifically, but that's a totally normal way to think when you're doing mathematics.

1: The more you talk about math, the less I understand what it really is.

0: Good. That means you're listening. So anyways if you thought all the thoughts above, you might end up doing what Church did, so let's do our best to get inside his head.

We're looking for some type of X where we can build a "Formal Theory of X" that doesn't feel fundamentally broken if we don't have infinitely many of them, or if the guts of each one aren't infinite either.

Sure there might be infinitely many Xs for this sought after value of X, but there shouldn't NEED to be.

We're looking for something like that.

Something fundamentally finite or at least something that we could force to be finite without it feeling like the hack job of truncating $\mathbb{N}$. 

Our X should be more general than numbers or sets.

Something that's hiding in plain sight all around us if we could just open our eyes and see what X is.

Something that's painted all over every sentence in every area of mathematics, both the discrete areas like number theory and combinatorics and graph theory, and the continuous areas like calculus and geometry and topology.

Our X should be staring us in the face whenever we open any textbook, and when first hear someone say what it is we should feel a feeling of "Damn. Of course. Why didn't I think of that?"

1: Seems reasonable. What kind of thing is like that?

0: You tell me.

1: Functions?

0: Functions.

0: Ok, so now do we understand why a person might do something like this in the first place?

1: Totally.

0: Ok so Church's notation for functions was λx---

1: You don't have to explain lambdas. I'm a professional developer.

0: Great! So with that notation in hand, Church defined the natural numbers like this:

```
0 := λf. λx. x
1 := λf. λx. f x
2 := λf. λx. f (f x)
3 := λf. λx. f (f (f x))
4 := λf. λx. f( f (f (f x)))
succ := λn. λf. λx. f (n f x)
```

1: Back up, I'm not ready for that yet.

0: You're not ready for the definition?

1: No.

0: What do you mean?

1: I mean that definition makes no sense to me. Back up to the part where they derive that.

0: Derive what?

1: The definition.

0: Church doesn't do that in this paper.

1: Ok can we find a textbook that does?

0: Sure, let's go look.

_(Narrator: 0 and 1 go find some other textbooks on λ calculus.)_

0: This one doesn't have it.

1: Same with this one.

0: Y'know I've actually never seen the kind of derivation you're asking for before.

1: Well what did Kleene use as a repl? 

0: He didn't have a repl.

1: How did he know if something he tried worked or not?

0: I think Church was his repl.

1: Well we can't do that! He's not here. And his paper isn't finished.

0: Don't blame Church, this is just how mathematicians write.

1: I thought he was a foundational person.

0: He is. I just mean if you publish in academic journals you have to write that way. It's basically required. You can write _about_ almost anything. All the journals consistently care about is that you write in an academic sounding way.

1: You're not allowed to write good?

0: You're definitely not allowed to write good in journals. They think that's wrong, and it's only right to write "well." Usually they care less about what you say and more about how you say it. And that makes it basically impossible to explain certain things, like what sorts of thoughts you'd have to have and what sorts of mistakes you'd have to make before you arrive at the definitions that you eventually use to prove stuff from. You're allowed to explain the part after the definitions, because it's possible to write that part well. But you're not allowed to explain the part before the definitions, at least not the parts that can only be explained good. If a thing can only be explained good and not well, you're not allowed to explain that thing.

1: You're not allowed to explain things?

0: You're allowed to explain things, but they have to sound formal.

1: I thought most mathematics wasn't formal.

0: No not "formal" as in formal languages. The journals don't care about formal languages and they certainly don't expect you to write in a formal language. They just want you to write in formal language.

1: I'm gonna scream.

0: I mean fancy English. Or natural language. They just want it to sound fancy.

1: What's the point of that?

0: I don't know, it's a bug that tends to show up in institutions that are culturally overvalued. Whenever a system or group has more social status than it deserves, it always starts talking fancy and insisting the big words matter and anyone who doesn't use the right words is inherently less sophisticated. It's a defensive position. It's not my cup of tea, but one can see where they're coming from.

1: That's dumb. Be my repl.

0: How so?

1: I'll write stuff. You tell me if it's a syntax error or not. Then when I plug things into functions, you evaluate them.

0: Let's split the work of evaluating them 50/50 and you've got a deal.

1: Great!

0: Ok I'm ready when you are.

1: x

0: (Says nothing)

1: So?

0: What do you want me to say?

1: I dunno, say yes if it's ok, or error if it's an error. Is that ok?

0: yes

1: x

0: yes

1: x y

0: hmm

1: That's not very repl of you.

0: I'm thinking.

1: About what?

0: I don't know if that's syntactically valid.

1: I thought you knew this system.

0: I mean, you have a free variable, and then you plugged it into another free variable. They're both functions. Cuz everything's functions. But neither of them has any lambdas in it. So I guess it's syntactically ok, but we can't reduce it any further. It just sort of sits there.

1: Ok, what about this.

λx. x

0: That's ok.

1: What about λx: 3

0: There's no 3 yet.

1: Oh right. How about this?

λx. y

0: That's ok.

1: You're supposed to say yes.

0: yes

1: λx. λx. x

0: error

1: Why?

0: Try plugging something into it.

1: What something?

0: Idk, like 3.

1: I thought there was no 3 yet.

0: Treat it like a variable.

1: What?

0: I just mean plug something into that thing you just defined. Something that doesn't feel like a variable, so you don't get confused.

1: 

(λx. λx. x)(3)

= λ3. 3

0: You can't do lambda of three.

1: Why not?

0: 3 isn't a variable.

1: I thought you said treat it like a variable.

0: Ok nevermind. Use a.

1:

(λx. λx. x)(a)

= λa. a

0: Now plug a into this: λx. λy. x

1: 

(λx. λy. x)(a)

= λy. a

1: What's was the point of that?

0: You got different things. In the (λx. λx. x)(a) example, the "a" got captured by the second lambda thing.

1: What?

0: Umm, one sec, I need to think.

1: Ok this isn't helping. Here let's back up.

0: I don't think we can back up further than this.

1: Of course we can.

0: How?

1: You said this was the first programming language right?

0: Yeah.

1: So obviously there's a bit before this.

0: Before what?

1: Before using it. I'm using the repl. That's WAY past the beginning of a language!

0: What comes before x and λx. x?

1: Implementing the language dummy.

0: Oh right.

0: Where should we start?

1: Definitely not at numbers. That definition from earlier scared me.

0: How can we do anything without numbers?

1: I dunno, I feel like most of programming isn't really about numbers.

0: Good point. Where should we start then?

1: I'd prefer to start with programming.

0: In the language we haven't written yet?

1: Of course!

0: Love it!

1: Finally we get to do programming?

0: Hell yeah. Let's go.

1: Hooray!

goto: [[lost+found/3/5|lost+found/3/5]]

## (3,5): Church's Language

### Or: Premathematics of λ

1: Wait. How can do programming in the language if we haven't written the language yet?

0: Y'know. Pseudo-code.

1: Does that count as programming?

0: Of course! If we didn't write the code before the language existed, how would we know how we wanted it to behave?

1: What's "it" in that sentence? The language or the code.

0: Both.

1: Makes sense.

0: Where would you like to start?

1: Definitely not with numbers. That definition scared me.

0: So where should we start?

1: I'd rather start with like, programming.

0: Which part?

1: I dunno. Maybe if we start with `if`, then `else`, then maybe some data structures or something then I'll have a better idea of what Church was thinking, because so far I don't really get why he'd want to do all this.

0: I'll follow your lead.

## 1. Control Flow: if `if` then `then` else `else`

1: How do I start?

0: You said you want to start by implementing `if`.

1: In what?

0: In functions!

1: How is `if` a function?

0: It's not. But we need to make it be one.

1: Why?

0: Cuz all we have is functions.

1: Ok, um...

```
def if(???):
	return what?
```

1: I'm definitely stuck.

0: No you're not! That was a great start.

1: How was that a great start?

0: Because now the rest is obvious. Here watch:

```
def if(if, then, else):
	if if
	then then
	else else
```

1: What the hell is going on zero?

0: I mean if `if` is a function, then it takes three things:
1. A boolean called `if`.
2. A stuff called `then`
3. A stuff called `else`

1: What's a stuff?

0: Whatever stuff you want to do. Like a code block. Any code.

1: Can we call the boolean something different? This is hurting my head.

0: Sure, refactor however you want.

1: Ok how's this?

```python
def if_then_else(condition, then_do_a_thing, else_do_b_thing):
	# Ok this is gonna be a problem...
	# Umm...
	if condition: # TODO: Implement if
		return then_do_a_thing
	else: # TODO: See above
		return else_do_b_thing
```

0: Great!

1: Zero that was a joke.

0: Seemed totally reasonable to me.

1: ZERO COME ON. Obviously I can't use `if` to implement `if`. I just got stuck and gave up.

0: I don't think you got stuck at all! Here let's re-write it in Church.

1: What?

0: I mean that pseudo-code looks like python. If we re-write your pseudo-code in Church, it sort of makes sense. Watch:

```
if_then_else = λc λa λb: c a b
```

1: What the hell's going on there?

0: It's just an abbreviation for your code. It means this:

```python
def if_then_else(c, # ondition
				 a, # a thing to do if c is true
				 b, # b thing to do if c is false
				 )  # that's it.
```
0: See?

1: But you didn't write the function body. That's just the signature.

0: The body is the same.

1: Same as what?

0: The signature! Look:

```python
def if_then_else(c,
				 a,
				 b,
				 ):
				 return (c
						 a
						 b
						 )
```

1: Is this actually an idea or are you just stalling for time?

0: It's your idea! I'm just rewriting your implementation by making the variable names shorter.

1: But my implementation was a joke. I used `if` inside of `if`. That was cheating.

0: Well obviously we need to use `if` inside of `if` or else it won't act like `if`.

1: Come again?

0: I mean unless we do something iffy in the implementation then it won't be iffy enough to act like if!

1: I agree that this is iffy.

0: Here look. It's already there in the code. I'll reformat it so it's clearer.

```python
def if_then_else(c, a, b):
	return c a b
```

1: What does that `return c a b` mean?

0: Oh sorry, in the top line I was writing python-y but then on line two I accidentally slipped back into my native language.

1: What?

0: The shell!

1: Oh right.

0: I was trying to write a normal function call, I just pronounced it with a shlaccent.

1: I still don't see how this is `if`.

0: It's obviously `if`! Here look:

```python
def if_then_else(c, a, b):
	return c(a, b)
```

1: I'm even more confused now.

0: Look back at your definition.

_(Narrator: 1 looks back at 1's definition.)_

1: I don't see how that helps.

0: Here I'll rewrite it.

```python
def if_then_else(c, a, b):
	if c:
		return a
	else:
		return b
```

1: It's still iffy.

0: It better be. If it's not iffy it's not if!

1: Can you stop with the puns and explain how your thing is my thing?

0: Pass a bool into both.

1: We didn't implement bools yet.

0: Well we also didn't implement errors so it's guaranteed to work!

1: You're the weirdest programming teacher.

0: Just do it.

1: Ok...

```python
#################
### 0's thing ###
#################

def if_then_else(c, a, b):
	return c(a, b)

# Now let's pass in `true`,
# even though we didn't
# implement it yet...
if_then_else(true, a, b)

# the true goes into the
# function and becomes
return true(a, b)

# which is just
true(a, b)

# Um...
# Ok I'm stuck. Let's go do mine.

#################
### 1's thing ###
#################

def if_then_else(c, a, b):
	if c:
		return a
	else:
		return b

# Pass in a true
if_then_else(true, a, b)

# the true goes into the function body
	if true:
		return a
	else:
		return b

# this one's easier to reason about.
# obviously this is just
return a

# which is just
a
```

1: Did I do it right?

0: Did you get any errors?

1: We didn't implement errors.

0: Well we didn't implement `if` either but you just used it twice.

1: That's true. Was that allowed?

0: Any errors?

1: No.

0: Great! I'd say we're on the right track.

1: I still don't understand your implementation.

0: Do you understand yours?

1: Yes, but mine was cheating.

0: Well mine's the same as yours, but mine isn't cheating.

_(Narrator: 1 looks back at 0's `if`.)_

```python
def if_then_else(c, a, b):
	return c(a, b)
	
>>> if_then_else(true, a, b)
true(a, b)
```

1: How is yours the same as mine?

0: Well it better return `a` like yours did or else it's not `if`. Because yours is definitely `if`. And yours returned `a`.

1: So yours behaves like this?

```python
>>> true(a, b)
a
```

0: I think it has to.

1: But we didn't define `true` yet.

0: I think we just did.

1: How?

0: Well `true` had better take two variables and return the first one.

1: What do you mean "had better"?

0: Well if it doesn't act like that, then my `if` doesn't act like `if` and I'm gonna have to start over. But if it does act like that, then I already implemented `if` and `true`, so the number of things I've implemented is either zero or two, and I'd prefer the latter, because in that case I'm ahead of you.

1: _(Skeptical)_ I feel like you're getting ahead of yourself.

0: Good point, we haven't done `false` yet. And until we have `false`, we can't say we're done with `if`.

1: How do we implement `false`?

0: I dunno. Pass it in.

1: I would remind you that we didn't implement it yet, but your weird backwards reasoning seemed to work last time, so what the hell...

```python
# Mine obviously does this:
>>> if_then_else(false, a, b)
b

# And yours is weird, same as before
def if_then_else(c, a, b):
	return c(a, b)
	
>>> if_then_else(false, a, b)
false(a, b)
```

1: What's `false(a, b)`?

0: Well it had better be `b` or I'm gonna have to start over.

1: Who decides if it gets to be `b`?

0: I think `false` gets to decide.

1: Who gets to decide how to implement `false`?

0: I think we do.

1: This feels illegal.

0: It's totally fine. Here look.

```python
def false(a, b):
	return b
```

0: And now we've implemented `false` too!

1: I'm kind of mad that this keeps working for you.

0: You're mad that it keeps working for _us._

1: How do we know if we cheated?

0: What do you mean?

1: I mean we're supposed to be implementing Church's λ language, but so far we've been speaking slang and pseudo-code and it all feels a bit iffy.

0: It had be---

1: Yes yes. How do we check if this all works in Church?

0: Well, let's write the same thing in Church and see if it works.

1: How will we know if it works?

0: I guess we'll have to use the language.

1: Again, I would complain, but this seems to be working.

0: I'll follow your lead.

1: What do you want me to do?

0: Take the iffy stuff we just did and say it in Church.

1: This?

```python
def if_then_else(c, a, b):
	return c(a, b)
```

0: Yeah.

1: How do I say it in Church?

0: Easy. You just go:

```sh
# And the L||D sed...
sed -E                            \
    -e '1s@[(]@ = @'              \
    -e '1s@(.)(, |[)])@λ\1@g'     \
    -e 'N;s@(def |\s+return )@@g' \
    -e 's@(, |[()])@ @g'          \
    -e 's@:@.@'
```

1: Simple enough.

_(Narrator: 1 runs the sed.)_

1: Ok it looks like this now:

```
if_then_else = λcλaλb.c a b
```

1: Is that right?

0: Has to be.

1: What's going on here?

0: It's just Church-lang.

1: What's the dot?

0: Think of it as a colon and it'll feel more familiar. The Church-lang code above is the same idea as this:

```python
def if_then_else(a,b,c): return c(a,b)
```

or equivalently:

```python
if_then_else = lambda c,a,b: c(a,b)
```

Now technically, in order to be Gramatically Correct Church[^1] that compiles correctly[^2] we have to replace all the multiple argument functions with single argument functions returning functions, like this:

[^1]: Or: gcc.
[^2]: Or: cc.

```python
if_then_else = lambda c: lambda a: lambda b: c(a)(b)
```

1: _(Looking back at the iffy stuff)_ How do we know if it worked?

0: I think we have to use it.

1: How do we use it?

0: I dunno, pass in a `true`.

1: Into what?[^3]

[^3]: 
	1: Into what?
	
	0: Into the function `if_then_else = λcλaλb.c a b`.
	
	1: No, I mean: When I pass something in to that function , does it go into the slot on the left (where the `c`  is) or the slot on the right (where the `b` is)?
	
	0: Why are you asking me? We're inventing this language after all.
	
	1: So I can pass in the `true` to any slot?
	
	0: No. I was saying, we _could_ design the language either way, but in this case we already decided which slot stuff goes in. If you need a hint, look at two code blocks above this one, in the python example with the three `lambdas`.
	
	1: Oh, I feel dumb.
	
	0: No worries, I have to remind myself about this stuff too.

0: This:

```
if_then_else = λcλaλb.c a b
```

1: Ok so...

```
# if we take the code here:
if_then_else = λcλaλb.c a b

# and pass in a true, we get
if_then_else(true) = λaλb.true a b = ?...
```

1: I'm confused. Why are there still λs in there?

0: You forgot to pass in two code blocks that tell the `if` what to do.

1: We didn't implemen--- Nevermind. I'm seeing a pattern here.

0: Pick up where you left off.

1: Ok, so let's pass in two imaginary code blocks `A` and `B` that say what to do when the condition's true or false.

```
if_then_else(true)(A)(B)
= (λcλaλb.c a b)(true)(A)(B)    # by definition
= (λaλb.true a b)(A)(B)         # pass the true into the c slot
= (λb.true A b)(B)              # pass the A into the b slot
= (true A B)                    # pass the B into the a slot
= true A B                      # ok i'm stuck
```

1: Now what?

0: Well we already defined `true`.

1: Oh right.

0: So now we just say it in Church, like this:

```python
# In the pseudo-code from earlier (non Church lang)
>>> true(a, b)
a
```

0: In Church lang, we pronounce it like this:

```
true = λaλb.a
```

1: How do I use that?

0: Plug it into true.

1: Plug true into true?

0: By definition!

1: All your worst nonsense somehow makes more sense than your best non-nonsense.

0: That's how truth works! Now show me how true works.

```
if_then_else(true)(A)(B)

...                             # all the steps I did above

= true A B                      # now let's plug true into true (O_o)
= (λaλb.a) A B                  # plug in the `then` code path
= (λb.A) B                      # plug in the `else` code path
A                               # I think this means it worked?
```

0: Of course that means it worked!

1: "Of course" how?

0: We plugged a `true` into `if` and the `then` branch popped out!

1: So if we pass `false` in we get `B`?

0: We better! If not, that wouldn't be very iffy.

1: Here I'll check, I think I'm getting the hang of Church lang.

```python
# This was our `false` in pseudo-code
def false(a, b):
	return b
```

1: So if we pronounce that in Church, we say

```
false = λaλb.b
```

1: Now let's plug `false` into the `false` slot of `if` and toss two pretend code blocks in too, same as before:

``` 
if_then_else(false)(A)(B)
= (λcλaλb.c a b)(false)(A)(B)   # by definition of if_then_else
= false A B                     # i'll just plug in all three this time
= (λaλb.b) A B                  # by our definition of false
= (λb.b) B                      # plug in the A
= B                             # (λb.b) is the identity, so we get B
```

0: It's false!

1: I messed up?

0: No! I mean hooray, our false worked like false. It's a true false!

1: I'm kinda surprised but this is actually making sense.

0: 1derful! Onward!

1: What should we do now?

0: I dunno, maybe we're ready for numbers?

1: How were zero and one defined again?

0: I think that's up to us.

1: Sure sure, but I mean how did Church define numbers again? I forgot.

0: I think it was:

```
0 := λf. λx. x
1 := λf. λx. f x
2 := λf. λx. f (f x)
3 := λf. λx. f (f (f x))
4 := λf. λx. f( f (f (f x)))
succ := λn. λf. λx. f (n f x)
```

1: Yeah I don't think I'm ready for numbers yet.

0: Why not?

1: Because I have no idea how to justify that definition with the stuff we've built so far.

0: So what should we do next?

1: Dunno.

0: Ok 1st lets decide what to do next. But 0th let's recap what we've implemented so far.

```
##############################
### the λ standard library ###
###       by 0 & 1         ###
##############################
if    := λa. λb. λc. a b c
true  := λa. λb. a
false := λa. λb. b
```

1: Wild.

0: What?

1: Until you renamed the variables, I didn't realize `if` was `λa. λb. λc. a b c`.

0: What's wrong with that?

1: It's like... nothing.

0: Not true. Zero is nothing. We didn't define zero yet.

1: I mean it's so minimal. It's like essentially "not defined."

0: Not true! Not's not defined yet, nor are Nor and And or Or.

1: ZERO STOP RECURSING!

0: It's hard in λ lang. Everything's a recurse word.

1: _(Smiling and frowning at the same time, somehow)_ ... I hate you.

0: What next?

1: Well now that we've got booleans, I guess we could do `and` and `or` and `not` and stuff.

0: Perfect! Let's go.

## 2. Logic and (Logic or (Logic and not not Logic))

> [!Editor's Note]
> The following section uses a somewhat different notation for the λ calculus than the section above, with the section below using `:` and preferring spaces in places where the above section used `.` and no spaces, respectively. Further, while the section above uses `true` and `false`, the § below uses `T` and `F`. Based on these and similar inconsistencies, it has often been suggested that the section below was written by a different Author or Authors than the section above. Were this to be the case, of course, we are consequently forced rather forcefully to the corollary assumption that the Author (or Authors) of whichever-of-these-two-sections-came-after[^4] was (or were) sufficiently familiar with the work of the Author (or Authors) of whichever-of-these-two-sections-came-before[^5] that he (or she (or they)) was (or was (or were))[^6] able to emulate his (or her (or their))[^7] writing style(s) with sufficiently high fidelity that they sound \\
> damn near identical bc both sound pretty weird so it'd be weird if it was 2 ppl writing the 2 things bc idk not many ppl write like that or whatever ok back to the thing.

[^4]: E.N. F.N. 1: (in the historical chronology of the publication and distribution of the document known as `sudocode`, not the chronoloy of the surrounding narrative within the book)

[^5]: E.N. F.N. 2: (same addendum as in supra E.N. F.N. 1.)

[^6]: E.N. F.N. 3: respectively.

[^7]: E.N. F.N. 4: ibid.

1: I'm stuck.

0: Already?

1: I think so. I mean, I don't entirely know how we invented `if` up there.

0: Sure you do! You were there the whole time.

1: I know, but it felt sort of like a shell game.

0: "Shell game" as in `man(6)`? How's it like---

1: No. I mean you're talking as if we're "inventing" or "deriving" all these definitions using some "process."

0: We are!

1: But to be honest I feel like you did some sort of magic trick where you slipped the standard definition into a really long conversation one piece at a time, and then somehow tricked me into thinking that I contributed to some kind of creative process, which I don't really feel like I did, and I don't like that feeling because I _did_ like the feeling I had briefly when I felt like I actually _did_ derive the definition like you said.

0: Can you complain that complaint a bit briefer?

1: I'm not convinced I understand what we just did.

0: Why aren't you convinced?

1: Because I don't know how to repeat it.

0: Repeat what?

1: Like the whole process. We sort of "derived a definition" up there. Seems like an important skill. But I'm not entirely sure what the rules of the game are.

0: There aren't any rules. We're inventing th---

1: Ok but that's not true.

0: Why not?

1: Because if there were really "no rules," then we could just define `and` in λ-lang to be `true` all the time no matter what we pass to it.

0: That's allowed!

1: _Sure but it's a pretty bad definition of `and`!_

0: What counts as a good definition?

1: ONE THAT ACTS LIKE `AND`!

0: Perfect. What does it mean to act like `and`?

1: Obviously, it needs to take two arguments.

0: Well, write that.

1: How?

0: Pseudo-code!

1: But there aren't multiple argument functions in λ-lang zero. And there don't seem to be type signatures or anything at all, at least not anything I can use to write _"this function takes two arguments" _even in pseudo-code.

0: Why not write this?

```
and = λa λb: (?)
```

1: What's the `(?)`

0: I don't know. We haven't decided yet.

1: Ok, now what?

0: What does `and` spit out when we pass two booleans in?

1: Another boolean.

0: Ok, write that for me.

1: Zero I don't know how to write that. This language is insane and it has zero features.

0: Plug in a `T` and `F`.

1: To what?

0: To that `and` we're implementing.

1: Like this?

```
and T F = (??)
```

0: Exactly!

1: What does that prove?

0: You said it yourself up above.

> 0: What does `and` spit out when we pass two booleans in?
> 
> 1: Another boolean.

1: So what?

0: Well, that's major progress!

1: How?

0: Because now we know that `(??)` thing you wrote has to be a boolean.

1: How does that help?

0: Well we already implemented booleans right?

1: Yeah.

0: What were they?

1: Weird two argument functions.

0: Mind reminding me how they looked?

1: They were those weird two argument functions remember?

```
T = λa λb: a
F = λa λb: b
```

0: Wonderful progress!

1: How is that progress?

0: You said it yourself. Booleans in λ-lang are two argument functions.

1: HOW IS THAT PROGRESS ZERO?

0: Put two booleans into `and` and `and` returns a boolean right?

1: Yeah.

0: And that boolean it returns is a two argument function, so now we can write this:

```
and T F = λa λb: (???)
```

1: Oh my god I think I'm starting to understand this.

0: Starting to understand `and`?

1: Starting to understand premathematics!

_(Narrator: It's not necessarily mathematics, that's just what it's called for historical re---)_

1: How to derive definitions.

0: What do you feel you understood just then that you didn't befo---

_(Narrator: 1 isn't listening to 0 or to Narrator.)_

1: --can do with this! Like how to get inside Church's head, how to understand what a person would have be _thinking_ to do crazy stuff like defining booleans as two argument functions, why is this not taught? This is the most... I feel like we could do _anything_ with this.

0: You seem excited.

1: Hell yeah!

0: What changed just now?

1: I got it!

0: Explain it to me.

1: Ok, here's how you derive a definition.

You just don't decide on anything about it until you need to.

You do absolutely nothing, then you go ahead and start using it!

The definition I mean.

It's lazy evaluation.

To derive a definition of `and` or `or` or `if_then_else` or `T` and `F` or whatever in an _arbitrarily unfamiliar system,_ you just do nothing -- be lazy -- and start using the def'n _inside the system._ 

The system will tell you when you need to decide.

Using stuff is the only way to know how it wants to be defined.

_(Narrator: The file falls into a high energy and almost manic (and a bit sweaty) sort of silence.)_

1: I love this! What should we do next?

0: We didn't actually do `and` yet.

1: But I get it now. I totally get it.

0: Want to do the honors?

1: Hell yeah.

Ok so...

```
# 1: Suppose we're Church.
# We're inventing λ-lang.
# We want to define 'and',
# but there's no textbooks
# on λ-lang yet b/c we're
# Church and we're like,
# inventing it ourselves.
#
# Here's how we can derive
# the definition of 'and',
# as if the definition was
# just any old calculation.
#
# 1. Just
# 2. Start
# 3. Using
# 4. It.
#
# For example:

and = ?

# Now suppose we want to
# call it. It takes two
# arguments, because our
# everyday concept of
# 'and' takes two args.
# So now we write:

and = λp λq: (?)

# and it returns a bool,
# and back when we invented
# if_then_else we decided
# that bools are two arg
# functions, like this:
#
# λa λb: (??)
#
# so our choice
# from earlier about how
# to implement bools means
# that now we can write
# this about 'and':

and = λp λq: (some boolean)

# and now we can write

and = λp λq: λa λb: (??)

# and that middle colon
# doesn't actually mean
# anything, we could
# write the same thing
# like this if we wanted:

and = λp λq λa λb: (??)

# now we're done until
# we run into a situation
# where we need more
# things to be true about
# the definition, for
# example, suppose we
# pass in two Ts, like this:

and T T = (λp λq λa λb: (??)) T T
        = λa λb: (?? with p and q replaced with T)

# We haven't even written
# the function body yet,
# but it had better be T,
# because if our definition
# of `and` didn't satisfy
# `and T T == T` then it'd
# be a pretty lame definition
# of and. So now we can say:

and T T = λa λb: (?? with p and q replaced with T)
        = T         # because we insist, right now
        = λa λb: a  # because of how we defined bools

# So now we know a new thing:

(?? with p and q replaced with T) = a

# where that ?? was the entire
# function body of `and` that
# we didn't even write yet!

# I need some new notation.
# Let's write (stuff) instead
# of (??) and think of it as
# an expression we didn't write
# yet that might have variables
# in it, in places we haven't
# decided on yet.

# So here's what we know so far:

# Fact 1:
#
# and = λp λq λa λb: (stuff)
#
# And we don't know what (stuff) is,
# but we know one thing about it,
# namely:
#
# Fact 2:
#
# stuff(p=T, q=T) = a
#
# Or in other words, whatever stuff
# is, it has to turn into 'a' when we
# pass T into the p slot and
# pass T into the q slot.
#
# To derive more facts, we need to use

# Um...
```

1: Oh no zero I'm stuck again.

0: No you're not.

1: I'm not?

0: Not at all. You know three more things about `and`!

1: Where did they come from?

0: From our intuitive idea of `and`.

1: What are they?

0: Like how `and F T` is `F` and all that.

1: OH! Of course. Wow I really spaced there. Ok back into the code block!...

```
# 1: Right ok...
#
# So now..
#
# Oof, I'm getting kinda tired.
```

1: Zero!

0: I'm here.

1: This is taking forever.

0: That's ok, you're new.

1: But I'm a professional devel---

0: I mean you're new to premathematics.

1: Why do you call it that? "Premathematics"?

0: Just a word I stole from some textbook.

1: Which textboo---

0: There are only like zero textbooks that talk about this whole process -- deriving definitions, I mean -- so I just took the word from the first textbook I ever encountered that actually explained the whole process. Around that time is when I got kinda obsessed with it.

1: I'm kind of loving it too but it's taking forever.

0: That's ok, you're new to it.

1: Is there a quicker way of doing this stuff?

0: Absolutely! Totally changes how you read textbooks, once you get it. It's hard to read a standard mathematics textbook after that without getting mad. The damn things are all half-complete, every one of em.

1: So how would you finish the `and` derivation? I feel like I get it but at this rate it'll take forever to derive the definitions of numbers and data structures and all the other bits of programming.

0: Here, I'll speed us up.

1: Don't skip steps though.

0: Of course. The best thing about premathematics is that once you 'get' it, it feels like every other explanation is skipping steps. But I'll try to skip some of the commentary. If anything's unclear, it's your job to let me know.

1: Deal!...

0: Ok so...

_(Narrator: 0 continues the logic section (of the fifth file (of the lambda calculus section (of the lost+found directory (of the book (or whatever this is))))))_

0: I'd finish up the derivation of `and` like this...

---

> INSERT IMAGE OF PHYSICAL NOTEBOOK
> EVENTUALLY REPLACE WITH EXCALIDRAW
> ALSO STAND UP AND GO WORK SOMEWHERE
> ELSE, IT'S TIME TO REBOOT YOUR BRAIN.

---

## 3. Data Structures = (Data, Structures)


## 4. Arithmetic (Succ n' friends)

1: Ok this time don't give away the answer. I want to try it myself and see if I get it right.

0: I'm afraid that's not how this works.

1: You're gonna tell me the answer against my will?

0: No, I mean it's not up to me to say what's right. We're implementing the language remember?

1: But how will we know if we get it right?

0: Same as any code. We just have to use it and see if we hate it enough to refactor.

1: Makes sense. Where do we start?

0: Well I think I'll start with zero and one. You can start with whomever you like.

1: You're an idiot.

_(Narrator: 0 and 1 each work independently on their own definitions of zero and one.)_

1: Got one.

0: One sec, I'm not done typing yet.

_(Narrator: The 0 character types a few more characters.)_

0: Ok I'm done.

1: How did you do it?

0: I did this.

```
0 = λaλb.b
1 = λaλb.a(b)
2 = λaλb.a(a(b))
3 = λaλb.a(a(a(b)))
```

0: What did you do?

1: I didn't see the point of having two variables. I just used one. Like this:

```
0 = λa.a
1 = λa.a(a)
2 = λa.a(a(a))
3 = λa.a(a(a(a)))
```

0: Hmm.

1: Which definition is better?

0: I dunno.

1: How do we find out?

0: I think we just have to use both and see which one we like better.

1: How do we "use" them?

0: I dunno, let's try to add one.

1: Add me?

0: No, I mean let's try succ.

1: Do what now?

0: This. Successor. Like the function f(n) = n+1.

1: Oh ok, I misheard. Isn't `succ n` just

```
succ n = a(n)
```

So like

```
4 = a(3)
```

Or for your definition, since

```
3 = λfλx.f(f(f(x)))
```

Wouldn't we just have

```
4 = f(3)
```

Like wrap one more copy of the function around it?

0: I dunno, substitute in the definitions of 3.

1: Ok.

```
4 = a(λa.a(a(a(a))))
```

Wait, I'm confused. Is having the lambda inside like that is allowed? This feels wrong.

0: Hey 1, I made progress! Come look!

_(Narrator: 1 goes over to see what 0 accomplished.)_

1: Zero, you just wrote

```
succ n = ?
```

1: That's not progress.

0: I think it is.

1: Ok then.

_(Narrator: 1 quickly writes a few characters.)_

1: _(Sarcastically)_ "Hey 0 I made progress."

0: Great! Let me see.

_(Narrator: 0 goes over to see what 1 accomplished.)_

0: Beautiful!

1: _(Confused)_ I was being sarcastic. I didn't do anything.

0: Sure you did!

1: Zero, I literally just wrote

```
succ n = m
```

1: I was making fun of you. This isn't progress.

0: I think it's wonderful progress.

1: You're acting weird again. Why is this 1derful?

0: Well we haven't agreed on which definition of numbers to use yet, but we each have our own definition, so I can do this:

```
succ = λn λ? λ? (stuff)
```

1: Explain?

0: Well whatever succ is, we know it takes an number n and spits out a number m. So I turned

```
# this
succ n = m

# into this
succ = λn (stuff)

# and since it spits out a number m,
# that (stuff) bit has to be a number,
# and since numbers in my definition
# are two argument functions, I wrote
succ = λn λ? λ? (stuff)
```
1: Are those question marks the same question mark or different question marks?

0: Different. I guess that wasn't clear. Here:

```
succ = λn λf λx. (stuff)
```

0: This isn't really saying anything new. It's just the idea that succ returns a number too, and my numbers are functions of two arguments. Now we just have to implement the `(stuff)`!

1: Isn't that the entire problem? How is this progress?

0: Or course it's progress! Now we know how to undress the numbers!

1: Un-what the who now?

0: You had a good idea about wrapping the function around one more time, but you were wrapping it around the outside. Now that the numbers are naked, no more lambdas wrapped around them, maybe we can add the extra copy of `f` down here.

1: Like how?

0: Watch.

```
succ = λn λf λx. f(n)
```

1: Wait I think this has the same problem as mine. That `n` has lambdas on it.

0: Show me?

1: Here look.

```
3 = λf λx. f(f(f(x))
```

So

```
3 g y = g(g(g(y)))
```

0: What are `g` and `y`?

1: I used different letters because I wasn't sure if I'm allowed to plug `f` and `x` into a thing that already has those.

0: I think it should be ok.

1: Ok then I just meant this:

```
3 f x = f(f(f(x)))
```

0: Great! Or in general:

```
n f x = naked n
```

0: So now

```
succ = λn λf λx. f(naked n)
```

Or

```
succ = λn λf λx. f(n f x)
```

1: Ok wait, in my definition of numbers, I'd have:

```
succ = λn λa. a(naked n)
```

Or:

```
succ = λn λa. a(n a)
```

0: Wonderful! We're done!

1: With what?

0: We both know how to `succ` any number.

1: But we didn't even agree on how to define numbers yet.

0: That ok! Even if we're succ'ing different things, at least we're both succ'ing something.

1: Now what?

0: Well what else can we do with two numbers?

1: The usual stuff I guess. There's:

- addition
- multiplication
- exponentiation
- should we do subtraction maybe?

## 4.5: Arithmetic Succs

### Or: Predecessor turns out to be surprisingly hard
### Or: Kleene at the Dentist
### Or: Kleene'ing Teeth

0: Well Church himself didn't actually think this was enough to capture ALL of computation! 

1: He didn't?

0: Hell no! You'd have to be insane to think that this was ALL of computation the first time you see it. I mean Church _came up_ with this idea and even HE didn't think that. 

1: How do you know?

0: From Steve.

TODO: 6:50. Church didn't think it would be possible to implement predecessor in lambda calculus. Kleene realizing how to implement predecessor at the dentist.

TODO: 7:15.
> Steve Kleene: So there was no idea at the beginning that this was going to be all effectively calculable functions.

TODO: 7:30.
> Steve Kleene: I kept taking it as a challenge and everything I tried I could work.

TODO:
> Steve Kleene: It was an unexpected fallout that this could represent all effectively calculable functions.

TODO:
> Steve Kleene: The basic work was done between January 1932 and the next 5 or 6 months.

TODO:
> Steve Kleene: Everything I tried, every kind of function I tried to define, every kind of effective operation that I tried to parallel by lambda definability, I probably knocked off within the first 5 months.

TODO:
> Steve Kleene: For us the first concept of lambda definability was after the fact, after having formulated the notion of lambda definable functions as simply the ones for which you could find formulas in this symbolism. And discovering that everything you thought of that you wanted to prove lambda definable you could!... But it was Church, I have to give the credit to Church, I can't take it myself, he said "Y'know, don't you think maybe we've really got ALL the effectively calculable functions?"


## 5. Cursing and Recursing

Y combinator goes here.

## Gödel arrives on the Scene

> Steve Kleene: The first thing we knew of Gödel's paper was one time the mathematics colloquium speaker was gonna be von Neumann. And of course von Neumann had lots of things of his own to talk about but instead of that we got him there and found out he was telling us about Gödel's 1931 results.
> 
> Someone: This was at Princeton?
> 
> Steve Kleene: This was at Princeton and it was in the Fall of 1931. And whether he had the paper itself or not I don't know... 
>
> C. C. Chang: Was this the first you'd heard of Gödel?
>
> Steve Kleene: When we went into this meeting was the first that any of us heard of Gödel. Church was teaching a logic course, Rosser and I were among the students, it was the first that any of us had heard of Gödel. I don't know whether Church was aware of Gödel's 1928 paper on completeness, he never gave it in class, because I... I never had the classical form of the propositional or predicate calculi in my coursework, I learned them for myself afterwards.
> 
> Steve Kleene: So as soon as we heard the lecture, the paper was available. We hadn't noticed it, y'know, we didn't go looking at every journal that came into the library to search it through for papers that would interest us, maybe we should've but we didn't, so of course we went and we read the paper right off.


goto: [[Old - 1]]
## Reminiscences - Church

![[reminiscences-of-logicians-004.jpg]]


![[reminiscences-of-logicians-005.jpg]]


![[reminiscences-of-logicians-006.jpg]]


![[reminiscences-of-logicians-007.jpg]]


![[reminiscences-of-logicians-008.jpg]]


![[reminiscences-of-logicians-009.jpg]]


![[reminiscences-of-logicians-010.jpg]]


![[reminiscences-of-logicians-015.jpg]]

## How to Undress a Number

```
1: Why not this?

succ := λn. λf. f n

0: What's the motivation?

1: I mean based on how we defined numbers, "+1" should just be "wrap another f around it."

0: I'm not sure that's what you did there.

1: How is that not what I did?

0: You're trying to define something like this right?

0 ≈ x
1 ≈ f(x)
2 ≈ f(f(x))
3 ≈ f(f(f(x)))

1: Why the squiggly equals signs?

0: I just meant "You're trying to do that, but without the f and x being free variables" right?

1: Yeah exactly.

0: So let's just toss some lambdas outside.

1: What's the point of that?

0: I dunno. It'll get rid of the free variables.

1: Ok, here:

0 := λf. λx. x
1 := λf. λx. f x
2 := λf. λx. f (f x)
3 := λf. λx. f (f (f x))
4 := λf. λx. f( f (f (f x)))

0: I'm still not sure how to define "+1".
1: Just wrap another f around it.
0: Around the outside?
1: Sure.
0: Like this?

5 := f( λf. λx. f( f (f (f x))))

1: Oh yeah, I guess that's wrong.

0: It's not too wrong though, we just need to wrap the f around the inside.

1: How do we do that if we only have 3 system calls?

0: System calls?

1: Yeah. So far it seems like we only have three.

0: What do you mean?

1: Like this:

System Calls
============
1: mkvar: takes a str, makes a var
2: mkfun: takes a var x and an expr e, makes λ x: e
3: rmvar: takes a fun f and an expr e

0: Hadn't thought of it like that. What do you mean by "str" and "var" and "expr" and "fun"?

1: Obviously, that's "string" and "variable" and "expression" and "function".

0: No no, I mean we only have functions.

1: Sure fine, I mean know there's only one type, but I figured we could just pull an Alonzo Church and give the one type 3 or 4 different names, depending on how we're thinking about it. It's really all the same type though. Everything's Alonzo Church. I mean functions.

0: Ok, as long as it's just following the laws of Alonzo Church.

1: So then how do we define "+1"?

0: Well I think your system calls idea solved it.

1: How so?

0: Here look. We tried this, but it was clearly wrong.

	5 := f( λf. λx. f( f (f (f x))))

0: So to make it right, we just need to get that f inside somehow.

1: How do we do that?

0: With your system calls! Look:

Supposing we start with, say, the number four, namely:

	4 :=  λf. λx. f( f (f (f x)))

Then we can get to five like this:

	4 = λf. λx. f( f (f (f x)))
	rmvar 4 = λx. f( f (f (f x)))
	rmvar (rmvar 4) = f( f (f (f x)))
	f(rmvar (rmvar 4)) = f( f( f (f (f x))))
	mkfun( f(rmvar (rmvar 4))) = λx. f( f( f (f (f x))))
	mkfun( mkfun( f(rmvar (rmvar 4)))) = λf. λx. f( f( f (f (f x))))

1: I don't think you used my syscalls right.

0: (Zero checks the syscall signatures) Oh, oops.

1: But I think I get your idea. Can I define some terms?

0: Always!

1: Ok so:

	undress(4) = f( f (f (f x)))

	f(undress(4)) = f( f( f (f (f x))))

	redress(f(undress(4))) = λf. λx. f( f( f (f (f x))))

And that's 5.

0: I don't think that's what redress means.

1: What?

0: Here look.

	re·dress /rəˈdres/
	1. (verb) To remedy or set right (an undesirable or unfair situation).
	2. (noun) A remedy or compensation for a wrong or grievance.

1: Yeah exactly. That's what I meant.

0: How is that what you meant?

1: Well we didn't ask permission to undress these numbers, so naturally thr redress step is how we make amends.

0: You're the weirdest student I've ever ha---

1: Whatever. Look, we did it!

	succ(n) = redress(f(undress(n)))

0: And now we can remedy or set right the crime we just committed against terminology by rewriting it like this:

	succ := λn. λf. λx. f (n f x)

1: How is that the same?

0: It's clearly the same.

- The succ function takes a number n.
  That's the λn bit.

- Then it returns a number,
  which is a two argument function.
  That's the λf. λx. bit.

- That accounts for the function signature.
  
- Now the internals of the function are just:
  f (n f x)

- And f (n f x) is the same as f(undress(n))

1: How is f (n f x) the same as f(undress(n))?

0: I'm just plugging in values that happen to have the same names as the function's parameters. That's how we undress any number n. Just feed it an unspecified thing named f, and another unspecified thing named x.

1: Got it! What about the redress step?

0: I already took care of that in the lambdas. I just reasoned in reverse, compared to what you did. The redress is the bit where I explained where the

	λn. λf. λx.

bits come from.

1: Great! Now how do we add numbers?

0: We just did that.

1: No no, I mean how do we add numbers other than 1?
```

## A bit more work towards Y premathematics

```
ω f = f(f(f(f(...)))) = f(ω f)

ω = λf. f(ω f)

But we can't put the ω on both sides.

Back to basics

ω = λf. stuff

What's stuff?

Well, two possibilities:
1. stuff is: λx. (?)
2. stuff is: A B
   in which case A should have
   a lambda, so
   stuff is (λx. ?) B

So

1. ω = λf λx. A
   Subquestion: What's A?
   
2. ω = λf. A B
   ω = λf. (λx. A) B
   Subquestion: What are A and B?

In case 2:
- Suppose B has no λ in it.
- Then ω = λf. A[x := B]
- So A has one fewer λ than we thought
- So either case 2 is impossible,
  or else B has a λ in it.

ω = λf. (λx. A) (λy. B)

So then

ω = λf. A[x := (λy. B)]

But then

ω f = A[x := (λy. B)]

- So this is either a contradiction,
  or else:

ω f = f(f(f(f(...)))) = f(ω f)

implies that

A[x := (λy. B)] = f(A[x := (λy. B)])

If that's the case, then

ω = λf. (λx. A) (λy. B)

can be written

ω = λf. (λx. f(...)) (λy. B)

ω = λf. (λx. f(ω)) (λy. B)

ω = λf. (λx. f(
               λf. (λx. f(...))
                   (λy. B)
              )
        )
         (λy. B)

What if 

ω = λf. (λx. f(x)) (λx. f(x))

ω = λf. f(λx. f(x))

ω = λf. f(f)

That's only twice.

What if 

ω = λf. (λx. f(x(f))) (λx. f(x(f)))

Then

ω = λf. f( (λx. f(x(f))) (f))

or

ω = λf. f(f(f(f))))

That's only 4 times.

What about

ω = (λf. f f) (λf. f f)

So

ω = (λf. f f) (λf. f f)
  = (λf. f f) (λf. f f)
  = (λf. f f) (λf. f f)
  = (λf. f f) (λf. f f)
  = (λf. f f) (λf. f f)
  
Um...


What about

ω = λf. (λx. f(x x)) (λx. f(x x))

That's 

ω = λf.   (λx. f(x x)) (λx. f(x x))
  = λf. f((λx. f(x x)) (λx. f(x x)))
  = λf. f(naked ω)

But naked ω is ω f, so

ω = λf. f(ω f)
  
Or

ω f = f(ω f)

```

## Y combinator

1: Recursion?

0:  The Y combinator:

```
Y := λf. (λx. f (x x)) (λx. f (x x))

Y g :=    (λx. g (x x)) (λx. g (x x))
    := g ((λx. g (x x)) (λx. g (x x)))   -- How did we get this again? Nvm.
	:= g (Y g)

Z = g (Z)
Z = g (g (Z))
Z = g( g (g (Z)))
Z = g( g( g (g (Z))))
...
Z = g( g( g (g (...))))

So

Y = λf. f( f( f (f (...))))

Y f = f( f( f (f (...))))
Y f = f(Y f)
Y = λf. f(Y f)
Y = λf. ((λx. f x) (Y f))
Y = λf. ((λx. f x) f(Y f))
Y = λf. ((λx. f x) ((λx. f x) (Y f)))  -- Ok we need to get rid of this Y somehow...

Y = λf (λx. f(x) f(Y f))

```

Show the key equation `Y f → f (Y f)`:

```
Y f
= (λf. (λx. f (x x)) (λx. f (x x))) f
→ (λx. f (x x)) (λx. f (x x))
→ f ( (λx. f (x x)) (λx. f (x x)) )
= f (Y f)
```

## Church's Numbers

### Or: 0 is a two argument function
### Or: 1 is a two argument function
### Or: Booleans are two argument functions
### Or: If is a three argument function
### Or: Plus One is a three argument function
### Or: Minus One may be impossible
### Or: What was Church thinking?

0: Ok before we cover Church's language in detail, I need to warn you. It's pretty weird.

1: Weird how?

0: It's pretty bare bones.

1: How so?

0: It doesn't have most of the things you're used to.

1: Such as?

0: No numbers.

1: No numbers?

0: No booleans.

1: No booleans!?

0: No if.

1: No if!?!?

0: I mean it has numbers and booleans. It also has if and everything else you could want. Just not at first. We have to implement those things ourselves. Starting from functions.

1: What on earth would motivate a person to make a language where numbers and booleans have to be implemented from functions?

---

TODO: Explain the von Neumann encoding from ZFC and the S(S(S...(S(0))...)) implementation in Formal Arithmetic.

---

1: How do you implement numbers using lambdas?


![[church-18.png]]

1: What's going on here?

0: The number 1 is a function that takes two variables. Then it calls the first variable passing the second.

1: Excuse me?

0: The number 2 is the same idea, but it calls the first variable twice.

1: I'm so confused.

0: Here I'll show you. In python it would look like this:

![[church-numerals-in-python-1.png]]

0: Make sense yet?

1: No.

0: Wait, I should correct that. There aren't really any two argument functions in Church's system. It should be more like this.

![[church-numerals-in-python-2.png]]

1: That's worse.

0: Oh and zero would be this.

![[church-numerals-in-python-3.png]]

1: This is insane.

0: Would it make more sense if I wrote it like this?

![[church-numerals-in-python-4.png]]

1: What are `verb` and `noun`?

0: Think of it like a crank. 

1: That doesn't help.

0: I mean "three" is the idea "turn the crank three times."

1: The only crank I see around here is you.

0: Ok what's "three" to you?

1: What's three?

0: Yes, explain the concept to me.

1: Three is, well, thr---

0: You can't say "three" in the definition.

1: Ok, three is any time there are this many of something:

$$\circ \circ \circ$$

0: Does it matter what sort of things they are?

1: No. It's three if there's that many of anything.

0: Ok, what if you want to encode "three" in a language that only has verbs.

1: What do you mean?

0: Like Church's lambda calculus. Everything is functions. How do you encode three?

1: Put three functions next to each other?

0: How do you put them "next to" each other? We don't have lists or tuples yet.

1: Oh right.

0: Or strings, so string concatenation won't work either.

1: So what do we do?

0: Well, what do we have?

1: Functions?

0: Right.

1: What can we do with functions?

0: Let's go see what Church says.

![[church-19.png]]

1: What does this say?

0: It just says "We can plug stuff into functions and vice versa."

1: What's vice versa? Unplug stuff out of functions?

0: Exactly.

1: I'm not sure what I meant by that. What did you mean?

0: What's the opposite of turning `λx: x²` into `3²`?

1: Turning `3²` into `λ3: 3²` for any value of `3`?

0: Exactly.

1: I'm not sure what I meant by that. What did you mean?

0: I mean the 3 becomes a variable there.

1: I don't see Church doing that anywhere in this picture.

0: But that's the idea. He's just saying you can plug stuff into functions, and you can unplug things out of expressions to make functions. Nothing that any programmer hasn't done a thousand times. This isn't a deep thought. It just turns out to be deep as a non-thought.

1: Do you _have_ to talk like this? 

0: Like what?

1: What do you mean it turns out to be deep as a "non-thought"?

0: Well Church himself didn't actually think this was enough to capture ALL of computation! 

1: He didn't?

0: Hell no! You'd have to be insane to think that this was ALL of computation the first time you see it. I mean Church _came up_ with this idea and even HE didn't think that. 

1: How do you know?

0: From Steve.

---

TODO: 6:50. Church didn't think it would be possible to implement predecessor in lambda calculus. Kleene realizing how to implement predecessor at the dentist.

TODO: 7:15.
> Steve Kleene: So there was no idea at the beginning that this was going to be all effectively calculable functions.

TODO: 7:30.
> Steve Kleene: I kept taking it as a challenge and everything I tried I could work.

TODO:
> Steve Kleene: It was an unexpected fallout that this could represent all effectively calculable functions.

TODO:
> Steve Kleene: The basic work was done between January 1932 and the next 5 or 6 months.

TODO:
> Steve Kleene: Everything I tried, every kind of function I tried to define, every kind of effective operation that I tried to parallel by lambda definability, I probably knocked off within the first 5 months.

TODO:
> Steve Kleene: For us the first concept of lambda definability was after the fact, after having formulated the notion of lambda definable functions as simply the ones for which you could find formulas in this symbolism. And discovering that everything you thought of that you wanted to prove lambda definable you could!... But it was Church, I have to give the credit to Church, I can't take it myself, he said "Y'know, don't you think maybe we've really got ALL the effectively calculable functions?"

