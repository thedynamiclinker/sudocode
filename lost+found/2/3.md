## 1. (2,3): Archaic Laws, Forgotten Names

### Or: The History of Logic

---

> _I believe that all mathematicians look upon logic with suspicion._
> Andrzej Mostowski, Reminiscences of Logicians

---

1: Why are we in here?

0: Because you asked for it.

1: Asked for what?

0: Some proper history.

1: You usually just say no. Why did you agree to this?

0: To prove my point to you beyond a reasonable doubt.

1: What point?

0: That one needs a creation story.

1: Was that one as in一

0: _(ahem)_ ...

0: In the beginning...

![[logos-to-logic-3.png]]

1: Zero, for Christ's sake.

0: Just teasing yah a bit.

1: Thank the lord.

0: On a more serious note, the history of logic starts here:

![[aristotle-organon.jpg|400]]

0: With Aristotle in the ORGA---

1: NO. No way. We're not starting with Aristotle.

0: Agreed. We wouldn't benefit much from going back that far. But that's always the risk with any proper history. In academic histories 一 unlike bibles 一 it's extremely hard to know where one should start.

1: One should start by telling you to get started.

0: At the beginning?

1: At the beginning.

0: Well beginnings are tricky, and deciding when they are is a hard problem. But that problem is now our problem, seeing as we've chosen _not_ to do the hard work of compiling a proper creation story, and instead chosen to be lazy by doing the much easier work of covering the History of Logic in the standard non-bible'ed academic format.

1: The _second_ of those two things is the "lazy" choice in your mind?

0: Absolutely!

1: I'm gonna need some convincing.

0: Ok well, in what follows, we're gonna see a very unusual field.

1: Kindergarten?

0: Super advanced kindergarten! See in this era of early prehistory, the study of foundations seemed a bit childish... at best... or mentally ill, at worst.

1: How do you figure that?

0: Are you kidding? Back then, nobody knew that formal theories of logic and arithmetic would eventually turn out to be all that's needed to build a machine that can emulate the logic of any other field.

1: I guess that was a bit of a game changes.

0: Exactly. But before the common era where we all know about The Universal Machine, what would you think if one of your colleagues, or even worse, one of your friends or family, suddenly showed up trying to study these things!

1: What things?

0: Words like "and" and "or" and "not." Elementary arithmetic. Especially if you open their notebooks and find it full of strange symbolic notations they invented themselves, instead of something more respectable, like words.

1: I don't believe it was that bad.

0: Ok then, put your self in their shoes.

1: Whose shoes?

0: Imagine you're a serious adult mathematician, back in the 1600s, 1700s, 1800s, whenever. You're a highly esteemed professor in the mathematics or physics or philosophy department at the University of Serious Adult Academics who study serious adult things.

1: Such as...

0: Well your colleagues have various areas of expertise. One of them is doing some work on Newton's method of fluxions and fluents.

1: What's a fluxio---

0: That's what Newton called the derivative back when he invented calculus.

1: Weird. Why did---

0: Others of your colleagues might be studying other serious adult things, like the insolubility of the quintic by radicals, or Riemann's new prime-counting function and how it relates to his theory of manifolds.

1: What era was this?

0: All of them. The point is that in most any era of the 1600s or 1700s or 1800s, when serious adult mathematicians at serious adult universities looked around at their colleagues, they saw other serious adults doing serious adult things.

1: Where are you going with this?

0: Well one day, one of your colleagues 一 one who you've heard is very intelligent and capable 一 submits a paper, or gives a talk on... oh dear. You haven't the faintest idea what it is. It looks like the ramblings of a mental patient, you whisper to your other colleagues. The gossip spreads.

1: Gossip? About what?

0: As you probe your clearly unwell colleague for more details, you find nothing that looks familiar to you or any of your academic colleagues. Instead, you find notebooks full of pages and pages of strange symbols.

1: Isn't that like, all math?

0: Symbols that aren't standard in any established area of mathematics. And worst of all, the stated goal of all this nonsense research appears to be some kind of schizophrenic desire to both:

1. "Formalize thought" with a "symbolic calculus of all mental procedures", surely too ambitious for any sensible research program by several orders of magnitude.
2. Then, in the same breath, your colleague claims that their technical work mostly focuses on "Elementary arithmetic."

0: They say they're attempting to secure the foundations of rationality itself by studying 一 not the esteemed field of number theory 一 but the basic addition and multiplication of whole numbers, using a language they've invented themselves, and in which they've proved a series of theorems that are of precisely no use to any one.

1: Why no use to any一

0: And plus there exists not one new result in all of it and not one person in the department can read the scribble anyway nor would any one of them want to even if they could or had the times. It's completely illogical.

1: Completely illogical indeed.

0: I mean it's almost as bad as if you came to study with a teacher you'd long admired from a distance, and found that instead of studying modern computing, this once great teacher had lost his mind and was now talking nonstop about bibles and asking you to help him write one!

1: Can't imagine what that's like.

0: But that's the backdrop against which the remainder of this file occurs. The history of logic has one of the strangest histories of any field. The people involved didn't build on each other's work for most of the field's history, and until somewhere between 1900 and 1930, "doing logic" meant constructing an entirely new system to capture "all mental activity" or "all reasoning" or at least a large part thereof 一 from scratch 一 using new symbols and new notations no one had ever seen before.

1: Sounds a bit nuts.

0: Indeed! Any many of the heroes we'll meet in the History of Logic were roundly thought to be nuts, given the behaviors above. That's why it's particularly important for them 一 more than the average mathematical or philosophical type 一 to project an air or sense or certain le _je ne sais quois_ of...

![[font-fancy-formality.png]]

_(Narrator: Zero begins to project a sense of formality, certainly in error, I'm not sure he knows what the word means.)_

---

ABSTRACT

In this file, we shall demonstrate, by way of example, the necessity of the creation story as a genre for properly telling a certain class of histories of a certain class of fields, including but not limited to the history of computing.

The function of a creation story is twofold: A creation story should be designed to be as true as possible, while at the same time allowing an effectively infinite number of historical precursors to be treated as rounding errors or archaeology.

To see the need for a creation story when it comes to the history of computing, we'll begin by demonstrating what would happen to the narrative of the current book if we tried to do without one. We'll see that this attempt leads to an overemphasis on a wacky grab bag of partially cooked ideas and bizarre notations, some of which were legitimately brilliant and ahead of their time, but none of which are relevant enough to the history of computing to be worth mentioning In The Beginning.

---

1: Do we really have to一一

0: Please, n' interrupt pas the abstract, sil vous plait.

1: _(Rolls eyes)_

---

ABSTRACT (Cont'd)

The Creation Story data type solves this problem. Properly executed, the Creation Story is a pragmatic truncation of history at a finite time in the past, before which all events are declared not to be relevant. This is, of course, in any literal sense, untrue, in no small part because the motivation for creating anything (whether a universe or a book) has, as its cause, a set of events that came before it.

Nevertheless, the Creation Story is a pragmatic necessity. If history is a Taylor Series, the Creation Story is its truncation to finitely many terms.  The only alternative is the sort of history that the author of a (very good) book like "Quantum Computing Since Democritus" pokes fun at in the title, in which a field with a substantial but non-infinite history (e.g. quantum computing) is traced back to the first human in recorded history who said something roughly like "The world is made of things, not stuff."

---

1: Hey zero, since you're pretty clearly trying to make fun of academese, you might want a more formal way of saying "things not stuff."

0: The distinction between things and stuff is formal at the linguistic level, as "thing" is a count noun and "stuff" is a mass noun, and as such we are confident that the attentive reader is capable of recognizing that the phrase "things, not stuff" is isomorphic to the phrase "discrete, not continuous."

1: _(Eyes roll harder)_

---

![[font-fancy-ergo.png]]

In this file, we will sketch the prehistory of the field that became computing, to make the case that a proper Creation Story is the right solution to the problems at hand.

---

1: Is this all just a way of punishing me for not wanting to一一

---

![[font-fancy-ergo-iterum.png]]

What follows is a brief histoire of The Field, which will be rounded to zero and treated as nonexistent in the histoire creationis that follows.

---

1: Are you done?

0: Yes. With the abstract.

1: What was the point of that?

0: My point is twofold...

1: Don't start talking like that again.

0: Both to outline the purpose of the historical review below, and to make a broader point about the history of logic in general.

1: Which is?

0: It's damn hard to get started.

1: Clearly. Are you going to start soon?

0: Logic faces an infinitely harder "premathematics" problem than any other part of mathematics. 

1: What's premathematics again?

0: Everything that doesn't show up in the books. Everything you do _before_ you figure out what the right definitions are that'll lead to the theory you end up developing. And how you ended up at the definitions you eventually chose rather than all the others. Logic has a harder problem than any other field when it comes to premathematics. When you create a notation for geometry, number theory, or calculus, you only need it to be powerful enough to talk about those areas. When creating a notation for logic, however, one needs to decide on a notation and a set of basic definitions for the formalization of potentially _all of thought._ Or if you choose to focus only on a subset of thought, then you've got an equally hard problem of deciding up front which parts to exclude and include. You see this difficulty throughout the history of logic, especially in the history of attempts to develop a notation for it, where "it" is "the thing that wasn't yet but eventually became logic."

That's why it shouldn't be surprising in retrospect to see how long it took for formal logic to get started as a field. Logic was an extremely late comer, notwithstanding Aristotle or semi-formal systems like Euclid which involved some embedded reasoning about a specific content domain. The history of mathematics is littered with the bones of all sorts of mathematicians who tried and failed to develop a general system for formalizing thought.

1: For example?

0: _(αηεμ)[^1]_

## 2. The Real History of Logic
### Or: Painful Irrelevant Historical Trash
### Or: Suspicions of Logicians
### Or: Let's Formalize Thought
### Or: Elaborating an instrument with nothing for it to do
### Or: Stay formal, be rigorous, and get diagnosed anyway

> _At the time I was a graduate student, there was a great deal of suspicion about mathematical logic from other mathematicians._
> -John Newsome Crossley, Reminiscences of Logicians

1: Gotta admit, after that section heading I'm curious to see what's coming.

0: Well get ready 1, it's time for _Serious Adult History!_

_(Narrator: Lights flash and music plays for like two seconds before zero proceeds.)_

0: The following is from an 820 page book on the history of mathematical notations.

1: Oh no.

![[history-of-logic-notation-01.png]]

0: It starts with 400 pages about arithmetic.

1: WE'RE SKIPPING THAT.

0: Of course, we're here to cover the real life no-nonsense non-narrative History of Logic, just like you asked for. We'll be using some other books too, not just that one. Lots of content!

1: Are you just gonna torture me until I beg for a creation story instead?

0: No! This'll actually be fun. Check it out.

## 3. Leibniz

### Or: Something like primes

![[leibniz-creation-as-binary-2.png]]

> _When I was a student, even the topologists regarded mathematical logicians as living in outer space. Today the connections between logic and computers are a matter of engineering practice at every level of computer organization._
> -Martin Davis, student of Alonzo Church. From _Influences of Logic in Computer Science._

0: Ok so Leibniz was an absolute badass. Invented calculus, but hated calculation.

> _It is unworthy of excellent men to lose hours like slaves in the labour of calculation which could safely be relegated to anyone else if machines were used._
> -Leibniz, _Machina Arithmetica._

0: Literally a world class mathematician, but thought most math was kinda "meh."

> _For if praise is given to the men who have determined the number of regular solids - which is of no use, except insofar as it is pleasant to contemplate - and if it is thought to be an exercise worthy of a mathematical genius to have brought to light the more elegant properties of a conchoid or cissoid, or some other figure which rarely has any use, how much better will it be to bring under mathematical laws human reasoning, which is the most excellent and useful thing we have.[^2]_
> -Ibidem guy, source Alibi.[^3]

0: He also invented binary.

1: Damn Leibniz, what a man!

0: But more than anything, he desperately wanted to build a universal system for reasoning and computing.

1: When was this?

0: The 1600s.

1: Mein Gott.

0: This dude was literally the most "Foundational" a person could be.

1: For real.

0: Ok so, in Leibniz we see a perfect example of premathematics.

1: What's premathematics?

0: All the mathematics they cut out of the textbooks.

1: Not sure what that means.

0: All the work you do to figure out what the definitions should be.

1: Definitions require work?

0: Of course! And it's where most of the interesting stuff is. Here I'll show you.

1: _(Looks at zero)_

0: No don't look at me, look at the picture.

![[history-of-logic-notation-04.png]]

0: So Leibniz has this "Something like primes" idea where he tries to represent atomic concepts by prime numbers, composite concepts by composite numbers, and universal quantification by divisibility.

1: Sorry I wasn't listening. What's the idea?

0: So Leibniz is like "Ok everybody listen up."

1: They didn't listen up did they?

0: They did not. But Leibniz is like "Ok, guys! Listen to me. Remember how I invented calculus and you all really like that now? Well listen up because this next one is gonna be a hundred times better."

1: He's kinda overselling it huh?

0: He's not.

1: Really?

0: It's at least that good.

1: Wow, what are we talking about again?

0: Logic!

1: Oh...

0: Computation!

1: Oh!

0: He's like "Guys let's formalize thought! All of it. And put it into symbols outside the head where we can manipulate them and then build machines that speak the language so they can manipulate the symbols for us. It'll be great here watch."

1: They didn't watch did they?

0: No but watch anyway.

1: Okee!

0: So everybody goes "How the hell do we formalize thought? Leibniz."

1: Reasonable question.

0: And Leibniz goes:

> _Something like primes!_
> 
> -Leibniz (paraphrased)

1: Something like primes?

0: Something like primes! Here watch.

1. Red: prime.
2. Hat: prime.
3. Red Hat: composite. (1 \* 2)
4. Fat: prime.
5. Guy: prime.
6. Fat Guy: composite. (4 \* 5)
7. In: prime.
8. Fat Guy In Red Hat: (6 \* 7 \* 3)

1: Why is Red Hat the same as Hat?

0: It isn't. Red Hat is Red times Hat.

1: But it's 2 \* 1. That's 2 and that's Hat.

0: No no, that "1" isn't the number 1.

1: Come again?

0: No just... imagine they're primes.

1: You're explaining this real bad.

0: Exactly. Leibniz did too.

![[history-of-logic-notation-05.png]]

1: That was more clear than yours.

0: Of course it was, he's Leibniz.

![[history-of-logic-notation-06.png]]

0: But apparently he felt frustrated that people didn't understand what he was talking about or why it's interesting.

![[history-of-logic-notation-06-2.png]]

> _I have spoken of my \[universal characteristic\] to \[people\], but they have given it no more attention than if I had related a dream._
> -Leibniz

1: Brutal.

0: So Leibniz is like "Why does nobody understand what I'm talking about?"

1: People never get it do they?

0: So Leibniz then pivots and goes on to use Cartesian notation. "Maybe they'll understand this time," he says to himself in that big itchy wig.

1: What wig?

0: This was wig era. Everyone had one.

![[leibniz-wig.jpg]]

1: He looks like he knows something about me.

0: He does.

1: o_o

0: So then he gets frustrated that nobody understands what he's talking about so he goes on to invent something vaguely like Boolean algebra with different notation.

![[history-of-logic-notation-06-3.png]]

0: These attempts look like the behavior of a distinguished Professor type suggesting ideas to one of their grad students, hoping the grad student's youthful energy and need for publications will drive them to explore the ideas technically.

1: That's why it didn't work huh.

0: Exactly. Speaking of Profs and motivation, there's a quote about this. Where's that Julian Assange thing with the rubberhose and Babylonian creation story in it?

1: That sentence had a lot going on.

0: _(Rummaging around the file system running `find | grep`s.)_

1: Uh, zero?

0: _(Adding a `-i` to the greps.)_

1: ... I'll wait.

0: Found it!

1: Found what?

0: The quote I was looking for.

![[assange-enuma-elish-01.jpg]]

1: Is that the quote?

0: No that's just the file.

![[assange-enuma-elish-02.jpg]]

1: _"450,000 bytes of Greek Polytheism later."_ Did you say this is from a codebase?

0: Yeah of course.

![[assange-enuma-elish-03.jpg]]

1: Which codebase?

0: Rubberhose.

![[assange-enuma-elish-04.jpg]]

1: What's a Rubberhose?

0: A hose that's rubber.

![[assange-enuma-elish-05.jpg]]

1: Look I know you love to torment me but I'm actually super curious. Did you say this code was by J一

0: Rubberhose is just a rubber hose. The codebase is about deniable encryption.

![[assange-enuma-elish-06.jpg]]

1: Deniable how?

0: Against a real threat model. Not the pretend type that the tired eyed Head of Security optimizes for. Cryptography is a nuclear weapon, but 99% of real world "security" is pointy haired midwit manager types smiling while the HoS puts some processes in place that instantly slow down work to a crawl throughout the company causing millions of dollars in unseen damage in one bureaucratic blast, all without any plausible threat model, and the only people bothered by it are the most productive ones. Too many academics if you ask me. Security in practice is Dr. Strangelove without Dr. Strangelove and without a shred of game theory it's just the HoS inflicting his in-built μ+2σ of anxiety on the group to avoid threat models each of which are infinitely less real than the Ultimate threat model at every company namely Never Doing Anything (1) worth remembering (2) worth buying or selling (3) worth all these not inexpensive salaries we all get. There's entirely too much theater in security and not nearly enough game theory or active criminals or ex-Nazis with a haunted hand that keeps heiling the Fürher of its own disembodied volition.

1: _(Staring at zero, unsure if he's done.)_

0: Anyways that's why it's called Rubberhose.

1: What's why it's called Rubberhose?

0: Because Assange wanted an encrypted filesystem designed for an actual real-world threat model where they just beat you with a rubber hose until you give up the keys and decrypt it for them.

1: OOOOOOHH.

0: Anyways we're not here to talk about that, we're looking for a quote.

1: Oh right. I forgot.

![[assange-enuma-elish-07.jpg]]

1: Marutukku?

0: Also known as Marduk.


![[assange-enuma-elish-08.jpg]]


1: What's this from?

0: A creation story. Or two of them I guess.

![[assange-enuma-elish-09.jpg]]

1: Which two?

0: Assange's creation story for Rubberhose. And the Enuma Elish.

1: What's the Enuma Elish?

0: Oldest creation story humans have.

1: Woah, where's it from?

0: Babel.

1: No way.

0: Also known as Babylon. Or בבל or BBL or LBB, same thing. Same three letters as the Hebrew word for Babylon, they just call it "Babel" in the tower story for some reason. But that's the same people. It's their creation story.

1: The Babel story is their creation story?

0: No the Enuma Elish is. The thing Assange is digging through to give his cryptosystem a proper mythology.

1: Y'know this creation story idea is sounding less annoying than before.

0: Anyways Assange eventually settles on Marduk.

1: Marduk is who again?

0: He's Babylon's main god guy so Assange names Rubberhose after HEY FOUND IT!

1: Found what?

0: The quote. Here look:

![[assange-enuma-elish-10.jpg]]

1: Oh wow we're still in Leibniz scope? That's an awesome quote by the way.

0: Agreed. Felt the need to dig it out when Leibniz got to the bit at the end of his life where he couldn't motivate people to work on his thing.

1: He should have put some Marduk in it.

0: Leibniz was no boring dude. We'll get to the Leibniz's _I Ching_ situation later.

1: What's his _I Ching_ situation?

0: That wig. Itching nonstop. I mean just look at that thing. It's gotta be一

_(Narrator: Zero keeps walking around acting like Leibniz in an itchy wig, as One looks on with an undefined but clearly nonnegative emotion.)_

![[leibniz-binary-creation-5.jpg|400]]

## 4. Lambert

> _Foreplay matters more than finishing._
> -Ovid, Dictum Apocryphum.

> _Anything cracked will shatter at a touch._
> -Ovid, possibly Ibid.

0: Then there was Lambert.

![[johann-heinrich-lambert-1.jpg]]

1: Holy Fivehead. Why does he look like Humpty Dumpty?

0: How do you mean?

1: He looks like an egg.

0: Check your premises.

1: What premises?

0: They never say Humpty Dumpty is an egg.

1: _(Recites lyrics in Onehead)_ Huh... They really don't.

0: People assume all sorts of illogical things about Humpty Dumpty.

1: Illogical how?

0: Not justified by the axioms.

1: What axioms?

0: Well, what do we know for sure about H.D.?

1: That he fell off a一

0: Wrong.

1: This file is definitely punishment.

0: This file is about logic, my one.

1: How is this about logic?

0: And logic is about what can be inferred from a given set of premises with absolute certainty.

1: I can infer with certainty that this section is called Lamb一

0: And anything that cannot be inferred with certainty from those premises may be consistent with them, or inconsistent with them, but not true,[^4] for "truth" in logic means "true in all interpretations," or as the logicians say, "true in all models."

1: Are we still talking about Humpty Dumpty or did we switch back to logic?

0: Both. Here's what we know from the original text about Mr. Dumpty.

> _Humpty Dumpty set en a wall,_
> _Humpty Dumpty had a great fall._
> _Four score Men and Four-score more,_
> _Could not make Humpty Dumpty where he was before._
> -Samuel Arnold, Juvenile Amusements, 1797. (Plus like duae litterae of Ibid. in linea prima.)

1: When was this Lambert guy around?

0: 1700s.

1: Noted.

0: Now, dearest One. What can be inferred with certainty about Mr. D, from the point of view of Model Theory?

1: What's Model Theory?

0: A branch of logic. One that concerns itself with the set of possible interpretations of the symbols, terms, and statements in a formal language.

1: What's the question?

0: Taking the original text of H.D. as written by S.A. in J.A. as our Axioms for a formal theory of H.D., what can one infer with certainty from said Ax?

1: Is that Zero-talk for "What do we know about Humpty Dumpty?"?

0: Exactly.

1: He fell.

0: Wrong.

1: Why are you like this?

0: Your conclusion only follows in the subset of models in which "fall" is given the interpretation numbered "1" in the definition below.

```
fall
0. The time of the year when the
   leaves typically fall from the
   trees; autumn; the season of the
   year between the autumnal equinox 
   and the winter solstice.
1. The act of moving to a lower
   position under the effect of 
   gravity.
2. A loss of greatness or status.
3. That which falls or cascades. 
4. The height of that which falls
   or cascades.
5. A reduction in quantity, pitch.
6. (sports) A crucial event or 
   circumstance.
7. (cricket) The action of a batsman 
   being out.
8. (curling) A defect in the ice 
   which causes stones thrown into
   an area to drift in a given 
   direction.
9. (wrestling) A wrestler being 
   pinned to the mat.
10. A hairpiece for women consisting 
    of long strands of hair on a 
    woven backing, intended primarily
    to cover hair loss.
11. (informal) Blame or 
    punishment for a failure
    or misdeed.
12. (nautical) The part of the rope 
    of a tackle to which the power
    is applied in hoisting.
13. An old Scots unit of measure 
    equal to six ells.
14. A short, flexible piece of 
    leather forming part of a
    bullwhip, placed between the
    thong and the cracker.
15. The lid on a piano that covers
    the keyboard.
```

1: As long as we agree mine's #1.

0: Now from the use of the term "had" in "he had a great fall" we can infer that "he fell" only in those models in which the interpretation of "fall" is one of the irregular verbs above, for example definition 1.

1: Please tell me there's a point to all this.

0: However one, if one chooses not to be deaf to all defs but def 1, but rather considers also def 0.

1: _(Not listening)_ Zero...

0: Then the following model is perfectly consistent with our axioms.

![[humpty-dumpty-2.png]]

1: ...

0: ... He had a great one.

1: Tedious fall puns aside, this isn't a model of the axioms.

0: Why not?

1: Where's the wall? Where are the kings hors---

0: There's no king in the original.

1: _(Rereads the text.)_ Dammit.

0: No horses either.

1: Ok then how am I to interpret the rest of the axioms? Aside from the "great fall" which, whatever I might have said a minute ago, I'll admit is pretty cute.

0: Well clearly, our protagonist, prior that great fall was a different sort of man.

1: Different how?

wall. (noun)
1. A barrier, built up for defensive purposes.
2. (figurative) A means of defence or security.
    She built a wall between herself and the outside world.
3. (roleplaying games) A character that has high defenses, thereby reducing the amount of damage taken from the opponent’s attacks.
4. (slang, seduction community, chiefly definite) The stage of biological aging where physical appearance and attractiveness start to deteriorate rapidly. 

1: Defensive outer shell?

0: On any reading.

1: Like over-protected?

0: Hardly. But yes he had his walls up. Don't let them in, don't let them see. He'd been an Ovial Libertine, before they met, in my model.

1: Ovaltine what?

0: A Shellborne Rake.

1: Like for leaves?

0: Before she leaves.

1: Who leaves? There's a girl egg?

0: Never said egg.

1: He sure looks like a一

0: But he was primal, a hunter, our Paleovarian Seducer Mr. D.

1: Are these real words?

0: He'd seen cracks unseen and spread broken many open, screwed them ova, l'ovum and leaves em he'd say, fore he leaves, after ne'er having l'ovum. A bad egg.

1: Egg huh?

0: It's a figure of speech one, grow up.

1: Sure.

0: Grade A dozens with whom he'd had his free range, his choice of whom to take home in which weather and when. And come home they did, ere the night was ova, and unclothed the heat of his sunny side under the satin sheets they felt, but then he'd break fast in the morning ere the sun was up, and when he leaf't he left 'em scrambled, dozens of unfertilized virgins now seen fried up and over easy, eaten up, hors d'oeuvre.

_(Narrator: One has at this point forgotten to be annoyed and is now listening intently to see where this is all going.)_

0: That was before she came.

1: Who?

0: She was hardly his first. And then she came. She was his first.

![[humpty-dumpty-3.png]]

0: He fell for her.

1: I hate you.

0: Then came the fall.

1: I thought it was already一

![[humpty-dumpty-4.png]]

1: I'm counting like three falls here.

0: So we're agreed it's a model?

1: The girl egg? I mean she was ok looki一

0: No, the interpretation. And I never said egg.

1: This was an impressive amount of effort for a lame dad joke but no I'm not convinced it makes sense.

0: Consider the following.

score.
1. (noun, vulgar, slang) A sexual conquest.
2. (noun, slang, crime) A prostitute's client.
3. (verb, vulgar, slang) To obtain sexual favors from a successful seduction.

1: This is a pretty elaborate backstory for a four line poem about an egg.

0: Elaborate how?

1: I mean you added all sorts of stuff that was nowhere in the original.

0: Such as?

1: His philandering. The breakup. The word "fall" meaning (as far as I can tell) everything from "falling in love" to "Autumn" to "falling out." That entirely unmotivated definition of "score" up there. Sure it's a possible interpretation, maybe, if you're insane, but there's no underlying reason why anyone would ever actually think this.

0: Are you sure?

1: Pretty sure.

0: What's his name?

_(Narrator: One frowns at the totality of the section and the file falls silent.)_

1: I hate you.

## 5. Lambert (again)[^5]

0: Ok backing up, I don't know why they use that ugly picture for the guy. There's other pictures where he looks like this.

![[johann-heinrich-lambert-2.jpg]]

1: Hey he's not an egg after all!

0: But for some reason every book that mentions the guy has that awful image from before of him looking all dumpy.

1: Looking all dumpty.\*

RESUME HERE

In Lambert's notation we a see a formal-ish language with the seeds of:
- constants
- variables
- types
- universal and (possibly?) existential quantification, called universality and particularity.

This very clearly mirrors the definition of modern formal languages as found in (for example) Mendelson or Kleene.

![[history-of-logic-notation-07-1.png]]

Lambert's notation also contains the seeds of ideas like set theoretic complement.

Lambert's > and < are a bit like universal and existential quantifiers, but he also introduces mA to mean "some A" and nA to mean (I think) "all A" and the _divides by the quantifiers!_

The richness of ideas you encounter when you see mathematicians doing proper premathematics is incredible, and often has a flavor a lot like programming, since definitions are the beginning of our implementations and we deal with the need to create our own definitions or compare the value of two definitions as developers much more often than mathematicians do.

Lambert's "Fire is to Heat as Cause is to Effect" is an early example of embedding algebra.

Quadrangles lol.

Holland's objection to Lambert's notation makes a great point: A good notation should support the implicit affordances suggested by its structure.

If you have a thing that looks like a fraction, you should expect users to assume that they can clear terms from the denominator by something like multiplication.

If they can't, the fraction notation is failing to support its Implicit Affordances. (Flesh this out. This needs to be a principle.)


![[history-of-logic-notation-07-2.png]]


## Castillion, Gergonne, Bolyai, Bentham

In Castillion, we see "genus" and "species" concepts that show seeds of the concept of types and values.

Gergonne is the first use of the backwards C notation for "is contained in."

In Bolyai we see something like equality vs isomorphism, and also subset and superset. A(=)B as distinct from his "equal with respect to content" is unclear, but having three ideas here instead of two almost suggests that we have a distinction that's more like "is" vs `__eq__` in python, plus an additional concept of isomorphism.

Bentham's notation covers equality of wholes or parts.

![[history-of-logic-notation-08-1.png]]


![[history-of-logic-notation-08-2.png]]


![[history-of-logic-notation-09-1.png]]

## De Morgan

> _I believe there must have been several philosophers who who looked upon mathematics logic with suspicion. I think there was a sharp division between mathematicians who regarded logic as something quite admissible, quite, how shall I say, respectable, and philosophers who looked upon it as with suspicion._
> -Andrzej Mostowski, Reminiscences of Logicians

- DeMorgan uses parentheses, dot, colon, and juxtaposition to stand for various boolean algebra style relations.

- DeMorgan uses CASE for negation, a behavior we also see mirrored in modern regular expressions (though obviously not by direct inheritance of the idea.)

- DeMorgan also uses inverse notation for the converse of a statement.

- DeMorgan great quote: "First, logic is the only science which has made no progress since the revival of letters; Second, logic is the only science that has produced no growth of symbols."

- At this point we're in the mid 1800s, and we arrive at Boole, when things start to look more modern, though still very different in notation.


![[history-of-logic-notation-10-1.png]]


![[history-of-logic-notation-10-2.png]]


![[history-of-logic-notation-10-3.png]]


## Boole
### Or: boole an, int elligent, char acter, \\
### void ing, long standinginterpretationsof, \\
### union and, int ersection, \\
### boole also, workedasanin, \\
### struct orandwas, union ed, \\
### int hesenseof, union meaningmarryto, \\
### boole sstudentmary, long story, \\
### short loveyou, const antlybusythesedays, \\
### extern alfactorsnotyourfaultitsme, \\
### volatile lifethesedays \\
### long timenosee \\
### signed theauthors;

> _In symbolic logic we have elaborated an instrument and nothing for it to do._
> - Ernst Schröder

0: In programming, when we use booleans, do you ever wonder "Why the last name?"

1: Not following.

0: Like usually we use last names before we get to know someone. But once we're on familiar terms, we switch to the first name. So at this point it should be the first.

1: Still not following.

0: This section's about George, of the Boole family, father of Booleans.

1: IT'S A GUY?!

0: Of course! Now I agree it's a bit silly to name the two basic truth values after "some guy." But it's a choice we're probably stuck with. And because of that, I'm a firm believer that the type of `True` and `False` should be `George`.

1: Like `int x; george bool;`?

0: Right, but remember to initialize your `george` before you use him or else he'll have undefined behavior.

1: Is history always this absurd?

0: Yes.

- Boole is more systematic than anyone before him. He uses the + - \* and / of ordinary arithmetic but gives them new meanings.

- Boole's choice of words makes it very clear that he's attempting to formalize thought itself, not some particular content domain.

- He shows that if we make the analogy of "or" with plus and "and" with times, then the distributive laws of algebra hold for concepts. Just noticing this seemingly trivial thing is a big step in the history of logic!

- The simple example of z(x+y) = zx + zy (where x is men, y is women, and z is European) is HUGE in that it shows the analogy of plus and times with "or" and "and" extends in at least some cases across linguistic categories! The z here is an adjective while the x and y are nouns, and the equality goes through just fine. In a sense that's obvious, because "European" here is just the noun phrase "European person," but at first glance it's a huge step toward the goal of formalizing the laws of thought.

- He then says that double application of adjectives in his system is the same as single application, which seems to be the thing that leads to the idea that the variables in the system should only take the values 0 and 1, aka "Booleans."

- "The equation x(1-x)=0 represents the principle of contradiction."

![[history-of-logic-notation-11-1.png]]


![[history-of-logic-notation-11-2.png]]


## Why was this so hard?

- MacFarlane 1879: The reason why Formal Logic has for so long been unable to cope with the subtlety of nature is that too much attention has been given to _pictorial notations._ Arithmetic could never be developed by means of the Roman system of notations; and Formal Logic cannot be developed so long as Barbara is represented by (holy shit insert picture wtf)... We cannot manipulate data so crudely expressed; because the nature of the symbols has not been investigated, and laws of manipulation derived from their general properties."

![[history-of-logic-notation-12-1.png]]

## Peirce

### Or: Symbolic Horse Giver Description Language

### Or: Don't describe a Gift Horse with the mouth

### Or: Reductio Ad Confederacism

> _When I was studying in Moscow University, Foundations of Mathematics was really a subject which was extremely unfashionable._
> -Vladimir Voevodsky, Fields Medalist 2002, How I became interested in foundations of mathematics.

0: Check out this quote. It's one of my favorites ever.

![[history-of-logic-peirce-01.jpg]]

1: I'm having trouble understanding what he's saying.

0: Let's read it slow. I'll translate.

> Much of my work will never be published.
> If I can, before I die, get so much of my stuff out into the world that folks will have trouble finding it all or reading it all, then I'll feel comfortable that I've written enough, and I won't blame myself for not doing more.

1: This just sounds like a guy wanting to be remembered.

0: Keep reading. It's coming up.

> I can't stand publishing stuff, but it isn't because people haven't been asking me to write more.
> 
> It's because some ideas can only be properly conveyed in dialogue. I need someone to push back, interrupt me, ask questions. In dialogue, I can explain.
> 
> But we aren't allowed to write like that in serious adult publications. So fuck em, I'd rather leave my stuff unpublished than write their way.

1: Aahahah.

0: Right?

1: That's a pretty loose translation but I see it now.

0: Love that quote.

1: I always felt like I love ideas and hate textbooks.

0: Same.

1: Ooh, we should write a book with dialogues!

0: Let's not get distracted. We have work to do.

- Peirce has a totally wacky notation for e and pi, and ends up developing a "Logic of Relatives." 

- Peirce: Absolute terms are in Roman font, Relative terms are in Italic, and Conjugate terms are in a type face called Madisonian (seeing a spiritual ancestor of APL and K here.)

- Bertrand Russell said of Peirce "he was one of the most original minds of the later nineteenth century and certainly the greatest American thinker ever."

> The contributions of C. S. Peirce to symbolic logic are more numerous and varied than those of any other writer一at least in the nineteenth century." For Peirce, logic also encompassed much of what is now called epistemology and the philosophy of science. He saw logic as the formal branch of semiotics or study of signs, of which he is a founder, which foreshadowed the debate among logical positivists and proponents of philosophy of language that dominated 20th-century Western philosophy. Peirce's study of signs also included a tripartite theory of predication.
> 
> -The Dynamic Read-Writable Free Encyclopedic Repository of the Modern State of Human Knowledge


> Additionally, he defined the concept of abductive reasoning, as well as rigorously formulating mathematical induction and deductive reasoning. He was one of the founders of statistics. As early as 1886, he saw that logical operations could be carried out by electrical switching circuits. The same idea was used decades later to produce digital computers.
> 
 > -The Dynamic Read-Writable Free Encyclopedic Repository of the Modern State of Human Knowledge

- Peirce: Include the bit from his Wikipedia page about the "negroes syllogism" that shows the confederate context he came from.

- Need the "giver of a horse to a lover of a woman" example. It's too wacky and bizarre not to include.

![[history-of-logic-notation-12-2.png]]


![[history-of-logic-notation-13-1.png]]


![[history-of-logic-notation-13-2.png]]


![[history-of-logic-notation-13-3.png]]

![[history-of-logic-notation-13-4.png]]


![[history-of-logic-peirce-03.jpg]]

![[history-of-logic-peirce-02.jpg]]


![[history-of-logic-peirce-04.jpg]]

![[history-of-logic-peirce-05.jpg]]


## Grassman

![[history-of-logic-notation-14-1.png]]


![[history-of-logic-notation-14-2.png]]

1: What's Op. cit.?

![[history-of-logic-notation-15-1.png]]


![[history-of-logic-notation-15-2.png]]


goto: [[lost+found/2/4]]

[^1]: Greek for _(ahem)_

[^2]: As quoted in Martin Davis _Mathematical Logic and the Origin of Modem Computers,_ quoting Parkinson 1966, _Leibniz - Logical Papers_, originally quoting Leibniz in the primary source _Nescio ergo dicamus id Latine et videamus num quis animadvertat_.

[^3]: Latin for elsewhere.

[^4]: Modulo Gödel, but that's a story for lost+found/4.

[^5]: Or: fiveplay.